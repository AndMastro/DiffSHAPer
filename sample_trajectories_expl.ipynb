{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProxySchemeUnknown",
     "evalue": "Proxy URL had no scheme, should start with http:// or https://",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProxySchemeUnknown\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataloader\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDPM\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmolecule_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_bond_order\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_xyz_file, visualize_chain\n",
      "File \u001b[0;32m~/Repositories/DiffLinker/src/lightning.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics, utils, delinker\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconst\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LINKER_SIZE_DIST\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/wandb/__init__.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# This needs to be early as other modules call it.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mterm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m termsetup, termlog, termerror, termwarn\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sdk \u001b[38;5;28;01mas\u001b[39;00m wandb_sdk\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m     30\u001b[0m wandb\u001b[38;5;241m.\u001b[39mwandb_lib \u001b[38;5;241m=\u001b[39m wandb_sdk\u001b[38;5;241m.\u001b[39mlib\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/wandb/sdk/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mmodule sdk\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wandb_helper \u001b[38;5;28;01mas\u001b[39;00m helper  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_alerts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlertLevel  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwandb_artifacts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Artifact  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/wandb/sdk/wandb_helper.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UsageError\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_util\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_config\u001b[39m(params, exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, include\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exclude \u001b[38;5;129;01mand\u001b[39;00m include:\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/wandb/sdk/lib/config_util.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Error\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_yaml\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filesystem\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/wandb/util.py:108\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m     default_dsn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://a2f1d701163c42b097b9588e56b1c37e@o151352.ingest.sentry.io/5288891\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    107\u001b[0m     sentry_dsn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(SENTRY_DSN, default_dsn)\n\u001b[0;32m--> 108\u001b[0m     \u001b[43msentry_sdk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdsn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentry_dsn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_integrations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSENTRY_ENV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m POW_10_BYTES \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    116\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    117\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m18\u001b[39m),\n\u001b[1;32m    123\u001b[0m ]\n\u001b[1;32m    125\u001b[0m POW_2_BYTES \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    126\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    127\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKiB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEiB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m),\n\u001b[1;32m    133\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/sentry_sdk/hub.py:105\u001b[0m, in \u001b[0;36m_init\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# type: (*Optional[str], **Any) -> ContextManager[Any]\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124;03m\"\"\"Initializes the SDK and optionally integrations.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    This takes the same arguments as the client constructor.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     Hub\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mbind_client(client)\n\u001b[1;32m    107\u001b[0m     rv \u001b[38;5;241m=\u001b[39m _InitGuard(client)\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/sentry_sdk/client.py:89\u001b[0m, in \u001b[0;36m_Client.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# type: (*Any, **Any) -> None\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions \u001b[38;5;241m=\u001b[39m get_options(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: Dict[str, Any]\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/sentry_sdk/client.py:111\u001b[0m, in \u001b[0;36m_Client._init_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     _client_init_debug\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport \u001b[38;5;241m=\u001b[39m \u001b[43mmake_transport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_flusher \u001b[38;5;241m=\u001b[39m SessionFlusher(capture_func\u001b[38;5;241m=\u001b[39m_capture_envelope)\n\u001b[1;32m    115\u001b[0m     request_bodies \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnever\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/sentry_sdk/transport.py:529\u001b[0m, in \u001b[0;36mmake_transport\u001b[0;34m(options)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# if a transport class is given only instantiate it if the dsn is not\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# empty or None\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdsn\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransport_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/sentry_sdk/transport.py:154\u001b[0m, in \u001b[0;36mHttpTransport.__init__\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_discarded_events \u001b[38;5;241m=\u001b[39m defaultdict(\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m    151\u001b[0m )  \u001b[38;5;66;03m# type: DefaultDict[Tuple[str, str], int]\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_client_report_sent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_pool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparsed_dsn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp_proxy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttps_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps_proxy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mca_certs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentry_sdk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hub\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhub_cls \u001b[38;5;241m=\u001b[39m Hub\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/sentry_sdk/transport.py:439\u001b[0m, in \u001b[0;36mHttpTransport._make_pool\u001b[0;34m(self, parsed_dsn, http_proxy, https_proxy, ca_certs)\u001b[0m\n\u001b[1;32m    436\u001b[0m opts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pool_options(ca_certs)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m proxy:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProxyManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m urllib3\u001b[38;5;241m.\u001b[39mPoolManager(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n",
      "File \u001b[0;32m~/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/urllib3/poolmanager.py:481\u001b[0m, in \u001b[0;36mProxyManager.__init__\u001b[0;34m(self, proxy_url, num_pools, headers, proxy_headers, proxy_ssl_context, use_forwarding_for_https, **connection_pool_kw)\u001b[0m\n\u001b[1;32m    478\u001b[0m proxy \u001b[38;5;241m=\u001b[39m parse_url(proxy_url)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m proxy\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProxySchemeUnknown(proxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proxy\u001b[38;5;241m.\u001b[39mport:\n\u001b[1;32m    484\u001b[0m     port \u001b[38;5;241m=\u001b[39m port_by_scheme\u001b[38;5;241m.\u001b[39mget(proxy\u001b[38;5;241m.\u001b[39mscheme, \u001b[38;5;241m80\u001b[39m)\n",
      "\u001b[0;31mProxySchemeUnknown\u001b[0m: Proxy URL had no scheme, should start with http:// or https://"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from src.datasets import get_dataloader\n",
    "from src.lightning import DDPM\n",
    "from src.molecule_builder import get_bond_order\n",
    "from src.visualizer import save_xyz_file, visualize_chain\n",
    "from tqdm.auto import tqdm\n",
    "from pdb import set_trace\n",
    "import sys #@mastro\n",
    "from src import const #@mastro\n",
    "import numpy as np #@mastro\n",
    "from numpy.random import default_rng\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from src.visualizer import load_molecule_xyz, load_xyz_files\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from src import const\n",
    "import networkx as nx\n",
    "\n",
    "from pysmiles import read_smiles\n",
    "#get running device from const file\n",
    "running_device = const.RUNNING_DEVICE\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# os.environ[\"https_proxy\"] = \"http://web-proxy.informatik.uni-bonn.de:3128\"\n",
    "# os.environ[\"http_proxy\"] = \"http://web-proxy.informatik.uni-bonn.de:3128\"\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    'ipykernel_launcher.py',\n",
    "    '--checkpoint', 'models/zinc_difflinker.ckpt',\n",
    "    '--chains', 'trajectories',\n",
    "    '--data', 'datasets',\n",
    "    '--prefix', 'zinc_final_test',\n",
    "    '--keep_frames', '10',\n",
    "    '--device', 'cuda:0', #not used, it is set in the code\n",
    "    '--P', \"node_edge_ratio\"\n",
    "]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--checkpoint', action='store', type=str, required=True)\n",
    "parser.add_argument('--chains', action='store', type=str, required=True)\n",
    "parser.add_argument('--prefix', action='store', type=str, required=True)\n",
    "parser.add_argument('--data', action='store', type=str, required=False, default=None)\n",
    "parser.add_argument('--keep_frames', action='store', type=int, required=True)\n",
    "parser.add_argument('--device', action='store', type=str, required=True) #not used, it is set in the code\n",
    "parser.add_argument('--P', action='store', type=str, required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "args.device = running_device #@mastro\n",
    "SEED = 42\n",
    "experiment_name = args.checkpoint.split('/')[-1].replace('.ckpt', '')\n",
    "chains_output_dir = os.path.join(args.chains, experiment_name, args.prefix, 'chains_' + args.P)\n",
    "final_states_output_dir = os.path.join(args.chains, experiment_name, args.prefix, 'final_states_' + args.P)\n",
    "os.makedirs(chains_output_dir, exist_ok=True)\n",
    "os.makedirs(final_states_output_dir, exist_ok=True)\n",
    "\n",
    "# Loading model form checkpoint (all hparams will be automatically set)\n",
    "model = DDPM.load_from_checkpoint(args.checkpoint, map_location=args.device)\n",
    "\n",
    "# Possibility to evaluate on different datasets (e.g., on CASF instead of ZINC)\n",
    "model.val_data_prefix = args.prefix\n",
    "\n",
    "print(f\"Running device: {args.device}\")\n",
    "# In case <Anonymous> will run my model or vice versa\n",
    "if args.data is not None:\n",
    "    model.data_path = args.data\n",
    "\n",
    "model = model.eval().to(args.device)\n",
    "model.setup(stage='val')\n",
    "dataloader = get_dataloader(\n",
    "    model.val_dataset,\n",
    "    batch_size=1, #@mastro, it was 32\n",
    "    # batch_size=len(model.val_dataset)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_molecular_similarity(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on distances and atom type.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        float: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    # If fragmen_mask is provided, only consider the atoms in the mask\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        mol1 = mol1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mol2 = mol2[mask2,:]\n",
    "\n",
    "    return 1 - torch.norm(mol1 - mol2)\n",
    "\n",
    "def compute_molecular_distance(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on distances and atom type.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        float: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    # If fragmen_mask is provided, only consider the atoms in the mask\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        mol1 = mol1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mol2 = mol2[mask2,:]\n",
    "\n",
    "    return torch.norm(mol1 - mol2).item()\n",
    "\n",
    "def compute_molecular_distance_batch(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on distances and atom type.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: The similarity between the two molecules for each element in the batch.\n",
    "    \"\"\"\n",
    "    # If fragment_mask is provided, only consider the atoms in the mask\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        batch_size = mol1.shape[0]\n",
    "        masked_mol1 = []\n",
    "        for i in range(batch_size):\n",
    "            masked_mol1.append(mol1[i, mask1[i], :])\n",
    "\n",
    "        if batch_size == 1:\n",
    "            mol1 = masked_mol1[0].unsqueeze(0)\n",
    "        else:    \n",
    "            mol1 = torch.stack(masked_mol1)\n",
    "           \n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        batch_size = mol2.shape[0]\n",
    "        masked_mol2 = []\n",
    "        for i in range(batch_size):\n",
    "            masked_mol2.append(mol2[i, mask2[i], :])\n",
    "        \n",
    "        if batch_size == 1:\n",
    "            mol2 = masked_mol2[0].unsqueeze(0)\n",
    "        else:    \n",
    "            mol2 = torch.stack(masked_mol2)\n",
    "\n",
    "    return torch.norm(mol1 - mol2, dim=(1,2))\n",
    "\n",
    "def compute_cosine_similarity(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on distances and atom type.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        float: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    # If fragmen_mask is provided, only consider the atoms in the mask\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        mol1 = mol1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mol2 = mol2[mask2,:]\n",
    "\n",
    "    return cosine_similarity(mol1.flatten().reshape(1, -1), mol2.flatten().reshape(1, -1)).item()\n",
    "\n",
    "\n",
    "def compute_cosine_similarity_batch(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on distances and atom type.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        float: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    # If fragmen_mask is provided, only consider the atoms in the mask\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        batch_size = mol1.shape[0]\n",
    "        masked_mol1 = []\n",
    "        for i in range(batch_size):\n",
    "            masked_mol1.append(mol1[i, mask1[i], :])\n",
    "        \n",
    "        if batch_size == 1:\n",
    "            mol1 = masked_mol1[0].unsqueeze(0)\n",
    "        else:    \n",
    "            mol1 = torch.stack(masked_mol1)\n",
    "        \n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mask2 = mask2.bool()\n",
    "        batch_size = mol2.shape[0]\n",
    "        masked_mol2 = []\n",
    "        for i in range(batch_size):\n",
    "            masked_mol2.append(mol2[i, mask2[i], :])\n",
    "        \n",
    "        if batch_size == 1:\n",
    "            mol2 = masked_mol2[0].unsqueeze(0)\n",
    "        else:    \n",
    "            mol2 = torch.stack(masked_mol2)\n",
    "\n",
    "    cos_sims = []\n",
    "    for i in range(mol1.shape[0]):\n",
    "        cos_sims.append(cosine_similarity(mol1[i].flatten().reshape(1, -1), mol2[i].flatten().reshape(1, -1)).item())\n",
    "\n",
    "    return cos_sims\n",
    "\n",
    "def compute_molecular_similarity_positions(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on positions.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        float: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    # If fragmen_mask is provided, only consider the atoms in the mask\n",
    "    positions1 = mol1[:, :3].squeeze()\n",
    "    positions2 = mol2[:, :3].squeeze()\n",
    "\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        positions1 = positions1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        positions2 = positions2[mask2,:]\n",
    "\n",
    "\n",
    "    return 1 - torch.norm(positions1 - positions2) #choose if distance or similarity, need to check what it the better choice\n",
    "\n",
    "def compute_one_hot_similarity(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Computes the similarity between two one-hot encoded molecules. The one-hot encoding indicates the atom type\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first one-hot encoded molecule.\n",
    "        mol2 (torch.Tensor): The second one-hot encoded molecule.\n",
    "        mask (torch.Tensor, optional): A mask to apply on the atoms. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply mask if provided\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        mol1 = mol1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mol2 = mol2[mask2,:]\n",
    "    \n",
    "    # Compute similarity by comparing the one-hot encoded features\n",
    "    similarity = torch.sum(mol1[:,3:-1] == mol2[:,3:-1]) / mol1[:, 3:-1].numel()\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def create_edge_index(mol, weighted=False):\n",
    "    \"\"\"\n",
    "    Create edge index for a molecule.\n",
    "    \"\"\"\n",
    "    adj = nx.to_scipy_sparse_array(mol).todense()\n",
    "    row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
    "    col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "    if weighted:\n",
    "        weights = torch.from_numpy(adj.data.astype(np.float32))\n",
    "        edge_weight = torch.FloatTensor(weights)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sphere_xai(ax, x, y, z, size, color, alpha):\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "\n",
    "    xs = size * np.outer(np.cos(u), np.sin(v))\n",
    "    ys = size * np.outer(np.sin(u), np.sin(v)) #* 0.8\n",
    "    zs = size * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    ax.plot_surface(x + xs, y + ys, z + zs, rstride=2, cstride=2, color=color, alpha=alpha)\n",
    "\n",
    "def plot_molecule_xai(ax, positions, atom_type, alpha, spheres_3d, hex_bg_color, is_geom, fragment_mask=None, phi_values=None):\n",
    "    x = positions[:, 0]\n",
    "    y = positions[:, 1]\n",
    "    z = positions[:, 2]\n",
    "    # Hydrogen, Carbon, Nitrogen, Oxygen, Flourine\n",
    "\n",
    "    idx2atom = const.GEOM_IDX2ATOM if is_geom else const.IDX2ATOM\n",
    "\n",
    "    colors_dic = np.array(const.COLORS)\n",
    "    radius_dic = np.array(const.RADII)\n",
    "    area_dic = 1500 * radius_dic ** 2\n",
    "\n",
    "    areas = area_dic[atom_type]\n",
    "    radii = radius_dic[atom_type]\n",
    "    colors = colors_dic[atom_type]\n",
    "\n",
    "    if fragment_mask is None:\n",
    "        fragment_mask = torch.ones(len(x))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        for j in range(i + 1, len(x)):\n",
    "            p1 = np.array([x[i], y[i], z[i]])\n",
    "            p2 = np.array([x[j], y[j], z[j]])\n",
    "            dist = np.sqrt(np.sum((p1 - p2) ** 2))\n",
    "            atom1, atom2 = idx2atom[atom_type[i]], idx2atom[atom_type[j]]\n",
    "            draw_edge_int = get_bond_order(atom1, atom2, dist)\n",
    "            line_width = (3 - 2) * 2 * 2\n",
    "            draw_edge = draw_edge_int > 0\n",
    "            if draw_edge:\n",
    "                if draw_edge_int == 4:\n",
    "                    linewidth_factor = 1.5\n",
    "                else:\n",
    "                    linewidth_factor = 1\n",
    "                linewidth_factor *= 0.5\n",
    "                ax.plot(\n",
    "                    [x[i], x[j]], [y[i], y[j]], [z[i], z[j]],\n",
    "                    linewidth=line_width * linewidth_factor * 2,\n",
    "                    c=hex_bg_color,\n",
    "                    alpha=alpha\n",
    "                )\n",
    "\n",
    "    # from pdb import set_trace\n",
    "    # set_trace()\n",
    "\n",
    "    if spheres_3d:\n",
    "        # idx = torch.where(fragment_mask[:len(x)] == 0)[0]\n",
    "        # ax.scatter(\n",
    "        #     x[idx],\n",
    "        #     y[idx],\n",
    "        #     z[idx],\n",
    "        #     alpha=0.9 * alpha,\n",
    "        #     edgecolors='#FCBA03',\n",
    "        #     facecolors='none',\n",
    "        #     linewidths=2,\n",
    "        #     s=900\n",
    "        # )\n",
    "        for i, j, k, s, c, f, phi in zip(x, y, z, radii, colors, fragment_mask, phi_values):\n",
    "            if f == 1:\n",
    "                alpha = 1.0\n",
    "                if phi > 0:\n",
    "                    c = 'red'\n",
    "\n",
    "            draw_sphere_xai(ax, i.item(), j.item(), k.item(), 0.5 * s, c, alpha)\n",
    "\n",
    "    else:\n",
    "        phi_values_array = np.array(list(phi_values.values()))\n",
    "\n",
    "        # #draw fragments\n",
    "        # fragment_mask_on_cpu = fragment_mask.cpu().numpy()\n",
    "        # colors_fragment = colors[fragment_mask_on_cpu == 1]\n",
    "        # x_fragment = x[fragment_mask_on_cpu == 1]\n",
    "        # y_fragment = y[fragment_mask_on_cpu == 1]\n",
    "        # z_fragment = z[fragment_mask_on_cpu == 1]\n",
    "        # areas_fragment = areas[fragment_mask_on_cpu == 1]\n",
    "        # ax.scatter(x_fragment, y_fragment, z_fragment, s=areas_fragment, alpha=0.9 * alpha, c=np.where(phi_values_array > 0, 'red', colors_fragment))\n",
    "\n",
    "        # #draw non-fragment atoms\n",
    "        # colors = colors[fragment_mask_on_cpu == 0]\n",
    "        # x = x[fragment_mask_on_cpu == 0]\n",
    "        # y = y[fragment_mask_on_cpu == 0]\n",
    "        # z = z[fragment_mask_on_cpu == 0]\n",
    "        # areas = areas[fragment_mask_on_cpu == 0]\n",
    "        # ax.scatter(x, y, z, s=areas, alpha=0.9 * alpha, c=colors)\n",
    "\n",
    "        #draw fragments\n",
    "        fragment_mask_on_cpu = fragment_mask.cpu().numpy()\n",
    "        colors_fragment = colors[fragment_mask_on_cpu == 1]\n",
    "        x_fragment = x[fragment_mask_on_cpu == 1]\n",
    "        y_fragment = y[fragment_mask_on_cpu == 1]\n",
    "        z_fragment = z[fragment_mask_on_cpu == 1]\n",
    "        areas_fragment = areas[fragment_mask_on_cpu == 1]\n",
    "        \n",
    "        # Calculate the gradient colors based on phi values\n",
    "        cmap = plt.cm.get_cmap('coolwarm')\n",
    "        norm = plt.Normalize(vmin=min(phi_values_array), vmax=max(phi_values_array))\n",
    "        colors_fragment_shadow = cmap(norm(phi_values_array))\n",
    "        \n",
    "        # ax.scatter(x_fragment, y_fragment, z_fragment, s=areas_fragment, alpha=0.9 * alpha, c=colors_fragment)\n",
    "\n",
    "        ax.scatter(x_fragment, y_fragment, z_fragment, s=areas_fragment, alpha=0.9 * alpha, c=colors_fragment, edgecolors=colors_fragment_shadow, linewidths=5, rasterized=False)\n",
    "\n",
    "        #draw non-fragment atoms\n",
    "        colors = colors[fragment_mask_on_cpu == 0]\n",
    "        x = x[fragment_mask_on_cpu == 0]\n",
    "        y = y[fragment_mask_on_cpu == 0]\n",
    "        z = z[fragment_mask_on_cpu == 0]\n",
    "        areas = areas[fragment_mask_on_cpu == 0]\n",
    "        ax.scatter(x, y, z, s=areas, alpha=0.9 * alpha, c=colors, rasterized=False)\n",
    "\n",
    "\n",
    "def plot_data3d_xai(positions, atom_type, is_geom, camera_elev=0, camera_azim=0, save_path=None, spheres_3d=False,\n",
    "                bg='black', alpha=1., fragment_mask=None, phi_values=None):\n",
    "    black = (0, 0, 0)\n",
    "    white = (1, 1, 1)\n",
    "    hex_bg_color = '#FFFFFF' if bg == 'black' else '#000000' #'#666666'\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.view_init(elev=camera_elev, azim=camera_azim)\n",
    "    if bg == 'black':\n",
    "        ax.set_facecolor(black)\n",
    "    else:\n",
    "        ax.set_facecolor(white)\n",
    "    ax.xaxis.pane.set_alpha(0)\n",
    "    ax.yaxis.pane.set_alpha(0)\n",
    "    ax.zaxis.pane.set_alpha(0)\n",
    "    ax._axis3don = False\n",
    "\n",
    "    if bg == 'black':\n",
    "        ax.w_xaxis.line.set_color(\"black\")\n",
    "    else:\n",
    "        ax.w_xaxis.line.set_color(\"white\")\n",
    "\n",
    "    plot_molecule_xai(\n",
    "        ax, positions, atom_type, alpha, spheres_3d, hex_bg_color, is_geom=is_geom, fragment_mask=fragment_mask, phi_values=phi_values\n",
    "    )\n",
    "\n",
    "    max_value = positions.abs().max().item()\n",
    "    axis_lim = min(40, max(max_value / 1.5 + 0.3, 3.2))\n",
    "    ax.set_xlim(-axis_lim, axis_lim)\n",
    "    ax.set_ylim(-axis_lim, axis_lim)\n",
    "    ax.set_zlim(-axis_lim, axis_lim)\n",
    "    dpi = 300 if spheres_3d else 300 #it was 120 and 50\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0.0, dpi=dpi)\n",
    "        # plt.savefig(save_path, bbox_inches='tight', pad_inches=0.0, dpi=dpi, transparent=True)\n",
    "\n",
    "        if spheres_3d:\n",
    "            img = imageio.imread(save_path)\n",
    "            img_brighter = np.clip(img * 1.4, 0, 255).astype('uint8')\n",
    "            imageio.imsave(save_path, img_brighter)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def visualize_chain_xai(\n",
    "        path, spheres_3d=False, bg=\"black\", alpha=1.0, wandb=None, mode=\"chain\", is_geom=False, fragment_mask=None, phi_values=None\n",
    "):\n",
    "    files = load_xyz_files(path)\n",
    "    save_paths = []\n",
    "\n",
    "    # Fit PCA to the final molecule – to obtain the best orientation for visualization\n",
    "    positions, one_hot, charges = load_molecule_xyz(files[-1], is_geom=is_geom)\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(positions)\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        file = files[i]\n",
    "\n",
    "        positions, one_hot, charges = load_molecule_xyz(file, is_geom=is_geom)\n",
    "        atom_type = torch.argmax(one_hot, dim=1).numpy()\n",
    "\n",
    "        # Transform positions of each frame according to the best orientation of the last frame\n",
    "        positions = pca.transform(positions)\n",
    "        positions = torch.tensor(positions)\n",
    "\n",
    "        fn = file[:-4] + '.png'\n",
    "        plot_data3d_xai(\n",
    "            positions, atom_type,\n",
    "            save_path=fn,\n",
    "            spheres_3d=spheres_3d,\n",
    "            alpha=alpha,\n",
    "            bg=bg,\n",
    "            camera_elev=90,\n",
    "            camera_azim=90,\n",
    "            is_geom=is_geom,\n",
    "            fragment_mask=fragment_mask,\n",
    "            phi_values=phi_values\n",
    "        )\n",
    "        save_paths.append(fn)\n",
    "\n",
    "    imgs = [imageio.imread(fn) for fn in save_paths]\n",
    "    dirname = os.path.dirname(save_paths[0])\n",
    "    gif_path = dirname + '/output.gif'\n",
    "    imageio.mimsave(gif_path, imgs, subrectangles=True)\n",
    "\n",
    "    if wandb is not None:\n",
    "        wandb.log({mode: [wandb.Video(gif_path, caption=gif_path)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainabiliy phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One sampling step at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #@mastro\n",
    "# num_samples = 5\n",
    "# sampled = 0\n",
    "# #end @mastro\n",
    "# start = 0\n",
    "# bond_order_dict = {0:0, 1:0, 2:0, 3:0}\n",
    "# ATOM_SAMPLER = False\n",
    "# SAVE_VISUALIZATION = True\n",
    "# chain_with_full_fragments = None\n",
    "# M = 100 #number of Monte Carlo Sampling steps\n",
    "# P = 0.2 #probability of atom to exist in random graph (also edge in the future)\n",
    "\n",
    "# # Create the folder if it does not exist\n",
    "# folder_save_path = \"results/explanations\"\n",
    "# if not os.path.exists(folder_save_path):\n",
    "#     os.makedirs(folder_save_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for data in dataloader:\n",
    "    \n",
    "#     if sampled < num_samples:\n",
    "#         chain_with_full_fragments = None\n",
    "#         sampled += 1\n",
    "#         rng = default_rng(seed = SEED)\n",
    "#         # generate chain with original and full fragments\n",
    "#         print(data[\"positions\"].shape)\n",
    "#         chain_batch, node_mask = model.sample_chain(data, keep_frames=args.keep_frames)\n",
    "\n",
    "#         # import gc\n",
    "\n",
    "#         # # Collect all objects\n",
    "#         # all_objects = gc.get_objects()\n",
    "\n",
    "#         # # Filter out tensors and print their devices\n",
    "#         # for obj in all_objects:\n",
    "#         #     if torch.is_tensor(obj):\n",
    "#         #         if obj.device == torch.device('cuda:0'):\n",
    "#         #             print(f\"Tensor: {obj}, Device: {obj.device}\")\n",
    "\n",
    "        \n",
    "\n",
    "#         # print(torch.cuda.memory_summary(device=0, abbreviated=False)) #@mastro\n",
    "#         # sys.exit() #@mastro\n",
    "        \n",
    "#         #get the generated molecule and store it in a variable\n",
    "#         chain_with_full_fragments = chain_batch[0, 0, :, :] #need to get only the final frame, is 0 ok in the first dimension?\n",
    "        \n",
    "#         # Compute distance of two chains\n",
    "#         mol_similarity = compute_molecular_similarity(chain_with_full_fragments.squeeze(), chain_with_full_fragments.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data[\"linker_mask\"][0].squeeze())\n",
    "#         print(\"Similarity between the two chains:\", mol_similarity.item())\n",
    "#         # compute similarity of one-hot vectors\n",
    "#         positional_similarity = compute_molecular_similarity_positions(chain_with_full_fragments.squeeze(), chain_with_full_fragments.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data[\"linker_mask\"][0].squeeze())\n",
    "#         print(\"Similarity between the two chains based on positions:\", positional_similarity.item())\n",
    "#         one_hot_similarity = compute_one_hot_similarity(chain_with_full_fragments.squeeze(), chain_with_full_fragments.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data[\"linker_mask\"][0].squeeze())\n",
    "#         print(\"Similarity between the two one-hot vectors:\", one_hot_similarity.item())\n",
    "#         # compute cosine similarity\n",
    "#         cos_simil = compute_cosine_similarity(chain_with_full_fragments.squeeze().cpu(), chain_with_full_fragments.squeeze().cpu(), mask1=data[\"linker_mask\"][0].squeeze().cpu(), mask2=data[\"linker_mask\"][0].squeeze().cpu())\n",
    "#         print(\"Cosine similarity between the two chains:\", cos_simil)\n",
    "    \n",
    "        \n",
    "#         # display(data[\"fragment_mask\"])\n",
    "#         # display(data[\"fragment_mask\"].shape)\n",
    "\n",
    "#         # display(data[\"linker_mask\"])\n",
    "#         # display(data[\"linker_mask\"].shape)\n",
    "        \n",
    "#         # display(data[\"edge_mask\"])\n",
    "#         # display(data[\"edge_mask\"].shape)\n",
    "\n",
    "#         #mask out all edges that are not bonds\n",
    "#         # idx2atom = const.GEOM_IDX2ATOM if model.is_geom else const.IDX2ATOM\n",
    "      \n",
    "#         # positions = data[\"positions\"][0].detach().cpu().numpy()\n",
    "#         # x  = positions[:,0]\n",
    "#         # y  = positions[:,1]\n",
    "#         # z  = positions[:,2]\n",
    "#         # # print(x)\n",
    "       \n",
    "#         # atom_type = torch.argmax(data[\"one_hot\"][0], dim=1)\n",
    "#         # print(\"Number of edges\", len(x) * len(x))\n",
    "#         # sys.exit()\n",
    "#         #uncomment to work on edge_mask (not huge effect, tho)\n",
    "#         # for i in range(len(x)):\n",
    "#         #     for j in range(i+1, len(x)):\n",
    "#         #         p1 = np.array([x[i], y[i], z[i]])\n",
    "#         #         p2 = np.array([x[j], y[j], z[j]])\n",
    "#         #         dist =  np.sqrt(np.sum((p1 - p2) ** 2)) #np.linalg.norm(p1-p2)\n",
    "                \n",
    "#         #         atom1, atom2 = idx2atom[atom_type[i].item()], idx2atom[atom_type[j].item()]\n",
    "#         #         bond_order = get_bond_order(atom1, atom2, dist)\n",
    "                \n",
    "#         #         bond_order_dict[bond_order] += 1\n",
    "#         #         # if bond_order <= 0: #TODO debug. Why not all set to 0?\n",
    "#         #         if True:\n",
    "#         #             data[\"edge_mask\"][i * len(x) + j] = 0\n",
    "#         #             data[\"edge_mask\"][j * len(x) + i] = 0\n",
    "#         #         #set all edge_mask indices to 0\n",
    "#         #         data[\"edge_mask\"] = torch.zeros_like(data[\"edge_mask\"])\n",
    "\n",
    "#         #randomly mask out 50% of atoms\n",
    "#         # mask = torch.rand(data[\"atom_mask\"].shape) > 0.5\n",
    "#         # data[\"atom_mask\"] = data[\"atom_mask\"] * mask.to(model.device)\n",
    "#         #mask out all atoms\n",
    "#         # data[\"atom_mask\"] = torch.zeros_like(data[\"atom_mask\"])\n",
    "        \n",
    "#         #variables that will become function/class arguments/variables\n",
    "\n",
    "        \n",
    "#         num_fragment_atoms = torch.sum(data[\"fragment_mask\"] == 1)\n",
    "\n",
    "        \n",
    "#         phi_atoms = {}\n",
    "#         fragment_indices = torch.where(data[\"fragment_mask\"] == 1)[1]\n",
    "#         num_fragment_atoms = len(fragment_indices)\n",
    "#         num_atoms = data[\"positions\"].shape[1]\n",
    "\n",
    "#         distances_random_samples = []\n",
    "#         cosine_similarities_random_samples = []\n",
    "\n",
    "#         for j in tqdm(range(num_fragment_atoms)):\n",
    "            \n",
    "#             marginal_contrib_distance = 0\n",
    "#             marginal_contrib_cosine_similarity = 0\n",
    "#             marginal_contrib_hausdorff = 0\n",
    "\n",
    "#             for step in tqdm(range(M)):\n",
    "#                 data_j_plus = data.copy()\n",
    "#                 data_j_minus = data.copy()\n",
    "#                 data_random = data.copy()\n",
    "\n",
    "#                 N_z_mask = rng.binomial(1, P, size = num_fragment_atoms)\n",
    "\n",
    "#                 # Ensure at least one element is 1, otherwise randomly select one since at least one fragment atom must be present\n",
    "#                 if not np.any(N_z_mask):\n",
    "#                     print(\"Zero elements in N_z_mask, randomly selecting one.\")\n",
    "#                     random_index = rng.integers(0, num_fragment_atoms)\n",
    "#                     N_z_mask[random_index] = 1\n",
    "\n",
    "#                 # print(\"N_z_mask for sample\", sampled, step, N_z_mask)\n",
    "\n",
    "#                 N_mask = torch.ones(num_fragment_atoms, dtype=torch.int)\n",
    "\n",
    "#                 pi = torch.randperm(num_fragment_atoms)\n",
    "\n",
    "#                 N_j_plus_index = torch.ones(num_fragment_atoms, dtype=torch.int)\n",
    "#                 N_j_minus_index = torch.ones(num_fragment_atoms, dtype=torch.int)\n",
    "#                 selected_node_index = np.where(pi == j)[0].item()\n",
    "                \n",
    "#                 # print(\"Selected node index\", selected_node_index)\n",
    "#                 for k in range(num_fragment_atoms):\n",
    "#                     if k <= selected_node_index:\n",
    "#                         N_j_plus_index[pi[k]] = N_mask[pi[k]]\n",
    "#                     else:\n",
    "#                         N_j_plus_index[pi[k]] = N_z_mask[pi[k]]\n",
    "\n",
    "#                 for k in range(num_fragment_atoms):\n",
    "#                     if k < selected_node_index:\n",
    "#                         N_j_minus_index[pi[k]] = N_mask[pi[k]]\n",
    "#                     else:\n",
    "#                         N_j_minus_index[pi[k]] = N_z_mask[pi[k]]\n",
    "\n",
    "\n",
    "#                 # print(\"N_j_plus_index\", N_j_plus_index)\n",
    "#                 # print(\"N_j_minus_index\", N_j_minus_index)\n",
    "#                 # print(N_j_plus_index == N_j_minus_index)\n",
    "                \n",
    "#                 N_j_plus = fragment_indices[N_j_plus_index.bool()] #fragement indices to keep in molecule j plus\n",
    "#                 N_j_minus = fragment_indices[N_j_minus_index.bool()] #fragement indices to keep in molecule j minus\n",
    "\n",
    "#                 N_random_sample = fragment_indices[torch.IntTensor(N_z_mask).bool()] #fragement indices to keep in random molecule\n",
    "#                 # print(\"N_j_plus\", N_j_plus)\n",
    "#                 # print(\"N_j_minus\", N_j_minus)\n",
    "#                 # print(N_j_plus == N_j_minus)\n",
    "#                 atom_mask_j_plus = torch.zeros(num_atoms, dtype=torch.bool)\n",
    "#                 atom_mask_j_minus = torch.zeros(num_atoms, dtype=torch.bool)\n",
    "\n",
    "#                 atom_mask_random_molecule = torch.zeros(num_atoms, dtype=torch.bool)\n",
    "\n",
    "#                 atom_mask_j_plus[N_j_plus] = True\n",
    "#                 #set to true also linker atoms\n",
    "#                 atom_mask_j_plus[data[\"linker_mask\"][0].squeeze().to(torch.int) == 1] = True\n",
    "#                 atom_mask_j_minus[N_j_minus] = True\n",
    "#                 #set to true also linker atoms\n",
    "#                 atom_mask_j_minus[data[\"linker_mask\"][0].squeeze().to(torch.int) == 1] = True\n",
    "\n",
    "#                 atom_mask_random_molecule[N_random_sample] = True\n",
    "#                 #set to true also linker atoms\n",
    "#                 atom_mask_random_molecule[data[\"linker_mask\"][0].squeeze().to(torch.int) == 1] = True\n",
    "\n",
    "#                 # print(\"Atom mask j plus\", atom_mask_j_plus)\n",
    "#                 # print(\"Atom mask j minus\", atom_mask_j_minus)\n",
    "#                 # print(atom_mask_j_minus==atom_mask_j_plus)\n",
    "\n",
    "#                 #for sample containing j\n",
    "#                 #remove positions of atoms in random_indices\n",
    "#                 data_j_plus[\"positions\"] = data_j_plus[\"positions\"][:, atom_mask_j_plus]\n",
    "#                 #remove one_hot of atoms in random_indices\n",
    "#                 data_j_plus[\"one_hot\"] = data_j_plus[\"one_hot\"][:, atom_mask_j_plus]\n",
    "#                 #remove atom_mask of atoms in random_indices\n",
    "#                 data_j_plus[\"atom_mask\"] = data_j_plus[\"atom_mask\"][:, atom_mask_j_plus]\n",
    "#                 #remove fragment_mask of atoms in random_indices\n",
    "#                 data_j_plus[\"fragment_mask\"] =  data_j_plus[\"fragment_mask\"][:, atom_mask_j_plus]\n",
    "#                 #remove linker_mask of atoms in random_indices\n",
    "#                 data_j_plus[\"linker_mask\"] = data_j_plus[\"linker_mask\"][:, atom_mask_j_plus]\n",
    "#                 #remove edge_mask of atoms in random_indices\n",
    "#                 for index in N_j_plus:\n",
    "#                     for i in range(num_atoms):\n",
    "#                         data_j_plus[\"edge_mask\"][index * num_atoms + i] = 0\n",
    "#                         data_j_plus[\"edge_mask\"][i * num_atoms + index] = 0\n",
    "\n",
    "#                 #remove all values in edge_mask that are 0\n",
    "#                 data_j_plus[\"edge_mask\"] = data_j_plus[\"edge_mask\"][data_j_plus[\"edge_mask\"] != 0]  #to be checked, but working on atoms has as effect. For the moment we stick to atoms, then we move to edges (need to edit internal function for this, or redefine everything...)\n",
    "\n",
    "#                 # print(\"After removal j plus:\", data_j_plus[\"positions\"])\n",
    "#                 # print(data_j_plus[\"positions\"].shape)\n",
    "                \n",
    "#                 #for sample not containing j\n",
    "#                 #remove positions of atoms in random_indices\n",
    "#                 data_j_minus[\"positions\"] = data_j_minus[\"positions\"][:, atom_mask_j_minus]\n",
    "#                 #remove one_hot of atoms in random_indices\n",
    "#                 data_j_minus[\"one_hot\"] = data_j_minus[\"one_hot\"][:, atom_mask_j_minus]\n",
    "#                 #remove atom_mask of atoms in random_indices\n",
    "#                 data_j_minus[\"atom_mask\"] = data_j_minus[\"atom_mask\"][:, atom_mask_j_minus]\n",
    "#                 #remove fragment_mask of atoms in random_indices\n",
    "#                 data_j_minus[\"fragment_mask\"] =  data_j_minus[\"fragment_mask\"][:, atom_mask_j_minus]\n",
    "#                 #remove linker_mask of atoms in random_indices\n",
    "#                 data_j_minus[\"linker_mask\"] = data_j_minus[\"linker_mask\"][:, atom_mask_j_minus]\n",
    "#                 #remove edge_mask of atoms in random_indices\n",
    "#                 for index in N_j_minus:\n",
    "#                     for i in range(num_atoms):\n",
    "#                         data_j_minus[\"edge_mask\"][index * num_atoms + i] = 0\n",
    "#                         data_j_minus[\"edge_mask\"][i * num_atoms + index] = 0\n",
    "\n",
    "#                 #remove all values in edge_mask that are 0\n",
    "#                 data_j_minus[\"edge_mask\"] = data_j_minus[\"edge_mask\"][data_j_minus[\"edge_mask\"] != 0]  #to be checked, but working on atoms has as effect. For the moment we stick to atoms, then we move to edges (need to edit internal function for this, or redefine everything...)\n",
    "\n",
    "#                 # print(\"After removal j minus:\", data_j_minus[\"positions\"])\n",
    "#                 # print(data_j_minus[\"positions\"].shape)\n",
    "\n",
    "#                 #for random sample\n",
    "#                 data_random[\"positions\"] = data_random[\"positions\"][:, atom_mask_random_molecule]\n",
    "#                 #remove one_hot of atoms in random_indices\n",
    "#                 data_random[\"one_hot\"] = data_random[\"one_hot\"][:, atom_mask_random_molecule]\n",
    "#                 #remove atom_mask of atoms in random_indices\n",
    "#                 data_random[\"atom_mask\"] = data_random[\"atom_mask\"][:, atom_mask_random_molecule]\n",
    "#                 #remove fragment_mask of atoms in random_indices\n",
    "#                 data_random[\"fragment_mask\"] =  data_random[\"fragment_mask\"][:, atom_mask_random_molecule]\n",
    "#                 #remove linker_mask of atoms in random_indices\n",
    "#                 data_random[\"linker_mask\"] = data_random[\"linker_mask\"][:, atom_mask_random_molecule]\n",
    "#                 #remove edge_mask of atoms in random_indices\n",
    "#                 for index in N_z_mask:\n",
    "#                     for i in range(num_atoms):\n",
    "#                         data_random[\"edge_mask\"][index * num_atoms + i] = 0\n",
    "#                         data_random[\"edge_mask\"][i * num_atoms + index] = 0\n",
    "\n",
    "#                 #remove all values in edge_mask that are 0\n",
    "#                 data_random[\"edge_mask\"] = data_random[\"edge_mask\"][data_random[\"edge_mask\"] != 0] \n",
    "\n",
    "\n",
    "\n",
    "#                 #with node j\n",
    "#                 chain_j_plus, node_mask_j_plus = model.sample_chain(data_j_plus, keep_frames=args.keep_frames)\n",
    "#                 #take only the ts 0 frame\n",
    "#                 chain_j_plus = chain_j_plus[0, 0, :, :]\n",
    "                \n",
    "            \n",
    "#                 V_j_plus_distance = compute_molecular_distance(chain_with_full_fragments.squeeze(), chain_j_plus.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data_j_plus[\"linker_mask\"][0].squeeze())\n",
    "\n",
    "#                 V_j_plus_cosine_similarity = compute_cosine_similarity(chain_with_full_fragments.squeeze().cpu(), chain_j_plus.squeeze().cpu(), mask1=data[\"linker_mask\"][0].squeeze().cpu(), mask2=data_j_plus[\"linker_mask\"][0].squeeze().cpu())\n",
    "\n",
    "#                 # print(\"V_j_plus\", V_j_plus)\n",
    "\n",
    "#                 #without node j\n",
    "#                 chain_j_minus, node_mask_j_minus = model.sample_chain(data_j_minus, keep_frames=args.keep_frames)\n",
    "\n",
    "#                 #take only the ts 0 frame\n",
    "#                 chain_j_minus = chain_j_minus[0, 0, :, :]\n",
    "\n",
    "#                 V_j_minus_distance = compute_molecular_distance(chain_with_full_fragments.squeeze(), chain_j_minus.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data_j_minus[\"linker_mask\"][0].squeeze())\n",
    "\n",
    "#                 V_j_minus_cosine_similarity = compute_cosine_similarity(chain_with_full_fragments.squeeze().cpu(), chain_j_minus.squeeze().cpu(), mask1=data[\"linker_mask\"][0].squeeze().cpu(), mask2=data_j_minus[\"linker_mask\"][0].squeeze().cpu())\n",
    "\n",
    "#                 #with random sample\n",
    "#                 chain_random, node_mask_random = model.sample_chain(data_random, keep_frames=args.keep_frames)\n",
    "\n",
    "#                 chain_random = chain_random[0, 0, :, :]\n",
    "\n",
    "#                 V_random_distance = compute_molecular_distance(chain_with_full_fragments.squeeze(), chain_random.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data_random[\"linker_mask\"][0].squeeze())\n",
    "\n",
    "#                 V_random_cosine_similarity = compute_cosine_similarity(chain_with_full_fragments.squeeze().cpu(), chain_random.squeeze().cpu(), mask1=data[\"linker_mask\"][0].squeeze().cpu(), mask2=data_random[\"linker_mask\"][0].squeeze().cpu())\n",
    "\n",
    "#                 distances_random_samples.append(V_random_distance)\n",
    "#                 cosine_similarities_random_samples.append(V_random_cosine_similarity)\n",
    "\n",
    "#                 # print(V_random_distance, V_random_cosine_similarity)\n",
    "                \n",
    "#                 marginal_contrib_distance += (V_j_plus_distance - V_j_minus_distance)\n",
    "\n",
    "#                 marginal_contrib_cosine_similarity += (V_j_plus_cosine_similarity - V_j_minus_cosine_similarity)\n",
    "\n",
    "#                 # marginal_contrib_hausdorff += (V_j_plus_hausdorff - V_j_minus_hausdorff)\n",
    "\n",
    "#             phi_atoms[fragment_indices[j].item()] = [0,0] #,0]    \n",
    "#             phi_atoms[fragment_indices[j].item()][0] = marginal_contrib_distance/M #j is the index of the fragment atom in the fragment indices tensor\n",
    "#             phi_atoms[fragment_indices[j].item()][1] = marginal_contrib_cosine_similarity/M\n",
    "#             # phi_atoms[fragment_indices[j]][2] = marginal_contrib_hausdorff/M\n",
    "\n",
    "#             print(data[\"name\"])\n",
    "\n",
    "#         phi_atoms_distances = {}\n",
    "#         phi_atoms_cosine_similarity = {}\n",
    "#         for atom_index, phi_values in phi_atoms.items():\n",
    "#             phi_atoms_distances[atom_index] = phi_values[0]\n",
    "#             phi_atoms_cosine_similarity[atom_index] = phi_values[1]\n",
    "\n",
    "#         if SAVE_VISUALIZATION:\n",
    "#             for i in range(len(data['positions'])):\n",
    "#                 chain = chain_batch[:, i, :, :]\n",
    "#                 assert chain.shape[0] == args.keep_frames\n",
    "#                 assert chain.shape[1] == data['positions'].shape[1]\n",
    "#                 assert chain.shape[2] == data['positions'].shape[2] + data['one_hot'].shape[2] + model.include_charges\n",
    "\n",
    "#                 # Saving chains\n",
    "#                 name = str(i + start)\n",
    "#                 chain_output = os.path.join(chains_output_dir, name)\n",
    "#                 os.makedirs(chain_output, exist_ok=True)\n",
    "\n",
    "#                 one_hot = chain[:, :, 3:-1]\n",
    "#                 positions = chain[:, :, :3]\n",
    "#                 chain_node_mask = torch.cat([node_mask[i].unsqueeze(0) for _ in range(args.keep_frames)], dim=0)\n",
    "#                 names = [f'{name}_{j}' for j in range(args.keep_frames)]\n",
    "\n",
    "#                 save_xyz_file(chain_output, one_hot, positions, chain_node_mask, names=names, is_geom=model.is_geom)\n",
    "#                 visualize_chain_xai(\n",
    "#                     chain_output,\n",
    "#                     spheres_3d=False,\n",
    "#                     alpha=0.7,\n",
    "#                     bg='white',\n",
    "#                     is_geom=model.is_geom,\n",
    "#                     fragment_mask=data['fragment_mask'][i].squeeze(),\n",
    "#                     phi_values=phi_atoms_distances\n",
    "#                 )\n",
    "\n",
    "#                 # Saving final prediction and ground truth separately\n",
    "#                 true_one_hot = data['one_hot'][i].unsqueeze(0)\n",
    "#                 true_positions = data['positions'][i].unsqueeze(0)\n",
    "#                 true_node_mask = data['atom_mask'][i].unsqueeze(0)\n",
    "#                 save_xyz_file(\n",
    "#                     final_states_output_dir,\n",
    "#                     true_one_hot,\n",
    "#                     true_positions,\n",
    "#                     true_node_mask,\n",
    "#                     names=[f'{name}_true'],\n",
    "#                     is_geom=model.is_geom,\n",
    "#                 )\n",
    "\n",
    "#                 pred_one_hot = chain[0, :, 3:-1].unsqueeze(0)\n",
    "#                 pred_positions = chain[0, :, :3].unsqueeze(0)\n",
    "#                 pred_node_mask = chain_node_mask[0].unsqueeze(0)\n",
    "#                 save_xyz_file(\n",
    "#                     final_states_output_dir,\n",
    "#                     pred_one_hot,\n",
    "#                     pred_positions,\n",
    "#                     pred_node_mask,\n",
    "#                     names=[f'{name}_pred'],\n",
    "#                     is_geom=model.is_geom\n",
    "#                 )\n",
    "\n",
    "#             start += len(data['positions'])\n",
    "\n",
    "#         # Save phi_atoms to a text file\n",
    "#         with open(f'{folder_save_path}/phi_atoms_{sampled}.txt', 'w') as write_file:\n",
    "#             write_file.write(\"sample name: \" + str(data[\"name\"]) + \"\\n\")\n",
    "#             write_file.write(\"atom_index,distance,cosine_similarity\\n\")\n",
    "#             for atom_index, phi_values in phi_atoms.items():\n",
    "#                 write_file.write(f\"{atom_index},{phi_values[0]},{phi_values[1]}\\n\")\n",
    "\n",
    "#             write_file.write(\"\\n\")\n",
    "#             #save sum of phi values for disance and cosine similarity\n",
    "#             write_file.write(\"Sum of phi values for distance\\n\")\n",
    "#             write_file.write(str(sum([p_values[0] for p_values in phi_atoms.values()])) + \"\\n\")\n",
    "#             write_file.write(\"Sum of phi values for cosine similarity\\n\")\n",
    "#             write_file.write(str(sum([p_values[1] for p_values in phi_atoms.values()])) + \"\\n\")     \n",
    "#             write_file.write(\"Distance random samples\\n\")\n",
    "#             write_file.write(str(distances_random_samples) + \"\\n\")\n",
    "#             write_file.write(\"Cosine similarity random samples\\n\")\n",
    "#             write_file.write(str(cosine_similarities_random_samples) + \"\\n\")\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple sampling steps at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two chains: 1.0\n",
      "Molecular distance using batches:  tensor([0.], device='cuda:0')\n",
      "Similarity between the two chains based on positions: 1.0\n",
      "Similarity between the two one-hot vectors: 1.0\n",
      "Cosine similarity between the two chains: 1.0\n",
      "Cosine similarity between the two chains using batches: [1.0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0304cb75654933a6e6ed3cff31e083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b92a29d844f498b93338985bf482aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cc1ccc(CCNC(=O)NCCc2csc(N3CCCC3)n2)c(C)c1']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01499f18bc9140a0a6d0515f6ce2daaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cc1ccc(CCNC(=O)NCCc2csc(N3CCCC3)n2)c(C)c1']\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n",
      "positions shape:  torch.Size([26, 3])\n",
      "atom_type shape:  (26,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mastro\\AppData\\Local\\Temp\\ipykernel_24832\\3400972096.py:205: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  imgs = [imageio.imread(fn) for fn in save_paths]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two chains: 1.0\n",
      "Molecular distance using batches:  tensor([0.], device='cuda:0')\n",
      "Similarity between the two chains based on positions: 1.0\n",
      "Similarity between the two one-hot vectors: 1.0\n",
      "Cosine similarity between the two chains: 0.9999998807907104\n",
      "Cosine similarity between the two chains using batches: [0.9999998807907104]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ec51d1d6594d428643ba3e9a7a957e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f740cdb755af475ca8f194da627edf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero elements in mask, randomly selecting one.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 599\u001b[0m\n\u001b[0;32m    595\u001b[0m data_random_batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([data_random_dict[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(PARALLEL_STEPS)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;66;03m#trying the new data batch\u001b[39;00m\n\u001b[1;32m--> 599\u001b[0m chain_j_plus_batch, node_mask_j_plus_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_j_plus_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m chain_j_plus \u001b[38;5;241m=\u001b[39m chain_j_plus_batch[\u001b[38;5;241m0\u001b[39m, :, :, :] \u001b[38;5;66;03m#it should take the first frame and all batch elements -> check it is really the first frame (I need the one at t0, the final generated molecule)\u001b[39;00m\n\u001b[0;32m    603\u001b[0m chain_j_minus_batch, node_mask_j_minus_batch \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msample_chain(data_j_minus_batch, keep_frames\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mkeep_frames)\n",
      "File \u001b[1;32mc:\\Repositories\\DiffLinker\\src\\lightning.py:456\u001b[0m, in \u001b[0;36mDDPM.sample_chain\u001b[1;34m(self, data, sample_fn, keep_frames)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenter_of_mass)\n\u001b[0;32m    454\u001b[0m x \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mremove_partial_mean_with_mask(x, node_mask, center_of_mass_mask)\n\u001b[1;32m--> 456\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_chain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfragment_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfragment_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinker_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinker_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chain, node_mask\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Repositories\\DiffLinker\\src\\edm.py:152\u001b[0m, in \u001b[0;36mEDM.sample_chain\u001b[1;34m(self, x, h, node_mask, fragment_mask, linker_mask, edge_mask, context, keep_frames)\u001b[0m\n\u001b[0;32m    149\u001b[0m s_array \u001b[38;5;241m=\u001b[39m s_array \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    150\u001b[0m t_array \u001b[38;5;241m=\u001b[39m t_array \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m--> 152\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_p_zs_given_zt_only_linker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfragment_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfragment_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinker_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinker_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m write_index \u001b[38;5;241m=\u001b[39m (s \u001b[38;5;241m*\u001b[39m keep_frames) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    163\u001b[0m chain[write_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnormalize_z(z)\n",
      "File \u001b[1;32mc:\\Repositories\\DiffLinker\\src\\edm.py:188\u001b[0m, in \u001b[0;36mEDM.sample_p_zs_given_zt_only_linker\u001b[1;34m(self, s, t, z_t, node_mask, fragment_mask, linker_mask, edge_mask, context)\u001b[0m\n\u001b[0;32m    185\u001b[0m sigma_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma(gamma_t, target_tensor\u001b[38;5;241m=\u001b[39mz_t)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Neural net prediction.\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m eps_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinker_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinker_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m eps_hat \u001b[38;5;241m=\u001b[39m eps_hat \u001b[38;5;241m*\u001b[39m linker_mask\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Compute mu for p(z_s | z_t)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Repositories\\DiffLinker\\src\\egnn.py:449\u001b[0m, in \u001b[0;36mDynamics.forward\u001b[1;34m(self, t, xh, node_mask, linker_mask, edge_mask, context)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# Forward EGNN\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# Output: h_final (B*N, nf), x_final (B*N, 3), vel (B*N, 3)\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124megnn_dynamics\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 449\u001b[0m     h_final, x_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinker_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinker_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m     node_mask \u001b[38;5;241m=\u001b[39m node_mask\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mrunning_device) \u001b[38;5;66;03m#@mastro moved node_mask to device\u001b[39;00m\n\u001b[0;32m    458\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mrunning_device) \u001b[38;5;66;03m#@mastro moved x to device \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Repositories\\DiffLinker\\src\\egnn.py:252\u001b[0m, in \u001b[0;36mEGNN.forward\u001b[1;34m(self, h, x, edge_index, node_mask, linker_mask, edge_mask)\u001b[0m\n\u001b[0;32m    249\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(h) \u001b[38;5;66;03m#@mastro moved h to device of embedding (hopefully the selected GPU)\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[1;32m--> 252\u001b[0m     h, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43me_block_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinker_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinker_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistances\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Important, the bias of the last linear might be non-zero\u001b[39;00m\n\u001b[0;32m    261\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_out(h) \u001b[38;5;66;03m#@mastro moved h to device of embedding (hopefully the selected GPU)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Repositories\\DiffLinker\\src\\egnn.py:185\u001b[0m, in \u001b[0;36mEquivariantBlock.forward\u001b[1;34m(self, h, x, edge_index, node_mask, linker_mask, edge_mask, edge_attr)\u001b[0m\n\u001b[0;32m    183\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([distances, edge_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[1;32m--> 185\u001b[0m     h, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgcl_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcl_equiv\u001b[39m\u001b[38;5;124m\"\u001b[39m](\n\u001b[0;32m    187\u001b[0m     h, x,\n\u001b[0;32m    188\u001b[0m     edge_index\u001b[38;5;241m=\u001b[39medge_index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m     edge_mask\u001b[38;5;241m=\u001b[39medge_mask,\n\u001b[0;32m    194\u001b[0m )\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# Important, the bias of the last linear might be non-zero\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Repositories\\DiffLinker\\src\\egnn.py:86\u001b[0m, in \u001b[0;36mGCL.forward\u001b[1;34m(self, h, edge_index, edge_attr, node_attr, node_mask, edge_mask)\u001b[0m\n\u001b[0;32m     84\u001b[0m row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mrunning_device)\n\u001b[0;32m     85\u001b[0m col \u001b[38;5;241m=\u001b[39m col\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mrunning_device)\n\u001b[1;32m---> 86\u001b[0m edge_feat, mij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m h, agg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_model(h, edge_index, edge_feat, node_attr)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Repositories\\DiffLinker\\src\\egnn.py:57\u001b[0m, in \u001b[0;36mGCL.edge_model\u001b[1;34m(self, source, target, edge_attr, edge_mask)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([source, target, edge_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m mij \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention:\n\u001b[0;32m     60\u001b[0m     att_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt_mlp(mij)\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#@mastro\n",
    "torch.set_printoptions(threshold=float('inf'))\n",
    "\n",
    "num_samples = 30\n",
    "sampled = 0\n",
    "#end @mastro\n",
    "start = 0\n",
    "\n",
    "SAVE_VISUALIZATION = True\n",
    "chain_with_full_fragments = None\n",
    "M = 100 #100 #number of Monte Carlo Sampling steps\n",
    "P = None #probability of atom to exist in random graph (also edge in the future)\n",
    "PARALLEL_STEPS = 100\n",
    "# Create the folder if it does not exist\n",
    "folder_save_path = \"results/explanations_\" + args.P\n",
    "if not os.path.exists(folder_save_path):\n",
    "    os.makedirs(folder_save_path)\n",
    "\n",
    "for data in dataloader:\n",
    "    \n",
    "    if sampled < num_samples:\n",
    "\n",
    "        smile = data[\"name\"][0]\n",
    "        \n",
    "        mol = read_smiles(smile)\n",
    "        num_nodes = mol.number_of_nodes()\n",
    "        \n",
    "        num_edges = mol.number_of_edges()\n",
    "        num_edges_directed = num_edges*2\n",
    "        \n",
    "        \n",
    "        graph_density = num_edges_directed/(num_nodes*(num_nodes-1))\n",
    "        max_number_of_nodes = num_edges + 1\n",
    "\n",
    "        node_density = num_nodes/max_number_of_nodes\n",
    "\n",
    "        node_edge_ratio = num_nodes/num_edges\n",
    "        \n",
    "        edge_node_ratio = num_edges/num_nodes\n",
    "        print(\"Graph density:\", graph_density)\n",
    "        print(\"Node density:\", node_density)\n",
    "        print(\"Node-edge ratio:\", node_edge_ratio)\n",
    "        print(\"Edge-node ratio:\", edge_node_ratio)\n",
    "        \n",
    "        if args.P == \"graph_density\":\n",
    "            P = graph_density #probability of atom to exist in random graph (not sure if correct approach, this was correct for edges)\n",
    "        elif args.P == \"node_density\":\n",
    "            P = node_density\n",
    "        elif args.P == \"node_edge_ratio\" or args.P == \"edge_node_ratio\":\n",
    "            if node_edge_ratio < edge_node_ratio:\n",
    "                P = node_edge_ratio\n",
    "                print(\"Using node-edge ratio\", node_edge_ratio)\n",
    "            else:\n",
    "                P = edge_node_ratio\n",
    "                print(\"Using edge-node ratio\", edge_node_ratio)            \n",
    "        else:\n",
    "            P = 0.2\n",
    "\n",
    "        print(\"Using P:\", args.P, P)\n",
    "\n",
    "        chain_with_full_fragments = None\n",
    "        sampled += 1\n",
    "        rng = default_rng(seed = SEED)\n",
    "        rng_torch = torch.Generator(device=\"cpu\")\n",
    "        rng_torch.manual_seed(SEED)\n",
    "        # generate chain with original and full fragments\n",
    "       \n",
    "        chain_batch, node_mask = model.sample_chain(data, keep_frames=args.keep_frames)\n",
    "        \n",
    "        #get the generated molecule and store it in a variable\n",
    "        chain_with_full_fragments = chain_batch[0, :, :, :] #need to get only the final frame, is 0 ok in the first dimension?\n",
    "        # print(\"Chain with full fragments shape:\", chain_with_full_fragments.shape)\n",
    "        # sys.exit()\n",
    "        # Compute distance of two chains\n",
    "        mol_similarity = compute_molecular_similarity(chain_with_full_fragments.squeeze(), chain_with_full_fragments.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data[\"linker_mask\"][0].squeeze())\n",
    "        print(\"Similarity between the two chains:\", mol_similarity.item())\n",
    "        #compute molecular distance using batches\n",
    "        original_linker_mask_batch = data[\"linker_mask\"][0].squeeze().repeat(PARALLEL_STEPS, 1) #check why it works\n",
    "        \n",
    "        mol_distance = compute_molecular_distance_batch(chain_with_full_fragments, chain_with_full_fragments, mask1=original_linker_mask_batch, mask2=original_linker_mask_batch)\n",
    "        print(\"Molecular distance using batches: \", mol_distance)\n",
    "        \n",
    "        # compute similarity of one-hot vectors\n",
    "        positional_similarity = compute_molecular_similarity_positions(chain_with_full_fragments.squeeze(), chain_with_full_fragments.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data[\"linker_mask\"][0].squeeze())\n",
    "        print(\"Similarity between the two chains based on positions:\", positional_similarity.item())\n",
    "        one_hot_similarity = compute_one_hot_similarity(chain_with_full_fragments.squeeze(), chain_with_full_fragments.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data[\"linker_mask\"][0].squeeze())\n",
    "        print(\"Similarity between the two one-hot vectors:\", one_hot_similarity.item())\n",
    "        # compute cosine similarity\n",
    "        cos_simil = compute_cosine_similarity(chain_with_full_fragments.squeeze().cpu(), chain_with_full_fragments.squeeze().cpu(), mask1=data[\"linker_mask\"][0].squeeze().cpu(), mask2=data[\"linker_mask\"][0].squeeze().cpu())\n",
    "        print(\"Cosine similarity between the two chains:\", cos_simil)\n",
    "        cos_simil_batch = compute_cosine_similarity_batch(chain_with_full_fragments.cpu(), chain_with_full_fragments.cpu(), mask1=original_linker_mask_batch.cpu(), mask2=original_linker_mask_batch.cpu())\n",
    "        print(\"Cosine similarity between the two chains using batches:\", cos_simil_batch)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # display(data[\"fragment_mask\"])\n",
    "        # display(data[\"fragment_mask\"].shape)\n",
    "\n",
    "        # display(data[\"linker_mask\"])\n",
    "        # display(data[\"linker_mask\"].shape)\n",
    "        \n",
    "        # display(data[\"edge_mask\"])\n",
    "        # display(data[\"edge_mask\"].shape)\n",
    "\n",
    "        #mask out all edges that are not bonds\n",
    "        # idx2atom = const.GEOM_IDX2ATOM if model.is_geom else const.IDX2ATOM\n",
    "      \n",
    "        # positions = data[\"positions\"][0].detach().cpu().numpy()\n",
    "        # x  = positions[:,0]\n",
    "        # y  = positions[:,1]\n",
    "        # z  = positions[:,2]\n",
    "        # # print(x)\n",
    "       \n",
    "        # atom_type = torch.argmax(data[\"one_hot\"][0], dim=1)\n",
    "        # print(\"Number of edges\", len(x) * len(x))\n",
    "        # sys.exit()\n",
    "        #uncomment to work on edge_mask (not huge effect, tho)\n",
    "        # for i in range(len(x)):\n",
    "        #     for j in range(i+1, len(x)):\n",
    "        #         p1 = np.array([x[i], y[i], z[i]])\n",
    "        #         p2 = np.array([x[j], y[j], z[j]])\n",
    "        #         dist =  np.sqrt(np.sum((p1 - p2) ** 2)) #np.linalg.norm(p1-p2)\n",
    "                \n",
    "        #         atom1, atom2 = idx2atom[atom_type[i].item()], idx2atom[atom_type[j].item()]\n",
    "        #         bond_order = get_bond_order(atom1, atom2, dist)\n",
    "                \n",
    "        #         bond_order_dict[bond_order] += 1\n",
    "        #         # if bond_order <= 0: #TODO debug. Why not all set to 0?\n",
    "        #         if True:\n",
    "        #             data[\"edge_mask\"][i * len(x) + j] = 0\n",
    "        #             data[\"edge_mask\"][j * len(x) + i] = 0\n",
    "        #         #set all edge_mask indices to 0\n",
    "        #         data[\"edge_mask\"] = torch.zeros_like(data[\"edge_mask\"])\n",
    "\n",
    "        #randomly mask out 50% of atoms\n",
    "        # mask = torch.rand(data[\"atom_mask\"].shape) > 0.5\n",
    "        # data[\"atom_mask\"] = data[\"atom_mask\"] * mask.to(model.device)\n",
    "        #mask out all atoms\n",
    "        # data[\"atom_mask\"] = torch.zeros_like(data[\"atom_mask\"])\n",
    "        \n",
    "        #variables that will become function/class arguments/variables\n",
    "\n",
    "        \n",
    "        num_fragment_atoms = torch.sum(data[\"fragment_mask\"] == 1)\n",
    "\n",
    "        \n",
    "        phi_atoms = {}\n",
    "        \n",
    "        \n",
    "        num_atoms = data[\"positions\"].shape[1]\n",
    "        num_linker_atoms = torch.sum(data[\"linker_mask\"] == 1)\n",
    "        \n",
    "        distances_random_samples = []\n",
    "        cosine_similarities_random_samples = []\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        for j in tqdm(range(num_fragment_atoms)): \n",
    "            \n",
    "            marginal_contrib_distance = 0\n",
    "            marginal_contrib_cosine_similarity = 0\n",
    "            marginal_contrib_hausdorff = 0\n",
    "\n",
    "            for step in tqdm(range(int(M/PARALLEL_STEPS))):\n",
    "\n",
    "                fragment_indices = torch.where(data[\"fragment_mask\"] == 1)[1]\n",
    "                num_fragment_atoms = len(fragment_indices)\n",
    "                fragment_indices = fragment_indices.repeat(PARALLEL_STEPS).to(args.device)\n",
    "\n",
    "                data_j_plus = data.copy()\n",
    "                data_j_minus = data.copy()\n",
    "                data_random = data.copy()\n",
    "\n",
    "                N_z_mask = torch.tensor(np.array([rng.binomial(1, P, size = num_fragment_atoms) for _ in range(PARALLEL_STEPS)]), dtype=torch.int32)\n",
    "                # Ensure at least one element is 1, otherwise randomly select one since at least one fragment atom must be present\n",
    "                # print(N_z_mask)\n",
    "                \n",
    "                \n",
    "                for i in range(len(N_z_mask)):\n",
    "                    # print(mask.shape)\n",
    "                    \n",
    "                    if not N_z_mask[i].any():\n",
    "                        \n",
    "                        print(\"Zero elements in mask, randomly selecting one.\")\n",
    "                        random_index = rng.integers(0, num_fragment_atoms)\n",
    "                        N_z_mask[i][random_index] = 1\n",
    "                       \n",
    "                \n",
    "                N_z_mask=N_z_mask.flatten().to(args.device)\n",
    "                \n",
    "                \n",
    "                # print(\"N_z_mask for sample\", sampled, step, N_z_mask)\n",
    "\n",
    "                N_mask = torch.ones(PARALLEL_STEPS * num_fragment_atoms, dtype=torch.int32, device=args.device)\n",
    "\n",
    "                pi = torch.cat([torch.randperm(num_fragment_atoms, generator=rng_torch) for _ in range(PARALLEL_STEPS)], dim=0)\n",
    "\n",
    "                N_j_plus_index = torch.ones(PARALLEL_STEPS*num_fragment_atoms, dtype=torch.int, device=args.device)\n",
    "                N_j_minus_index = torch.ones(PARALLEL_STEPS*num_fragment_atoms, dtype=torch.int, device=args.device)\n",
    "\n",
    "                selected_node_index = np.where(pi == j)\n",
    "                selected_node_index = torch.tensor(np.array(selected_node_index), device=args.device).squeeze()\n",
    "                selected_node_index = selected_node_index.repeat_interleave(num_fragment_atoms) #@mastro TO BE CHECKED IF THIS IS CORRECT\n",
    "                # print(\"Selected node index\", selected_node_index)\n",
    "                k_values = torch.arange(num_fragment_atoms*PARALLEL_STEPS, device=args.device)\n",
    "\n",
    "                add_to_pi = torch.arange(start=0, end=PARALLEL_STEPS*num_fragment_atoms, step=num_fragment_atoms).repeat_interleave(num_fragment_atoms) #check if it is correct ot consider num_fragment_atoms and not num_atoms\n",
    "\n",
    "                pi_add = pi + add_to_pi\n",
    "                pi_add = pi_add.to(device=args.device)\n",
    "                #this must be cafeully checked. this should be adapted for nodes\n",
    "                add_to_node_index = torch.arange(start=0, end=PARALLEL_STEPS*num_atoms, step=num_atoms) #@mastro change step from num_fragment_atoms to num_atoms\n",
    "                \n",
    "                add_to_node_index = add_to_node_index.repeat_interleave(num_fragment_atoms).to(args.device) #changed from num_atoms to num_fragment_atoms\n",
    "\n",
    "                \n",
    "                # print(\"Selected node index\", selected_node_index)\n",
    "                # add_to_node_index = add_to_node_index.repeat(2,1).to(args.device) #this is probalby not needed with nodes, to be checked\n",
    "\n",
    "                \n",
    "                \n",
    "                N_j_plus_index[pi_add] = torch.where(k_values <= selected_node_index, N_mask[pi_add], N_z_mask[pi_add])\n",
    "                N_j_minus_index[pi_add] = torch.where(k_values < selected_node_index, N_mask[pi_add], N_z_mask[pi_add]) \n",
    "\n",
    "                # if torch.all(N_j_plus_index == N_j_minus_index):\n",
    "                #     print(\"N_j_plus_index and N_j_minus_index are the same\")\n",
    "                # else:\n",
    "                #     print(\"N_j_plus_index and N_j_minus_index are different\")\n",
    "\n",
    "                # retained_indices_plus = torch.nonzero(N_j_plus_index).flatten()\n",
    "                # retained_indices_minus = torch.nonzero(N_j_minus_index).flatten()\n",
    "                # print(\"Retained indices plus\", retained_indices_plus)\n",
    "                # print(\"Retained indices minus\", retained_indices_minus)\n",
    "                #this must be debugged\n",
    "                # N_j_plus = torch.index_select(fragment_indices + add_to_node_index, 0, index = retained_indices_plus) #fragements to keep in molecule j plus\n",
    "                fragment_indices = fragment_indices + add_to_node_index\n",
    "                \n",
    "                \n",
    "                N_j_plus = fragment_indices[(N_j_plus_index==1)] #fragement to keep in molecule j plus\n",
    "                # print(\"N_j_plus\", N_j_plus)\n",
    "                # print(\"N_j_plus shape\", N_j_plus.shape)\n",
    "                \n",
    "                # N_j_minus = torch.index_select(fragment_indices +  add_to_node_index, 0, index = retained_indices_minus) #fragement indices to keep in molecule j minus\n",
    "                # N_j_minus = fragment_indices[N_j_minus_index] #fragement indices to keep in molecule j minus\n",
    "               \n",
    "                N_j_minus = fragment_indices[(N_j_minus_index==1)] #it is ok. it contains fragmens indices to keep in molecule j minus (indices that index the atom nodes)\n",
    "\n",
    "                # print(\"N_j_plus_index\", N_j_plus_index)\n",
    "                # print(\"N_j_minus_index\", N_j_minus_index)\n",
    "                # print(torch.all(N_j_plus_index == N_j_minus_index))\n",
    "                # print(\"fragment_indices\", fragment_indices)\n",
    "                # print(\"N_j_plus\", N_j_plus)\n",
    "                # print(\"N_j_minus\", N_j_minus)\n",
    "                # print(\"N_j_plus shape\", N_j_plus.shape)\n",
    "                # print(\"N_j_minus shape\", N_j_minus.shape)\n",
    "                # if torch.all(N_j_plus == N_j_minus):\n",
    "                #     print(\"N_j_plus and N_j_minus are the same\")\n",
    "                # else:\n",
    "                #     print(\"N_j_plus and N_j_minus are different\")\n",
    "                \n",
    "                # N_random_sample = fragment_indices[torch.IntTensor(N_z_mask)] #fragement indices to keep in random molecule\n",
    "                # N_random_sample = torch.index_select(fragment_indices + add_to_node_index, 0, index = N_z_mask) #fragement indices to keep in random molecule\n",
    "                N_random_sample = fragment_indices[(N_z_mask==1)] #fragement indices to keep in random molecule\n",
    "                \n",
    "                \n",
    "                # print(\"N_j_plus\", N_j_plus)\n",
    "                # print(\"N_j_minus\", N_j_minus)\n",
    "                # print(\"N random sample\", N_random_sample)\n",
    "                # print(\"N_j_plus shape\", N_j_plus.shape)\n",
    "                # print(\"N_j_minus shape\", N_j_minus.shape)\n",
    "                # print(\"N random sample shape\", N_random_sample.shape)\n",
    "\n",
    "                atom_mask_j_plus = torch.zeros(num_atoms*PARALLEL_STEPS, dtype=torch.bool)\n",
    "                atom_mask_j_minus = torch.zeros(num_atoms*PARALLEL_STEPS, dtype=torch.bool)\n",
    "                atom_mask_random_molecule = torch.zeros(num_atoms*PARALLEL_STEPS, dtype=torch.bool)\n",
    "\n",
    "                    \n",
    "                atom_mask_j_plus[N_j_plus] = True\n",
    "                \n",
    "                atom_mask_j_minus[N_j_minus] = True\n",
    "\n",
    "                # print(\"Atom mask j plus\", atom_mask_j_plus)\n",
    "                # print(\"Atom mask j minus\", atom_mask_j_minus)\n",
    "\n",
    "                #set to true also linker atoms\n",
    "                parallelized_linker_mask = data[\"linker_mask\"][0].squeeze().to(torch.int).repeat(PARALLEL_STEPS)\n",
    "                atom_mask_j_plus[(parallelized_linker_mask == 1)] = True #COMMENTED FOR DEBUGGING\n",
    "                # atom_mask_j_plus = atom_mask_j_plus.repeat(PARALLEL_STEPS, 1) ##@mastro TO BE CHECKED\n",
    "\n",
    "                \n",
    "                #set to true also linker atoms\n",
    "                atom_mask_j_minus[(parallelized_linker_mask == 1)] = True #COMMENTED FOR DEBUGGING\n",
    "\n",
    "                # atom_mask_j_minus = atom_mask_j_minus.repeat(PARALLEL_STEPS, 1) ##@mastro TO BE CHECKED\n",
    "\n",
    "                atom_mask_random_molecule[N_random_sample] = True\n",
    "                #set to true also linker atoms\n",
    "                atom_mask_random_molecule[(parallelized_linker_mask == 1)] = True\n",
    "                # atom_mask_random_molecule = atom_mask_random_molecule.repeat(PARALLEL_STEPS, 1) ##@mastro TO BE CHECKED\n",
    "                # print(\"Atom mask j plus\", atom_mask_j_plus)\n",
    "                # print(\"Atom mask j minus\", atom_mask_j_minus)\n",
    "                # print(\"Atom mask random molecule\", atom_mask_random_molecule)\n",
    "                # print(\"Atom mask j plus shape\", atom_mask_j_plus.shape)\n",
    "                # print(\"Atom mask j minus shape\", atom_mask_j_minus.shape)\n",
    "                # print(\"Atom mask random molecule shape\", atom_mask_random_molecule.shape)\n",
    "                # print(\"parallelized_linker_mask\", parallelized_linker_mask)\n",
    "                # print(\"parallelized_linker_mask shape\", parallelized_linker_mask.shape)\n",
    "                \n",
    "                # if torch.all(atom_mask_j_plus == atom_mask_j_minus):\n",
    "                #     print(\"atom_mask_j_plus and atom_mask_j_minus are the same\")\n",
    "                # else:\n",
    "                #     print(\"atom_mask_j_plus and atom_mask_j_minus are different\")\n",
    "                \n",
    "                # print(\"All SEEMS fine up to here\")\n",
    "                #for sample containing j\n",
    "                #remove positions of atoms in random_indices\n",
    "\n",
    "                atom_mask_j_plus = atom_mask_j_plus.view(PARALLEL_STEPS, num_atoms)\n",
    "                \n",
    "                atom_mask_j_minus = atom_mask_j_minus.view(PARALLEL_STEPS, num_atoms)\n",
    "                atom_mask_random_molecule = atom_mask_random_molecule.view(PARALLEL_STEPS, num_atoms)\n",
    "                \n",
    "                # print(\"Atom mask j plus\", atom_mask_j_plus)\n",
    "                # print(\"Atom mask j plus shape\", atom_mask_j_plus.shape)\n",
    "                data_j_plus_dict = {}\n",
    "                data_j_minus_dict = {}\n",
    "                data_random_dict = {}\n",
    "\n",
    "                for i in range(PARALLEL_STEPS):\n",
    "                    data_j_plus_dict[i] = data.copy()\n",
    "                    data_j_minus_dict[i] = data.copy()\n",
    "                    data_random_dict[i] = data.copy()\n",
    "\n",
    "                    #data j plus\n",
    "                    data_j_plus_dict[i][\"positions\"] = data_j_plus_dict[i][\"positions\"][:, atom_mask_j_plus[i]]\n",
    "                    data_j_plus_dict[i][\"num_atoms\"] = data_j_plus_dict[i][\"positions\"].shape[1]\n",
    "                    # remove one_hot of atoms in random_indices\n",
    "                    data_j_plus_dict[i][\"one_hot\"] = data_j_plus_dict[i][\"one_hot\"][:, atom_mask_j_plus[i]]\n",
    "                    # remove atom_mask of atoms in random_indices\n",
    "                    data_j_plus_dict[i][\"atom_mask\"] = data_j_plus_dict[i][\"atom_mask\"][:, atom_mask_j_plus[i]]\n",
    "                    # remove fragment_mask of atoms in random_indices\n",
    "                    data_j_plus_dict[i][\"fragment_mask\"] = data_j_plus_dict[i][\"fragment_mask\"][:, atom_mask_j_plus[i]]\n",
    "                    # remove linker_mask of atoms in random_indices\n",
    "                    data_j_plus_dict[i][\"linker_mask\"] = data_j_plus_dict[i][\"linker_mask\"][:, atom_mask_j_plus[i]]\n",
    "                    data_j_plus_dict[i][\"charges\"] = data_j_plus_dict[i][\"charges\"][:, atom_mask_j_plus[i]]\n",
    "                    data_j_plus_dict[i][\"anchors\"] = data_j_plus_dict[i][\"anchors\"][:, atom_mask_j_plus[i]]\n",
    "                    # remove edge_mask of atoms in random_indices\n",
    "                    # print(\"Shape of edge_mask:\", data_j_plus_dict[i][\"edge_mask\"].shape)\n",
    "                    # print(\"Shape of atom_mask_j_plus[i]:\", atom_mask_j_plus[i].shape)\n",
    "                    # print(\"Shape of atom_mask_j_plus[i].unsqueeze(1):\", atom_mask_j_plus[i].unsqueeze(1).shape)\n",
    "                    # print(\"Shape of atom_mask_j_plus[i].unsqueeze(1) * atom_mask_j_plus[i]:\", (atom_mask_j_plus[i].unsqueeze(1) * atom_mask_j_plus[i]).shape)\n",
    "                    \n",
    "                    edge_mask_to_keep = (atom_mask_j_plus[i].unsqueeze(1) * atom_mask_j_plus[i]).flatten()\n",
    "\n",
    "                    # print(\"Edge mask to keep shape:\", edge_mask_to_keep.shape)\n",
    "                    data_j_plus_dict[i][\"edge_mask\"] = data_j_plus_dict[i][\"edge_mask\"][edge_mask_to_keep]\n",
    "\n",
    "                    # for index in N_j_plus:\n",
    "                    #     for j in range(num_atoms):\n",
    "                    #         data_j_plus_dict[i][\"edge_mask\"][index * num_atoms + j] = 0\n",
    "                    #         data_j_plus_dict[i][\"edge_mask\"][j * num_atoms + index] = 0\n",
    "                    # data_j_plus_dict[i][\"edge_mask\"] = data_j_plus_dict[i][\"edge_mask\"][data_j_plus_dict[i][\"edge_mask\"] != 0]\n",
    "\n",
    "                    #data j minus\n",
    "                    data_j_minus_dict[i][\"positions\"] = data_j_minus_dict[i][\"positions\"][:, atom_mask_j_minus[i]]\n",
    "                    data_j_minus_dict[i][\"num_atoms\"] = data_j_minus_dict[i][\"positions\"].shape[1]\n",
    "                    # remove one_hot of atoms in random_indices\n",
    "                    data_j_minus_dict[i][\"one_hot\"] = data_j_minus_dict[i][\"one_hot\"][:, atom_mask_j_minus[i]]\n",
    "                    # remove atom_mask of atoms in random_indices\n",
    "                    data_j_minus_dict[i][\"atom_mask\"] = data_j_minus_dict[i][\"atom_mask\"][:, atom_mask_j_minus[i]]\n",
    "                    # remove fragment_mask of atoms in random_indices\n",
    "                    data_j_minus_dict[i][\"fragment_mask\"] = data_j_minus_dict[i][\"fragment_mask\"][:, atom_mask_j_minus[i]]\n",
    "                    # remove linker_mask of atoms in random_indices\n",
    "                    data_j_minus_dict[i][\"linker_mask\"] = data_j_minus_dict[i][\"linker_mask\"][:, atom_mask_j_minus[i]]\n",
    "                    data_j_minus_dict[i][\"charges\"] = data_j_minus_dict[i][\"charges\"][:, atom_mask_j_minus[i]]\n",
    "                    data_j_minus_dict[i][\"anchors\"] = data_j_minus_dict[i][\"anchors\"][:, atom_mask_j_minus[i]]\n",
    "                    # remove edge_mask of atoms in random_indices\n",
    "                    edge_mask_to_keep = (atom_mask_j_minus[i].unsqueeze(1) * atom_mask_j_minus[i]).flatten() \n",
    "                    data_j_minus_dict[i][\"edge_mask\"] = data_j_minus_dict[i][\"edge_mask\"][edge_mask_to_keep]\n",
    "\n",
    "                    #data random\n",
    "                    data_random_dict[i][\"positions\"] = data_random_dict[i][\"positions\"][:, atom_mask_random_molecule[i]]\n",
    "                    data_random_dict[i][\"num_atoms\"] = data_random_dict[i][\"positions\"].shape[1]\n",
    "                    # remove one_hot of atoms in random_indices\n",
    "                    data_random_dict[i][\"one_hot\"] = data_random_dict[i][\"one_hot\"][:, atom_mask_random_molecule[i]]\n",
    "                    # remove atom_mask of atoms in random_indices\n",
    "                    data_random_dict[i][\"atom_mask\"] = data_random_dict[i][\"atom_mask\"][:, atom_mask_random_molecule[i]]\n",
    "                    # remove fragment_mask of atoms in random_indices\n",
    "                    data_random_dict[i][\"fragment_mask\"] = data_random_dict[i][\"fragment_mask\"][:, atom_mask_random_molecule[i]]\n",
    "                    # remove linker_mask of atoms in random_indices\n",
    "                    data_random_dict[i][\"linker_mask\"] = data_random_dict[i][\"linker_mask\"][:, atom_mask_random_molecule[i]]\n",
    "                    data_random_dict[i][\"charges\"] = data_random_dict[i][\"charges\"][:, atom_mask_random_molecule[i]]\n",
    "                    data_random_dict[i][\"anchors\"] = data_random_dict[i][\"anchors\"][:, atom_mask_random_molecule[i]]\n",
    "                    # remove edge_mask of atoms in random_indices\n",
    "                    # remove edge_mask of atoms in random_indices\n",
    "                    edge_mask_to_keep = (atom_mask_random_molecule[i].unsqueeze(1) * atom_mask_random_molecule[i]).flatten() \n",
    "\n",
    "                    data_random_dict[i][\"edge_mask\"] = data_random_dict[i][\"edge_mask\"][edge_mask_to_keep]\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                # print(\"DEBUG UP TO HERE\")\n",
    "                # sys.exit()\n",
    "                # print(\"After removal j plus:\", data_j_plus[\"positions\"])\n",
    "                # print(data_j_plus[\"positions\"].shape)\n",
    "                \n",
    "                #generation step\n",
    "\n",
    "                \n",
    "\n",
    "                # print(\"Max atoms j plus\", max_atoms_j_plus)\n",
    "                # print(\"Max atoms j minus\", max_atoms_j_minus)\n",
    "                # print(\"Max atoms random\", max_atoms_random)\n",
    "                \n",
    "                \n",
    "                PADDING = True\n",
    "            \n",
    "                if PADDING:\n",
    "\n",
    "                    max_atoms_j_plus = max(data_j_plus_dict[i][\"num_atoms\"] for i in range(PARALLEL_STEPS))\n",
    "\n",
    "                    max_edges_j_plus = max(data_j_plus_dict[i][\"edge_mask\"].shape[0] for i in range(PARALLEL_STEPS))\n",
    "                    \n",
    "                    \n",
    "                    max_atoms_j_minus = max(data_j_minus_dict[i][\"num_atoms\"] for i in range(PARALLEL_STEPS))\n",
    "\n",
    "                    max_edges_j_minus = max(data_j_minus_dict[i][\"edge_mask\"].shape[0] for i in range(PARALLEL_STEPS))\n",
    "\n",
    "                    max_atoms_random = max(data_random_dict[i][\"num_atoms\"] for i in range(PARALLEL_STEPS))\n",
    "\n",
    "                    max_edges_random = max(data_random_dict[i][\"edge_mask\"].shape[0] for i in range(PARALLEL_STEPS))\n",
    "                    \n",
    "                    for i in range(PARALLEL_STEPS):\n",
    "                        #for j plus positions\n",
    "                        num_atoms_to_stack = max_atoms_j_plus - data_j_plus_dict[i][\"positions\"].shape[1]\n",
    "                        padding = torch.zeros(data_j_plus_dict[i][\"positions\"].shape[0], num_atoms_to_stack, data_j_plus_dict[i][\"positions\"].shape[2]).to(args.device)\n",
    "                        stacked_positions = torch.cat((data_j_plus_dict[i][\"positions\"], padding), dim=1)\n",
    "                        data_j_plus_dict[i][\"positions\"] = stacked_positions\n",
    "                        # print(\"Shape of positions after stacking:\", data_j_plus_dict[i][\"positions\"].shape)\n",
    "                        # print(\"Positions after stacking:\", data_j_plus_dict[i][\"positions\"])\n",
    "                        #for j plus one_hot\n",
    "                        padding = torch.zeros(data_j_plus_dict[i][\"one_hot\"].shape[0], num_atoms_to_stack, data_j_plus_dict[i][\"one_hot\"].shape[2]).to(args.device)\n",
    "                        stacked_one_hot = torch.cat((data_j_plus_dict[i][\"one_hot\"], padding), dim=1)\n",
    "                        data_j_plus_dict[i][\"one_hot\"] = stacked_one_hot\n",
    "                        # print(\"Shape of one_hot after stacking:\", data_j_plus_dict[i][\"one_hot\"].shape)\n",
    "                        # print(\"One_hot after stacking:\", data_j_plus_dict[i][\"one_hot\"])\n",
    "                        #for j plus fragment_mask\n",
    "                        padding = torch.zeros(data_j_plus_dict[i][\"fragment_mask\"].shape[0], num_atoms_to_stack, data_j_plus_dict[i][\"fragment_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_fragment_mask = torch.cat((data_j_plus_dict[i][\"fragment_mask\"], padding), dim=1)\n",
    "                        data_j_plus_dict[i][\"fragment_mask\"] = stacked_fragment_mask\n",
    "\n",
    "                        #for j plus charges\n",
    "                        padding = torch.zeros(data_j_plus_dict[i][\"charges\"].shape[0], num_atoms_to_stack, data_j_plus_dict[i][\"charges\"].shape[2]).to(args.device)\n",
    "                        stacked_charges = torch.cat((data_j_plus_dict[i][\"charges\"], padding), dim=1)\n",
    "                        data_j_plus_dict[i][\"charges\"] = stacked_charges\n",
    "                        # for kj plus anchors\n",
    "                        padding = torch.zeros(data_j_plus_dict[i][\"anchors\"].shape[0], num_atoms_to_stack, data_j_plus_dict[i][\"anchors\"].shape[2]).to(args.device)\n",
    "                        stacked_anchors = torch.cat((data_j_plus_dict[i][\"anchors\"], padding), dim=1)\n",
    "                        data_j_plus_dict[i][\"anchors\"] = stacked_anchors\n",
    "                        # print(\"Shape of fragment_mask after stacking:\", data_j_plus_dict[i][\"fragment_mask\"].shape)\n",
    "                        # print(\"Fragment_mask after stacking:\", data_j_plus_dict[i][\"fragment_mask\"])\n",
    "                        #for j plus linker_mask\n",
    "                        padding = torch.zeros(data_j_plus_dict[i][\"linker_mask\"].shape[0], num_atoms_to_stack, data_j_plus_dict[i][\"linker_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_linker_mask = torch.cat((data_j_plus_dict[i][\"linker_mask\"], padding), dim=1)\n",
    "                        data_j_plus_dict[i][\"linker_mask\"] = stacked_linker_mask\n",
    "                        # print(\"Shape of linker_mask after stacking:\", data_j_plus_dict[i][\"linker_mask\"].shape)\n",
    "                        # print(\"Linker_mask after stacking:\", data_j_plus_dict[i][\"linker_mask\"])\n",
    "                        #for j plus atom_mask\n",
    "                        padding = torch.zeros(data_j_plus_dict[i][\"atom_mask\"].shape[0], num_atoms_to_stack, data_j_plus_dict[i][\"atom_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_atom_mask = torch.cat((data_j_plus_dict[i][\"atom_mask\"], padding), dim=1)\n",
    "                        data_j_plus_dict[i][\"atom_mask\"] = stacked_atom_mask\n",
    "                        # print(\"Shape of atom_mask after stacking:\", data_j_plus_dict[i][\"atom_mask\"].shape)\n",
    "                        # print(\"Atom_mask after stacking:\", data_j_plus_dict[i][\"atom_mask\"])\n",
    "                        #for j plus edge_mask TODO THIS NEEDS TO BE CHECKED\n",
    "                        num_edges_to_stack = max_edges_j_plus - data_j_plus_dict[i][\"edge_mask\"].shape[0]\n",
    "                        data_j_plus_dict[i][\"edge_mask\"] = data_j_plus_dict[i][\"edge_mask\"].unsqueeze(0)\n",
    "                        padding = torch.zeros(data_j_plus_dict[i][\"edge_mask\"].shape[0], num_edges_to_stack, data_j_plus_dict[i][\"edge_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_edge_mask = torch.cat((data_j_plus_dict[i][\"edge_mask\"], padding), dim=1)\n",
    "                        data_j_plus_dict[i][\"edge_mask\"] = stacked_edge_mask\n",
    "                        # print(\"Shape of edge_mask after stacking:\", data_j_plus_dict[i][\"edge_mask\"].shape)\n",
    "                        # print(\"Edge_mask after stacking:\", data_j_plus_dict[i][\"edge_mask\"])\n",
    "                        \n",
    "                        \n",
    "                        #for j minus\n",
    "                        num_atoms_to_stack = max_atoms_j_minus - data_j_minus_dict[i][\"positions\"].shape[1]\n",
    "                        padding = torch.zeros(data_j_minus_dict[i][\"positions\"].shape[0], num_atoms_to_stack, data_j_minus_dict[i][\"positions\"].shape[2]).to(args.device) #why does this work?\n",
    "                        stacked_positions = torch.cat((data_j_minus_dict[i][\"positions\"], padding), dim=1)\n",
    "                        data_j_minus_dict[i][\"positions\"] = stacked_positions\n",
    "                        # print(\"Shape of positions after stacking:\", data_j_minus_dict[i][\"positions\"].shape)\n",
    "                        # print(\"Positions after stacking:\", data_j_minus_dict[i][\"positions\"])\n",
    "                        #for j minus one_hot\n",
    "                        padding = torch.zeros(data_j_minus_dict[i][\"one_hot\"].shape[0], num_atoms_to_stack, data_j_minus_dict[i][\"one_hot\"].shape[2]).to(args.device)\n",
    "                        stacked_one_hot = torch.cat((data_j_minus_dict[i][\"one_hot\"], padding), dim=1)\n",
    "                        data_j_minus_dict[i][\"one_hot\"] = stacked_one_hot\n",
    "                        # print(\"Shape of one_hot after stacking:\", data_j_minus_dict[i][\"one_hot\"].shape)\n",
    "                        # print(\"One_hot after stacking:\", data_j_minus_dict[i][\"one_hot\"])\n",
    "                        #for j minus fragment_mask\n",
    "                        padding = torch.zeros(data_j_minus_dict[i][\"fragment_mask\"].shape[0], num_atoms_to_stack, data_j_minus_dict[i][\"fragment_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_fragment_mask = torch.cat((data_j_minus_dict[i][\"fragment_mask\"], padding), dim=1)\n",
    "                        data_j_minus_dict[i][\"fragment_mask\"] = stacked_fragment_mask\n",
    "\n",
    "                        #for j minus charges\n",
    "                        padding = torch.zeros(data_j_minus_dict[i][\"charges\"].shape[0], num_atoms_to_stack, data_j_minus_dict[i][\"charges\"].shape[2]).to(args.device)\n",
    "                        stacked_charges = torch.cat((data_j_minus_dict[i][\"charges\"], padding), dim=1)\n",
    "                        data_j_minus_dict[i][\"charges\"] = stacked_charges\n",
    "                        # for kj plus anchors\n",
    "                        padding = torch.zeros(data_j_minus_dict[i][\"anchors\"].shape[0], num_atoms_to_stack, data_j_minus_dict[i][\"anchors\"].shape[2]).to(args.device)\n",
    "                        stacked_anchors = torch.cat((data_j_minus_dict[i][\"anchors\"], padding), dim=1)\n",
    "                        data_j_minus_dict[i][\"anchors\"] = stacked_anchors\n",
    "                        # print(\"Shape of fragment_mask after stacking:\", data_j_minus_dict[i][\"fragment_mask\"].shape)\n",
    "                        # print(\"Fragment_mask after stacking:\", data_j_minus_dict[i][\"fragment_mask\"])\n",
    "                        #for j minus linker_mask\n",
    "                        padding = torch.zeros(data_j_minus_dict[i][\"linker_mask\"].shape[0], num_atoms_to_stack, data_j_minus_dict[i][\"linker_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_linker_mask = torch.cat((data_j_minus_dict[i][\"linker_mask\"], padding), dim=1)\n",
    "                        data_j_minus_dict[i][\"linker_mask\"] = stacked_linker_mask\n",
    "                        # print(\"Shape of linker_mask after stacking:\", data_j_minus_dict[i][\"linker_mask\"].shape)\n",
    "                        # print(\"Linker_mask after stacking:\", data_j_minus_dict[i][\"linker_mask\"])\n",
    "                        #for j minus atom_mask\n",
    "                        padding = torch.zeros(data_j_minus_dict[i][\"atom_mask\"].shape[0], num_atoms_to_stack, data_j_minus_dict[i][\"atom_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_atom_mask = torch.cat((data_j_minus_dict[i][\"atom_mask\"], padding), dim=1)\n",
    "                        data_j_minus_dict[i][\"atom_mask\"] = stacked_atom_mask\n",
    "                        # print(\"Shape of atom_mask after stacking:\", data_j_minus_dict[i][\"atom_mask\"].shape)\n",
    "                        # print(\"Atom_mask after stacking:\", data_j_minus_dict[i][\"atom_mask\"])\n",
    "                        #for j minus edge_mask\n",
    "                        num_edges_to_stack = max_edges_j_minus - data_j_minus_dict[i][\"edge_mask\"].shape[0]\n",
    "                        data_j_minus_dict[i][\"edge_mask\"] = data_j_minus_dict[i][\"edge_mask\"].unsqueeze(0)\n",
    "                        padding = torch.zeros(data_j_minus_dict[i][\"edge_mask\"].shape[0], num_edges_to_stack, data_j_minus_dict[i][\"edge_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_edge_mask = torch.cat((data_j_minus_dict[i][\"edge_mask\"], padding), dim=1)\n",
    "                        data_j_minus_dict[i][\"edge_mask\"] = stacked_edge_mask\n",
    "                        # print(\"Shape of edge_mask after stacking:\", data_j_minus_dict[i][\"edge_mask\"].shape)\n",
    "                        # print(\"Edge_mask after stacking:\", data_j_minus_dict[i][\"edge_mask\"])\n",
    "\n",
    "                        #for random\n",
    "                        num_atoms_to_stack = max_atoms_random - data_random_dict[i][\"positions\"].shape[1]\n",
    "                        padding = torch.zeros(data_random_dict[i][\"positions\"].shape[0], num_atoms_to_stack, data_random_dict[i][\"positions\"].shape[2]).to(args.device)\n",
    "                        stacked_positions = torch.cat((data_random_dict[i][\"positions\"], padding), dim=1)\n",
    "                        data_random_dict[i][\"positions\"] = stacked_positions\n",
    "                        # print(\"Shape of positions after stacking:\", data_random_dict[i][\"positions\"].shape)\n",
    "                        # print(\"Positions after stacking:\", data_random_dict[i][\"positions\"])\n",
    "                        #for random one_hot\n",
    "                        padding = torch.zeros(data_random_dict[i][\"one_hot\"].shape[0], num_atoms_to_stack, data_random_dict[i][\"one_hot\"].shape[2]).to(args.device)\n",
    "                        stacked_one_hot = torch.cat((data_random_dict[i][\"one_hot\"], padding), dim=1)\n",
    "                        data_random_dict[i][\"one_hot\"] = stacked_one_hot\n",
    "                        # print(\"Shape of one_hot after stacking:\", data_random_dict[i][\"one_hot\"].shape)\n",
    "                        # print(\"One_hot after stacking:\", data_random_dict[i][\"one_hot\"])\n",
    "                        #for random fragment_mask\n",
    "                        padding = torch.zeros(data_random_dict[i][\"fragment_mask\"].shape[0], num_atoms_to_stack, data_random_dict[i][\"fragment_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_fragment_mask = torch.cat((data_random_dict[i][\"fragment_mask\"], padding), dim=1)\n",
    "                        data_random_dict[i][\"fragment_mask\"] = stacked_fragment_mask\n",
    "                        # print(\"Shape of fragment_mask after stacking:\", data_random_dict[i][\"fragment_mask\"].shape)\n",
    "                        # print(\"Fragment_mask after stacking:\", data_random_dict[i][\"fragment_mask\"])\n",
    "                        #for random linker_mask\n",
    "                        padding = torch.zeros(data_random_dict[i][\"linker_mask\"].shape[0], num_atoms_to_stack, data_random_dict[i][\"linker_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_linker_mask = torch.cat((data_random_dict[i][\"linker_mask\"], padding), dim=1)\n",
    "                        data_random_dict[i][\"linker_mask\"] = stacked_linker_mask\n",
    "\n",
    "                        #for random charges\n",
    "                        padding = torch.zeros(data_random_dict[i][\"charges\"].shape[0], num_atoms_to_stack, data_random_dict[i][\"charges\"].shape[2]).to(args.device)\n",
    "                        stacked_charges = torch.cat((data_random_dict[i][\"charges\"], padding), dim=1)\n",
    "                        data_random_dict[i][\"charges\"] = stacked_charges\n",
    "\n",
    "                        #for random anchors\n",
    "                        padding = torch.zeros(data_random_dict[i][\"anchors\"].shape[0], num_atoms_to_stack, data_random_dict[i][\"anchors\"].shape[2]).to(args.device)\n",
    "                        stacked_anchors = torch.cat((data_random_dict[i][\"anchors\"], padding), dim=1)\n",
    "                        data_random_dict[i][\"anchors\"] = stacked_anchors\n",
    "                        # print(\"Shape of linker_mask after stacking:\", data_random_dict[i][\"linker_mask\"].shape)\n",
    "                        # print(\"Linker_mask after stacking:\", data_random_dict[i][\"linker_mask\"])\n",
    "                        #for random atom_mask\n",
    "                        padding = torch.zeros(data_random_dict[i][\"atom_mask\"].shape[0], num_atoms_to_stack, data_random_dict[i][\"atom_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_atom_mask = torch.cat((data_random_dict[i][\"atom_mask\"], padding), dim=1)\n",
    "                        data_random_dict[i][\"atom_mask\"] = stacked_atom_mask\n",
    "                        # print(\"Shape of atom_mask after stacking:\", data_random_dict[i][\"atom_mask\"].shape)\n",
    "                        # print(\"Atom_mask after stacking:\", data_random_dict[i][\"atom_mask\"])\n",
    "                        #for random edge_mask\n",
    "                        num_edges_to_stack = max_edges_random - data_random_dict[i][\"edge_mask\"].shape[0]\n",
    "                        data_random_dict[i][\"edge_mask\"] = data_random_dict[i][\"edge_mask\"].unsqueeze(0)\n",
    "                        padding = torch.zeros(data_random_dict[i][\"edge_mask\"].shape[0], num_edges_to_stack, data_random_dict[i][\"edge_mask\"].shape[2]).to(args.device)\n",
    "                        stacked_edge_mask = torch.cat((data_random_dict[i][\"edge_mask\"], padding), dim=1)\n",
    "                        data_random_dict[i][\"edge_mask\"] = stacked_edge_mask\n",
    "                        # print(\"Shape of edge_mask after stacking:\", data_random_dict[i][\"edge_mask\"].shape)\n",
    "                        # print(\"Edge_mask after stacking:\", data_random_dict[i][\"edge_mask\"])\n",
    "\n",
    "                \n",
    "                #create batch for j plus\n",
    "                data_j_plus_batch = {}\n",
    "                data_j_plus_batch[\"positions\"] = torch.stack([data_j_plus_dict[i][\"positions\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze()\n",
    "                data_j_plus_batch[\"one_hot\"] = torch.stack([data_j_plus_dict[i][\"one_hot\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_plus_batch[\"atom_mask\"] = torch.stack([data_j_plus_dict[i][\"atom_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_plus_batch[\"fragment_mask\"] = torch.stack([data_j_plus_dict[i][\"fragment_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_plus_batch[\"linker_mask\"] = torch.stack([data_j_plus_dict[i][\"linker_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_plus_batch[\"charges\"] = torch.stack([data_j_plus_dict[i][\"charges\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_plus_batch[\"anchors\"] = torch.stack([data_j_plus_dict[i][\"anchors\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                # data_j_plus_batch[\"edge_mask\"] = torch.stack([data_j_plus_dict[i][\"edge_mask\"] for i in range(PARALLEL_STEPS)], dim=0)\n",
    "                \n",
    "                data_j_plus_batch[\"uuid\"] = [i for i in range(PARALLEL_STEPS)]\n",
    "                data_j_plus_batch[\"num_atoms\"] = [data_j_plus_dict[i][\"num_atoms\"] for i in range(PARALLEL_STEPS)]\n",
    "                data_j_plus_batch[\"name\"] = [data[\"name\"] for _ in range(PARALLEL_STEPS)]\n",
    "                data_j_plus_batch[\"edge_mask\"] = torch.cat([data_j_plus_dict[i][\"edge_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze().view(-1).unsqueeze(1)\n",
    "\n",
    "\n",
    "                #create batch for j minus\n",
    "                data_j_minus_batch = {}\n",
    "                data_j_minus_batch[\"positions\"] = torch.stack([data_j_minus_dict[i][\"positions\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze()\n",
    "                data_j_minus_batch[\"one_hot\"] = torch.stack([data_j_minus_dict[i][\"one_hot\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_minus_batch[\"atom_mask\"] = torch.stack([data_j_minus_dict[i][\"atom_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_minus_batch[\"fragment_mask\"] = torch.stack([data_j_minus_dict[i][\"fragment_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_minus_batch[\"linker_mask\"] = torch.stack([data_j_minus_dict[i][\"linker_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_minus_batch[\"charges\"] = torch.stack([data_j_minus_dict[i][\"charges\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_j_minus_batch[\"anchors\"] = torch.stack([data_j_minus_dict[i][\"anchors\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                # data_j_minus_batch[\"edge_mask\"] = torch.stack([data_j_minus_dict[i][\"edge_mask\"] for i in range(PARALLEL_STEPS)], dim=0)\n",
    "                data_j_minus_batch[\"uuid\"] = [i for i in range(PARALLEL_STEPS)]\n",
    "                data_j_minus_batch[\"num_atoms\"] = [data_j_minus_dict[i][\"num_atoms\"] for i in range(PARALLEL_STEPS)]\n",
    "                data_j_minus_batch[\"name\"] = [data[\"name\"] for _ in range(PARALLEL_STEPS)]\n",
    "                data_j_minus_batch[\"edge_mask\"] = torch.cat([data_j_minus_dict[i][\"edge_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze().view(-1).unsqueeze(1)\n",
    "\n",
    "                #create batch for random\n",
    "                data_random_batch = {}\n",
    "                data_random_batch[\"positions\"] = torch.stack([data_random_dict[i][\"positions\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze()\n",
    "                data_random_batch[\"one_hot\"] = torch.stack([data_random_dict[i][\"one_hot\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_random_batch[\"atom_mask\"] = torch.stack([data_random_dict[i][\"atom_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_random_batch[\"fragment_mask\"] = torch.stack([data_random_dict[i][\"fragment_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_random_batch[\"linker_mask\"] = torch.stack([data_random_dict[i][\"linker_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_random_batch[\"charges\"] = torch.stack([data_random_dict[i][\"charges\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                data_random_batch[\"anchors\"] = torch.stack([data_random_dict[i][\"anchors\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze(1)\n",
    "                # data_random_batch[\"edge_mask\"] = torch.stack([data_random_dict[i][\"edge_mask\"] for i in range(PARALLEL_STEPS)], dim=0)\n",
    "                data_random_batch[\"uuid\"] = [i for i in range(PARALLEL_STEPS)]\n",
    "                data_random_batch[\"num_atoms\"] = [data_random_dict[i][\"num_atoms\"] for i in range(PARALLEL_STEPS)]\n",
    "                data_random_batch[\"name\"] = [data[\"name\"] for _ in range(PARALLEL_STEPS)]\n",
    "                data_random_batch[\"edge_mask\"] = torch.cat([data_random_dict[i][\"edge_mask\"] for i in range(PARALLEL_STEPS)], dim=0).squeeze().view(-1).unsqueeze(1)\n",
    "\n",
    "\n",
    "                #trying the new data batch\n",
    "                chain_j_plus_batch, node_mask_j_plus_batch = model.sample_chain(data_j_plus_batch, keep_frames=args.keep_frames)\n",
    "\n",
    "                chain_j_plus = chain_j_plus_batch[0, :, :, :] #it should take the first frame and all batch elements -> check it is really the first frame (I need the one at t0, the final generated molecule)\n",
    "                \n",
    "                chain_j_minus_batch, node_mask_j_minus_batch = model.sample_chain(data_j_minus_batch, keep_frames=args.keep_frames)\n",
    "\n",
    "                chain_j_minus = chain_j_minus_batch[0, :, :, :] \n",
    "\n",
    "                chain_random_batch, node_mask_random_batch = model.sample_chain(data_random_batch, keep_frames=args.keep_frames)\n",
    "\n",
    "                chain_random = chain_random_batch[0, :, :, :]\n",
    "                \n",
    "                \n",
    "                #with node j\n",
    "                # chain_j_plus, node_mask_j_plus = model.sample_chain(data_j_plus, keep_frames=args.keep_frames)\n",
    "                #take only the ts 0 frame\n",
    "                chain_with_full_fragments_batch = chain_with_full_fragments.repeat(PARALLEL_STEPS, 1, 1)\n",
    "\n",
    "                \n",
    "                V_j_plus_distance_batch = compute_molecular_distance_batch(chain_with_full_fragments_batch, chain_j_plus, mask1=original_linker_mask_batch, mask2=data_j_plus_batch[\"linker_mask\"].squeeze())\n",
    "                \n",
    "                \n",
    "                V_j_plus_distance = torch.sum(V_j_plus_distance_batch).item()\n",
    "                # print(\"V j plus distance batch\", V_j_plus_distance_batch)\n",
    "                # print(\"V_j_plus_distance\", V_j_plus_distance)\n",
    "                \n",
    "\n",
    "                V_j_plus_cosine_similarity_batch = compute_cosine_similarity_batch(chain_with_full_fragments_batch.cpu(), chain_j_plus.cpu(), mask1=original_linker_mask_batch.cpu(), mask2=data_j_plus_batch[\"linker_mask\"].squeeze().cpu())\n",
    "\n",
    "                V_j_plus_cosine_similarity = sum(V_j_plus_cosine_similarity_batch)\n",
    "                # print(\"V j plus cosine similarity batch\", V_j_plus_cosine_similarity_batch)\n",
    "                # print(\"V_j_plus_cosine_similarity\", V_j_plus_cosine_similarity)\n",
    "                # print(\"V_j_plus\", V_j_plus)\n",
    "\n",
    "                # #without node j\n",
    "                # chain_j_minus, node_mask_j_minus = model.sample_chain(data_j_minus, keep_frames=args.keep_frames)\n",
    "\n",
    "                # #take only the ts 0 frame\n",
    "                # chain_j_minus = chain_j_minus[0, 0, :, :]\n",
    "\n",
    "                V_j_minus_distance_batch = compute_molecular_distance_batch(chain_with_full_fragments_batch, chain_j_minus, mask1=original_linker_mask_batch, mask2=data_j_minus_batch[\"linker_mask\"].squeeze())\n",
    "\n",
    "                V_j_minus_distance = torch.sum(V_j_minus_distance_batch).item()\n",
    "                # print(\"V j minus distance batch\", V_j_minus_distance_batch)\n",
    "                # print(\"V_j_minus_distance\", V_j_minus_distance)\n",
    "                \n",
    "                V_j_minus_cosine_similarity_batch = compute_cosine_similarity_batch(chain_with_full_fragments_batch.cpu(), chain_j_minus.cpu(), mask1=original_linker_mask_batch.cpu(), mask2=data_j_minus_batch[\"linker_mask\"].squeeze().cpu())\n",
    "\n",
    "                V_j_minus_cosine_similarity = sum(V_j_minus_cosine_similarity_batch)\n",
    "\n",
    "                # print(\"V j minus cosine similarity batch\", V_j_minus_cosine_similarity_batch)\n",
    "                # print(\"V_j_minus_cosine_similarity\", V_j_minus_cosine_similarity)\n",
    "\n",
    "                #with random sample\n",
    "                # chain_random, node_mask_random = model.sample_chain(data_random, keep_frames=args.keep_frames)\n",
    "\n",
    "                # chain_random = chain_random[0, 0, :, :]\n",
    "\n",
    "                V_random_distance_batch = compute_molecular_distance_batch(chain_with_full_fragments_batch, chain_random, mask1=original_linker_mask_batch, mask2=data_random_batch[\"linker_mask\"].squeeze())\n",
    "                \n",
    "                # print(\"V random distance batch\", V_random_distance_batch)\n",
    "                \n",
    "\n",
    "                V_random_cosine_similarity = compute_cosine_similarity_batch(chain_with_full_fragments_batch.cpu(), chain_random.cpu(), mask1=original_linker_mask_batch.cpu(), mask2=data_random_batch[\"linker_mask\"].squeeze().cpu())\n",
    "\n",
    "                for r_dist in V_random_distance_batch:\n",
    "                    distances_random_samples.append(r_dist.item())\n",
    "                \n",
    "                for r_cos in V_random_cosine_similarity:\n",
    "                    cosine_similarities_random_samples.append(r_cos)\n",
    "                \n",
    "\n",
    "                # print(\"Distances random samples\", str(distances_random_samples))\n",
    "                # print(\"Cosine similarities random samples\", str(cosine_similarities_random_samples))\n",
    "                \n",
    "\n",
    "                # print(V_random_distance, V_random_cosine_similarity)\n",
    "                \n",
    "                marginal_contrib_distance += (V_j_plus_distance - V_j_minus_distance)\n",
    "\n",
    "                marginal_contrib_cosine_similarity += (V_j_plus_cosine_similarity - V_j_minus_cosine_similarity)\n",
    "\n",
    "                # marginal_contrib_hausdorff += (V_j_plus_hausdorff - V_j_minus_hausdorff)\n",
    "\n",
    "            phi_atoms[fragment_indices[j].item()] = [0,0] #,0]    \n",
    "            phi_atoms[fragment_indices[j].item()][0] = marginal_contrib_distance/M #j is the index of the fragment atom in the fragment indices tensor\n",
    "            phi_atoms[fragment_indices[j].item()][1] = marginal_contrib_cosine_similarity/M\n",
    "            # phi_atoms[fragment_indices[j]][2] = marginal_contrib_hausdorff/M\n",
    "\n",
    "        print(data[\"name\"])\n",
    "\n",
    "        phi_atoms_distances = {}\n",
    "        phi_atoms_cosine_similarity = {}\n",
    "        for atom_index, phi_values in phi_atoms.items():\n",
    "            phi_atoms_distances[atom_index] = phi_values[0]\n",
    "            phi_atoms_cosine_similarity[atom_index] = phi_values[1]\n",
    "        \n",
    "        # Save phi_atoms to a text file\n",
    "        with open(f'{folder_save_path}/phi_atoms_{sampled}.txt', 'w') as write_file:\n",
    "            write_file.write(\"sample name: \" + str(data[\"name\"]) + \"\\n\")\n",
    "            write_file.write(\"atom_index,distance,cosine_similarity\\n\")\n",
    "            for atom_index, phi_values in phi_atoms.items():\n",
    "                write_file.write(f\"{atom_index},{phi_values[0]},{phi_values[1]}\\n\")\n",
    "\n",
    "            write_file.write(\"\\n\")\n",
    "            # save sum of phi values for disance and cosine similarity\n",
    "            write_file.write(\"Sum of phi values for distance\\n\")\n",
    "            write_file.write(str(sum([p_values[0] for p_values in phi_atoms.values()])) + \"\\n\")\n",
    "            write_file.write(\"Sum of phi values for cosine similarity\\n\")\n",
    "            write_file.write(str(sum([p_values[1] for p_values in phi_atoms.values()])) + \"\\n\")     \n",
    "            write_file.write(\"Average distance random samples:\\n\")\n",
    "            write_file.write(str(sum(distances_random_samples)/len(distances_random_samples)) + \"\\n\")\n",
    "            write_file.write(\"Average cosine similarity random samples:\\n\")\n",
    "            write_file.write(str(sum(cosine_similarities_random_samples)/len(cosine_similarities_random_samples)) + \"\\n\")      \n",
    "            write_file.write(\"Distances random samples\\n\")\n",
    "            write_file.write(str(distances_random_samples) + \"\\n\")\n",
    "            write_file.write(\"Cosines similarity random samples\\n\")\n",
    "            write_file.write(str(cosine_similarities_random_samples) + \"\\n\")\n",
    "\n",
    "        if SAVE_VISUALIZATION:\n",
    "            for i in range(len(data['positions'])):\n",
    "                chain = chain_batch[:, i, :, :]\n",
    "                assert chain.shape[0] == args.keep_frames\n",
    "                assert chain.shape[1] == data['positions'].shape[1]\n",
    "                assert chain.shape[2] == data['positions'].shape[2] + data['one_hot'].shape[2] + model.include_charges\n",
    "\n",
    "                # Saving chains\n",
    "                name = str(i + start)\n",
    "                chain_output = os.path.join(chains_output_dir, name)\n",
    "                os.makedirs(chain_output, exist_ok=True)\n",
    "\n",
    "                one_hot = chain[:, :, 3:-1]\n",
    "                positions = chain[:, :, :3]\n",
    "                chain_node_mask = torch.cat([node_mask[i].unsqueeze(0) for _ in range(args.keep_frames)], dim=0)\n",
    "                names = [f'{name}_{j}' for j in range(args.keep_frames)]\n",
    "\n",
    "                save_xyz_file(chain_output, one_hot, positions, chain_node_mask, names=names, is_geom=model.is_geom)\n",
    "                visualize_chain_xai(\n",
    "                    chain_output,\n",
    "                    spheres_3d=False,\n",
    "                    alpha=0.7,\n",
    "                    bg='white',\n",
    "                    is_geom=model.is_geom,\n",
    "                    fragment_mask=data['fragment_mask'][i].squeeze(),\n",
    "                    phi_values=phi_atoms_distances\n",
    "                )\n",
    "\n",
    "                # Saving final prediction and ground truth separately\n",
    "                true_one_hot = data['one_hot'][i].unsqueeze(0)\n",
    "                true_positions = data['positions'][i].unsqueeze(0)\n",
    "                true_node_mask = data['atom_mask'][i].unsqueeze(0)\n",
    "                save_xyz_file(\n",
    "                    final_states_output_dir,\n",
    "                    true_one_hot,\n",
    "                    true_positions,\n",
    "                    true_node_mask,\n",
    "                    names=[f'{name}_true'],\n",
    "                    is_geom=model.is_geom,\n",
    "                )\n",
    "\n",
    "                pred_one_hot = chain[0, :, 3:-1].unsqueeze(0)\n",
    "                pred_positions = chain[0, :, :3].unsqueeze(0)\n",
    "                pred_node_mask = chain_node_mask[0].unsqueeze(0)\n",
    "                save_xyz_file(\n",
    "                    final_states_output_dir,\n",
    "                    pred_one_hot,\n",
    "                    pred_positions,\n",
    "                    pred_node_mask,\n",
    "                    names=[f'{name}_pred'],\n",
    "                    is_geom=model.is_geom\n",
    "                )\n",
    "\n",
    "            start += len(data['positions'])\n",
    "\n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Shapley value Propeties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapley_values = {0:(-0.18252010345458985,-0.03153111279010773),\n",
    "# 1:(-0.19735857963562012,-0.0004155013896524906),\n",
    "# 2:(0.24352870702743531,0.03291264953091741),\n",
    "# 3:(0.5766246366500855,-0.02155731648206711),\n",
    "# 4:(-0.8824016571044921,-0.02419700352475047),\n",
    "# 5:(0.04895777225494385,-0.02288945931941271),\n",
    "# 6:(-0.11883691549301148,-0.017148097790777684),\n",
    "# 7:(-0.3973711347579956,-0.08772553377784789),\n",
    "# 8:(-1.0809556245803833,0.005452861245721578),\n",
    "# 9:(-0.09876126766204835,-0.04913015581667423),\n",
    "# 10:(-0.9884893560409546,0.11794438790529967),\n",
    "# 11:(-1.126043050289154,0.13286019276827574),\n",
    "# 12:(-1.1925089359283447,-0.07200432924553751),\n",
    "# 13:(-1.183656153678894,0.11058532498776913),\n",
    "# 14:(-1.2386692070960998,0.12144924929365515),\n",
    "# 15:(-0.9519470238685608,0.09354953311383724),\n",
    "# 16:(-1.0259105682373046,0.1189951341226697),\n",
    "# 17:(-0.47114646434783936,-0.006474981680512428),\n",
    "# 18:(-0.516231164932251,0.08100643368437886),\n",
    "# 19:(-1.2924485397338867,0.13028908021748065)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of shapley values for distance -12.076144630908965\n",
      "Sum of shapley values for cosine similarity 0.6119713550526649\n"
     ]
    }
   ],
   "source": [
    "# sum_shapley_values_distance = 0\n",
    "# sum_shapley_values_cosine_similarity = 0\n",
    "\n",
    "# for key, value in shapley_values.items():\n",
    "#     sum_shapley_values_distance += value[0]\n",
    "#     sum_shapley_values_cosine_similarity += value[1]\n",
    "\n",
    "# print(\"Sum of shapley values for distance\", sum_shapley_values_distance)\n",
    "# print(\"Sum of shapley values for cosine similarity\", sum_shapley_values_cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Convert the list to a numpy array\n",
    "# distances_array = np.array(distances_random_graphs)\n",
    "\n",
    "# # Calculate the z-scores for each element in the array\n",
    "# z_scores = (distances_array - np.mean(distances_array)) / np.std(distances_array)\n",
    "\n",
    "# # Define a threshold for outliers (e.g., z-score > 3)\n",
    "# threshold = 0.5\n",
    "\n",
    "# # Create a mask to identify outliers\n",
    "# outlier_mask = np.abs(z_scores) > threshold\n",
    "\n",
    "# # Remove outliers from the array\n",
    "# filtered_distances = distances_array[~outlier_mask]\n",
    "\n",
    "# # Convert the filtered array back to a list\n",
    "# filtered_distances_list = filtered_distances.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.445761892345402"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(filtered_distances_list) / len(filtered_distances_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.90079116821289,\n",
       " 13.994956016540527,\n",
       " 18.59467315673828,\n",
       " 99.57367706298828,\n",
       " 12.549628257751465,\n",
       " 12.131684303283691,\n",
       " 33.354164123535156,\n",
       " 12.624557495117188,\n",
       " 7.622239589691162,\n",
       " 7.140101909637451,\n",
       " 8.129176139831543,\n",
       " 11.115296363830566,\n",
       " 11.150999069213867,\n",
       " 12.553301811218262,\n",
       " 18.150859832763672,\n",
       " 39.439090728759766,\n",
       " 14.725622177124023,\n",
       " 12.986281394958496,\n",
       " 9.173707962036133,\n",
       " 11.731589317321777,\n",
       " 10.623479843139648,\n",
       " 14.190513610839844,\n",
       " 9.719880104064941,\n",
       " 22.595802307128906,\n",
       " 11.12348747253418,\n",
       " 16.891321182250977,\n",
       " 15.867040634155273,\n",
       " 6.8220624923706055,\n",
       " 15.32767391204834,\n",
       " 14.361724853515625,\n",
       " 13.085883140563965,\n",
       " 9.035792350769043,\n",
       " 11.632275581359863,\n",
       " 20.091903686523438,\n",
       " 15.532211303710938,\n",
       " 117.51826477050781,\n",
       " 12.189861297607422,\n",
       " 16.283920288085938,\n",
       " 18.390846252441406,\n",
       " 8.840758323669434,\n",
       " 15.95419692993164,\n",
       " 9.660080909729004,\n",
       " 8.623753547668457,\n",
       " 17.921588897705078,\n",
       " 12.339995384216309,\n",
       " 10.192910194396973,\n",
       " 14.382380485534668,\n",
       " 17.58751678466797,\n",
       " 8.23885440826416,\n",
       " 13.433709144592285,\n",
       " 9.593979835510254,\n",
       " 10.967704772949219,\n",
       " 12.773087501525879,\n",
       " 17.316118240356445,\n",
       " 16.888185501098633,\n",
       " 10.666703224182129,\n",
       " 9.54337215423584,\n",
       " 13.131654739379883,\n",
       " 8.862771987915039,\n",
       " 20.0909423828125,\n",
       " 12.038680076599121,\n",
       " 8.496023178100586,\n",
       " 15.084773063659668,\n",
       " 28.776079177856445,\n",
       " 14.874223709106445,\n",
       " 9.538623809814453,\n",
       " 8.145123481750488,\n",
       " 17.69808006286621,\n",
       " 11.451218605041504,\n",
       " 17.596590042114258,\n",
       " 7.713534832000732,\n",
       " 9.267410278320312,\n",
       " 8.377812385559082,\n",
       " 12.443464279174805,\n",
       " 9.23165225982666,\n",
       " 7.949616432189941,\n",
       " 14.71863079071045,\n",
       " 11.06482982635498,\n",
       " 18.3727970123291,\n",
       " 19.899072647094727,\n",
       " 12.815223693847656,\n",
       " 9.274666786193848,\n",
       " 15.73747444152832,\n",
       " 13.252983093261719,\n",
       " 8.710273742675781,\n",
       " 8.975485801696777,\n",
       " 15.580423355102539,\n",
       " 11.826573371887207,\n",
       " 14.264101028442383,\n",
       " 31.91473960876465,\n",
       " 64.17339324951172,\n",
       " 17.470298767089844,\n",
       " 8.343291282653809,\n",
       " 17.53420066833496,\n",
       " 13.094176292419434,\n",
       " 12.624659538269043,\n",
       " 13.29981517791748,\n",
       " 92.17593383789062,\n",
       " 16.668046951293945,\n",
       " 17.38125991821289,\n",
       " 15.251635551452637,\n",
       " 14.045061111450195,\n",
       " 12.001233100891113,\n",
       " 19.510133743286133,\n",
       " 17.609756469726562,\n",
       " 11.652176856994629,\n",
       " 10.514715194702148,\n",
       " 14.88312816619873,\n",
       " 13.046287536621094,\n",
       " 70.30615234375,\n",
       " 8.78591251373291,\n",
       " 8.672098159790039,\n",
       " 16.624267578125,\n",
       " 11.7927827835083,\n",
       " 10.962799072265625,\n",
       " 10.831814765930176,\n",
       " 8.06410026550293,\n",
       " 9.344090461730957,\n",
       " 10.921401023864746,\n",
       " 13.781452178955078,\n",
       " 13.000008583068848,\n",
       " 13.64437198638916,\n",
       " 14.806971549987793,\n",
       " 64.73077392578125,\n",
       " 17.488983154296875,\n",
       " 10.001614570617676,\n",
       " 13.821581840515137,\n",
       " 9.20461368560791,\n",
       " 18.423873901367188,\n",
       " 11.150386810302734,\n",
       " 13.311408996582031,\n",
       " 8.561570167541504,\n",
       " 69.8349609375,\n",
       " 16.09000587463379,\n",
       " 10.647528648376465,\n",
       " 12.956040382385254,\n",
       " 21.508037567138672,\n",
       " 14.847746849060059,\n",
       " 15.939468383789062,\n",
       " 8.488847732543945,\n",
       " 13.12687873840332,\n",
       " 27.037609100341797,\n",
       " 16.800561904907227,\n",
       " 16.64445686340332,\n",
       " 13.937997817993164,\n",
       " 19.06344223022461,\n",
       " 19.3958797454834,\n",
       " 8.182333946228027,\n",
       " 15.081774711608887,\n",
       " 13.452703475952148,\n",
       " 9.053831100463867,\n",
       " 10.179545402526855,\n",
       " 11.762200355529785,\n",
       " 15.534356117248535,\n",
       " 14.996820449829102,\n",
       " 17.824600219726562,\n",
       " 11.682884216308594,\n",
       " 13.216797828674316,\n",
       " 13.14797306060791,\n",
       " 88.205322265625,\n",
       " 13.995166778564453,\n",
       " 13.644662857055664,\n",
       " 13.231528282165527,\n",
       " 8.826067924499512,\n",
       " 8.81607437133789,\n",
       " 12.175833702087402,\n",
       " 12.967278480529785,\n",
       " 11.300259590148926,\n",
       " 12.155691146850586,\n",
       " 8.25037670135498,\n",
       " 10.764246940612793,\n",
       " 11.88794231414795,\n",
       " 14.512004852294922,\n",
       " 12.95032024383545,\n",
       " 13.645676612854004,\n",
       " 11.74242115020752,\n",
       " 11.460274696350098,\n",
       " 14.68875503540039,\n",
       " 14.583455085754395,\n",
       " 13.928496360778809,\n",
       " 8.401372909545898,\n",
       " 9.419363975524902,\n",
       " 15.985710144042969,\n",
       " 9.360016822814941,\n",
       " 47.873226165771484,\n",
       " 12.506614685058594,\n",
       " 15.970625877380371,\n",
       " 17.951297760009766,\n",
       " 12.506709098815918,\n",
       " 12.172075271606445,\n",
       " 10.580382347106934,\n",
       " 58.27928161621094,\n",
       " 15.034242630004883,\n",
       " 50.50627136230469,\n",
       " 15.334737777709961,\n",
       " 15.018738746643066,\n",
       " 8.316046714782715,\n",
       " 8.562100410461426,\n",
       " 15.030044555664062,\n",
       " 71.23239135742188,\n",
       " 15.056232452392578,\n",
       " 13.78482437133789,\n",
       " 14.468690872192383,\n",
       " 13.743317604064941,\n",
       " 11.187176704406738,\n",
       " 6.418200492858887,\n",
       " 18.091672897338867,\n",
       " 18.416152954101562,\n",
       " 10.001916885375977,\n",
       " 15.015134811401367,\n",
       " 22.67055320739746,\n",
       " 21.574569702148438,\n",
       " 15.522256851196289,\n",
       " 8.886856079101562,\n",
       " 14.800872802734375,\n",
       " 9.598064422607422,\n",
       " 11.920475959777832,\n",
       " 61.655277252197266,\n",
       " 11.745392799377441,\n",
       " 13.361960411071777,\n",
       " 12.651230812072754,\n",
       " 15.173436164855957,\n",
       " 10.20767593383789,\n",
       " 11.558145523071289,\n",
       " 13.817797660827637,\n",
       " 17.00383758544922,\n",
       " 86.9465103149414,\n",
       " 14.227371215820312,\n",
       " 8.502904891967773,\n",
       " 63.643775939941406,\n",
       " 16.2381649017334,\n",
       " 68.77086639404297,\n",
       " 16.842241287231445,\n",
       " 29.20728302001953,\n",
       " 104.66841888427734,\n",
       " 13.297395706176758,\n",
       " 11.490921974182129,\n",
       " 11.665875434875488,\n",
       " 15.498967170715332,\n",
       " 15.983936309814453,\n",
       " 15.490246772766113,\n",
       " 94.63960266113281,\n",
       " 12.658391952514648,\n",
       " 12.584333419799805,\n",
       " 61.490421295166016,\n",
       " 13.70885944366455,\n",
       " 9.461601257324219,\n",
       " 16.171279907226562,\n",
       " 14.173911094665527,\n",
       " 15.558684349060059,\n",
       " 8.964704513549805,\n",
       " 12.975093841552734,\n",
       " 38.12180709838867,\n",
       " 14.698602676391602,\n",
       " 12.251805305480957,\n",
       " 8.364845275878906,\n",
       " 73.21941375732422,\n",
       " 12.468559265136719,\n",
       " 10.806327819824219,\n",
       " 15.765046119689941,\n",
       " 38.61955642700195,\n",
       " 25.2303466796875,\n",
       " 10.55815601348877,\n",
       " 16.790437698364258,\n",
       " 16.72580337524414,\n",
       " 10.947154998779297,\n",
       " 44.476951599121094,\n",
       " 11.342514038085938,\n",
       " 9.823236465454102,\n",
       " 13.439870834350586,\n",
       " 14.057900428771973,\n",
       " 15.702348709106445,\n",
       " 10.194940567016602,\n",
       " 11.569419860839844,\n",
       " 16.279428482055664,\n",
       " 11.077016830444336,\n",
       " 17.648103713989258,\n",
       " 10.986272811889648,\n",
       " 11.707524299621582,\n",
       " 13.497894287109375,\n",
       " 114.54523468017578,\n",
       " 60.219261169433594,\n",
       " 11.34465503692627,\n",
       " 17.984201431274414,\n",
       " 10.890538215637207,\n",
       " 8.185347557067871,\n",
       " 41.305606842041016,\n",
       " 16.288894653320312,\n",
       " 10.930126190185547,\n",
       " 9.697709083557129,\n",
       " 9.454169273376465,\n",
       " 16.14569091796875,\n",
       " 7.287662029266357,\n",
       " 19.164567947387695,\n",
       " 8.18952751159668,\n",
       " 12.114006996154785,\n",
       " 14.718876838684082,\n",
       " 13.660598754882812,\n",
       " 7.137762546539307,\n",
       " 14.310454368591309,\n",
       " 13.83088207244873,\n",
       " 13.601731300354004,\n",
       " 11.374911308288574,\n",
       " 12.588821411132812,\n",
       " 10.643749237060547,\n",
       " 14.501836776733398,\n",
       " 7.655153751373291,\n",
       " 25.34112548828125,\n",
       " 16.27726936340332,\n",
       " 12.277924537658691,\n",
       " 13.433985710144043,\n",
       " 15.98641586303711,\n",
       " 11.581562042236328,\n",
       " 15.882213592529297,\n",
       " 15.093315124511719,\n",
       " 10.40549087524414,\n",
       " 10.727749824523926,\n",
       " 69.3736343383789,\n",
       " 12.763786315917969,\n",
       " 6.882559299468994,\n",
       " 8.245793342590332,\n",
       " 8.511961936950684,\n",
       " 13.76906681060791,\n",
       " 14.810815811157227,\n",
       " 14.240970611572266,\n",
       " 73.23014068603516,\n",
       " 8.3338041305542,\n",
       " 8.692272186279297,\n",
       " 16.71268653869629,\n",
       " 76.13397979736328,\n",
       " 11.38884449005127,\n",
       " 15.482198715209961,\n",
       " 13.273999214172363,\n",
       " 13.864989280700684,\n",
       " 14.873936653137207,\n",
       " 15.938603401184082,\n",
       " 15.499252319335938,\n",
       " 9.533032417297363,\n",
       " 12.131134033203125,\n",
       " 14.583467483520508,\n",
       " 10.751606941223145,\n",
       " 12.345020294189453,\n",
       " 9.381270408630371,\n",
       " 12.66125202178955,\n",
       " 8.552224159240723,\n",
       " 33.45722579956055,\n",
       " 12.638304710388184,\n",
       " 95.25855255126953,\n",
       " 12.710970878601074,\n",
       " 8.803593635559082,\n",
       " 8.221055030822754,\n",
       " 15.017343521118164,\n",
       " 9.953560829162598,\n",
       " 52.0971794128418,\n",
       " 18.072296142578125,\n",
       " 7.914463520050049,\n",
       " 14.725645065307617,\n",
       " 13.39150333404541,\n",
       " 11.575958251953125,\n",
       " 13.230031967163086,\n",
       " 9.491990089416504,\n",
       " 12.860107421875,\n",
       " 7.974977016448975,\n",
       " 10.814910888671875,\n",
       " 10.971990585327148,\n",
       " 11.948029518127441,\n",
       " 15.91380786895752,\n",
       " 11.850900650024414,\n",
       " 30.33868408203125,\n",
       " 16.38983726501465,\n",
       " 13.10588264465332,\n",
       " 81.3344955444336,\n",
       " 14.5990571975708,\n",
       " 7.989089488983154,\n",
       " 12.68564510345459,\n",
       " 11.342852592468262,\n",
       " 9.488457679748535,\n",
       " 17.77791976928711,\n",
       " 13.5999174118042,\n",
       " 37.581878662109375,\n",
       " 10.817098617553711,\n",
       " 16.679418563842773,\n",
       " 52.27433395385742,\n",
       " 8.068964958190918,\n",
       " 16.101106643676758,\n",
       " 15.701685905456543,\n",
       " 10.257023811340332,\n",
       " 14.741579055786133,\n",
       " 14.575613021850586,\n",
       " 15.70040225982666,\n",
       " 14.47760009765625,\n",
       " 11.149016380310059,\n",
       " 15.399667739868164,\n",
       " 12.463533401489258,\n",
       " 12.344133377075195,\n",
       " 9.85230827331543,\n",
       " 10.088934898376465,\n",
       " 16.35111427307129,\n",
       " 11.112174987792969,\n",
       " 16.054683685302734,\n",
       " 21.263277053833008,\n",
       " 16.61769676208496,\n",
       " 12.683947563171387,\n",
       " 11.60739517211914,\n",
       " 13.781305313110352,\n",
       " 44.46507263183594,\n",
       " 12.36363697052002,\n",
       " 17.617530822753906,\n",
       " 11.271045684814453,\n",
       " 15.722209930419922,\n",
       " 11.535789489746094,\n",
       " 12.749752044677734,\n",
       " 7.245047092437744,\n",
       " 25.049476623535156,\n",
       " 9.355659484863281,\n",
       " 91.5381088256836,\n",
       " 13.09835147857666,\n",
       " 43.77478790283203,\n",
       " 13.353759765625,\n",
       " 11.243021965026855,\n",
       " 14.344939231872559,\n",
       " 22.586719512939453,\n",
       " 61.63052749633789,\n",
       " 11.218603134155273,\n",
       " 14.148180961608887,\n",
       " 12.577577590942383,\n",
       " 16.64189910888672,\n",
       " 9.968767166137695,\n",
       " 13.764602661132812,\n",
       " 92.05048370361328,\n",
       " 16.939903259277344,\n",
       " 6.361188888549805,\n",
       " 13.822798728942871,\n",
       " 17.46392822265625,\n",
       " 15.206936836242676,\n",
       " 15.252385139465332,\n",
       " 11.729472160339355,\n",
       " 9.917499542236328,\n",
       " 14.209548950195312,\n",
       " 8.2781982421875,\n",
       " 18.495769500732422,\n",
       " 14.957857131958008,\n",
       " 13.36463737487793,\n",
       " 67.4285888671875,\n",
       " 11.830961227416992,\n",
       " 15.976922035217285,\n",
       " 10.101573944091797,\n",
       " 9.5398530960083,\n",
       " 9.283186912536621,\n",
       " 16.630590438842773,\n",
       " 82.12898254394531,\n",
       " 10.795676231384277,\n",
       " 9.574674606323242,\n",
       " 8.211753845214844,\n",
       " 8.317020416259766,\n",
       " 17.35848617553711,\n",
       " 19.046621322631836,\n",
       " 10.673645973205566,\n",
       " 17.231094360351562,\n",
       " 14.196640014648438,\n",
       " 15.906322479248047,\n",
       " 95.96017456054688,\n",
       " 16.897001266479492,\n",
       " 15.440664291381836,\n",
       " 11.983726501464844,\n",
       " 6.6015543937683105,\n",
       " 13.456393241882324,\n",
       " 16.277090072631836,\n",
       " 8.065096855163574,\n",
       " 12.918499946594238,\n",
       " 10.775928497314453,\n",
       " 13.884522438049316,\n",
       " 7.073297023773193,\n",
       " 17.756973266601562,\n",
       " 11.461078643798828,\n",
       " 14.569354057312012,\n",
       " 10.598976135253906,\n",
       " 15.125158309936523,\n",
       " 14.1181058883667,\n",
       " 17.792455673217773,\n",
       " 19.60222625732422,\n",
       " 11.961310386657715,\n",
       " 15.116540908813477,\n",
       " 16.01392364501953,\n",
       " 11.030943870544434,\n",
       " 8.910484313964844,\n",
       " 9.509554862976074,\n",
       " 17.800067901611328,\n",
       " 15.164569854736328,\n",
       " 14.670177459716797,\n",
       " 88.6915054321289,\n",
       " 12.757003784179688,\n",
       " 14.310590744018555,\n",
       " 9.07774543762207,\n",
       " 16.862485885620117,\n",
       " 9.439908027648926,\n",
       " 10.220917701721191,\n",
       " 14.240350723266602,\n",
       " 40.20277786254883,\n",
       " 20.16124725341797,\n",
       " 16.219444274902344,\n",
       " 16.65301513671875,\n",
       " 10.62325668334961,\n",
       " 13.734065055847168,\n",
       " 15.613786697387695,\n",
       " 8.161663055419922,\n",
       " 11.33582878112793,\n",
       " 8.462597846984863,\n",
       " 9.912310600280762,\n",
       " 14.480301856994629,\n",
       " 8.693795204162598,\n",
       " 45.62960433959961,\n",
       " 11.716885566711426,\n",
       " 10.923089981079102,\n",
       " 17.40431785583496,\n",
       " 17.74018096923828,\n",
       " 12.137772560119629,\n",
       " 13.51106071472168,\n",
       " 11.30299186706543,\n",
       " 12.02062702178955,\n",
       " 15.675127029418945,\n",
       " 15.032716751098633,\n",
       " 9.049527168273926,\n",
       " 12.351417541503906,\n",
       " 14.299474716186523,\n",
       " 14.794717788696289,\n",
       " 12.363577842712402,\n",
       " 16.672121047973633,\n",
       " 11.58381462097168,\n",
       " 12.191515922546387,\n",
       " 14.990013122558594,\n",
       " 16.577877044677734,\n",
       " 76.04591369628906,\n",
       " 9.153544425964355,\n",
       " 17.500690460205078,\n",
       " 8.538971900939941,\n",
       " 25.207828521728516,\n",
       " 11.293585777282715,\n",
       " 15.654316902160645,\n",
       " 86.48731994628906,\n",
       " 9.346173286437988,\n",
       " 14.346590042114258,\n",
       " 11.479499816894531,\n",
       " 10.730838775634766,\n",
       " 16.054508209228516,\n",
       " 15.093586921691895,\n",
       " 19.79429817199707,\n",
       " 10.897029876708984,\n",
       " 17.370534896850586,\n",
       " 14.462530136108398,\n",
       " 11.198225021362305,\n",
       " 9.267816543579102,\n",
       " 10.98493766784668,\n",
       " 11.289857864379883,\n",
       " 17.239336013793945,\n",
       " 13.556992530822754,\n",
       " 41.982601165771484,\n",
       " 9.476637840270996,\n",
       " 13.523673057556152,\n",
       " 18.27334213256836,\n",
       " 11.9056396484375,\n",
       " 7.497525691986084,\n",
       " 9.317440032958984,\n",
       " 11.975285530090332,\n",
       " 27.088430404663086,\n",
       " 12.991883277893066,\n",
       " 15.491015434265137,\n",
       " 7.88443660736084,\n",
       " 12.811760902404785,\n",
       " 12.648347854614258,\n",
       " 17.135892868041992,\n",
       " 13.93150806427002,\n",
       " 20.809669494628906,\n",
       " 34.16574478149414,\n",
       " 7.8645405769348145,\n",
       " 11.909616470336914,\n",
       " 10.309382438659668,\n",
       " 10.354181289672852,\n",
       " 15.613704681396484,\n",
       " 36.93091583251953,\n",
       " 110.46654510498047,\n",
       " 9.712177276611328,\n",
       " 8.263484954833984,\n",
       " 9.402942657470703,\n",
       " 13.111052513122559,\n",
       " 10.161175727844238,\n",
       " 8.154107093811035,\n",
       " 16.999860763549805,\n",
       " 15.889485359191895,\n",
       " 15.779815673828125,\n",
       " 9.410789489746094,\n",
       " 15.567009925842285,\n",
       " 9.809372901916504,\n",
       " 12.531021118164062,\n",
       " 14.250614166259766,\n",
       " 17.9440975189209,\n",
       " 11.193950653076172,\n",
       " 13.94561767578125,\n",
       " 17.39723014831543,\n",
       " 14.717508316040039,\n",
       " 11.178109169006348,\n",
       " 11.863083839416504,\n",
       " 13.983922958374023,\n",
       " 16.899805068969727,\n",
       " 17.37537384033203,\n",
       " 50.51288604736328,\n",
       " 90.2881851196289,\n",
       " 114.02394104003906,\n",
       " 9.9369478225708,\n",
       " 14.581583976745605,\n",
       " 115.93660736083984,\n",
       " 91.25593566894531,\n",
       " 17.302541732788086,\n",
       " 16.615230560302734,\n",
       " 10.671255111694336,\n",
       " 14.109707832336426,\n",
       " 15.769636154174805,\n",
       " 8.390755653381348,\n",
       " 11.630675315856934,\n",
       " 11.566071510314941,\n",
       " 12.012032508850098,\n",
       " 13.529691696166992,\n",
       " 15.081244468688965,\n",
       " 7.619426250457764,\n",
       " 10.07054328918457,\n",
       " 11.75484561920166,\n",
       " 8.847921371459961,\n",
       " 18.49893569946289,\n",
       " 12.589421272277832,\n",
       " 11.385807991027832,\n",
       " 13.44986629486084,\n",
       " 7.3566789627075195,\n",
       " 11.126753807067871,\n",
       " 115.1276626586914,\n",
       " 11.853428840637207,\n",
       " 9.208089828491211,\n",
       " 12.032096862792969,\n",
       " 61.5062255859375,\n",
       " 64.83589172363281,\n",
       " 12.81176471710205,\n",
       " 15.652209281921387,\n",
       " 11.118395805358887,\n",
       " 8.029684066772461,\n",
       " 8.396458625793457,\n",
       " 68.54464721679688,\n",
       " 12.024041175842285,\n",
       " 10.978395462036133,\n",
       " 9.908374786376953,\n",
       " 16.47556495666504,\n",
       " 10.23449993133545,\n",
       " 9.79993724822998,\n",
       " 10.829285621643066,\n",
       " 11.360042572021484,\n",
       " 64.6798324584961,\n",
       " 9.917633056640625,\n",
       " 106.91581726074219,\n",
       " 21.220693588256836,\n",
       " 15.75705623626709,\n",
       " 7.881631374359131,\n",
       " 9.127352714538574,\n",
       " 12.71451473236084,\n",
       " 8.411365509033203,\n",
       " 21.13786506652832,\n",
       " 10.872757911682129,\n",
       " 16.53838539123535,\n",
       " 12.896525382995605,\n",
       " 12.709114074707031,\n",
       " 12.073543548583984,\n",
       " 14.947966575622559,\n",
       " 8.916463851928711,\n",
       " 16.108610153198242,\n",
       " 10.707052230834961,\n",
       " 8.583785057067871,\n",
       " 10.001741409301758,\n",
       " 12.740950584411621,\n",
       " 10.625408172607422,\n",
       " 12.930603981018066,\n",
       " 17.968597412109375,\n",
       " 8.518970489501953,\n",
       " 9.465893745422363,\n",
       " 16.741853713989258,\n",
       " 8.966487884521484,\n",
       " 12.891875267028809,\n",
       " 10.23681640625,\n",
       " 14.482185363769531,\n",
       " 12.775634765625,\n",
       " 21.32612419128418,\n",
       " 15.98818588256836,\n",
       " 12.199485778808594,\n",
       " 14.404911994934082,\n",
       " 16.117820739746094,\n",
       " 30.77677345275879,\n",
       " 10.415335655212402,\n",
       " 7.750854015350342,\n",
       " 12.815423011779785,\n",
       " 14.577651977539062,\n",
       " 8.151029586791992,\n",
       " 18.81167221069336,\n",
       " 13.661920547485352,\n",
       " 12.445822715759277,\n",
       " 11.601381301879883,\n",
       " 18.45810317993164,\n",
       " 12.547820091247559,\n",
       " 8.371438980102539,\n",
       " 42.407291412353516,\n",
       " 8.784523963928223,\n",
       " 11.032090187072754,\n",
       " 10.364784240722656,\n",
       " 13.131935119628906,\n",
       " 12.029441833496094,\n",
       " 15.829763412475586,\n",
       " 12.772907257080078,\n",
       " 85.35541534423828,\n",
       " 14.088205337524414,\n",
       " 15.86083698272705,\n",
       " 9.73794937133789,\n",
       " 6.406563758850098,\n",
       " 7.324241638183594,\n",
       " 10.341604232788086,\n",
       " 10.299869537353516,\n",
       " 10.412753105163574,\n",
       " 12.475834846496582,\n",
       " 13.548815727233887,\n",
       " 54.29713821411133,\n",
       " 16.655685424804688,\n",
       " 13.365704536437988,\n",
       " 9.260379791259766,\n",
       " 12.094717979431152,\n",
       " 11.122003555297852,\n",
       " 8.614922523498535,\n",
       " 12.408309936523438,\n",
       " 21.27689552307129,\n",
       " 8.919564247131348,\n",
       " 14.129417419433594,\n",
       " 14.39644718170166,\n",
       " 9.93635368347168,\n",
       " 17.97496795654297,\n",
       " 13.67654037475586,\n",
       " 9.598725318908691,\n",
       " 15.049284934997559,\n",
       " 13.420178413391113,\n",
       " 17.3514404296875,\n",
       " 11.059821128845215,\n",
       " 16.323352813720703,\n",
       " 10.138786315917969,\n",
       " 18.3267822265625,\n",
       " 10.944792747497559,\n",
       " 15.471132278442383,\n",
       " 13.489191055297852,\n",
       " 14.863912582397461,\n",
       " 10.311471939086914,\n",
       " 17.876075744628906,\n",
       " 9.679759979248047,\n",
       " 77.70812225341797,\n",
       " 8.807772636413574,\n",
       " 8.622052192687988,\n",
       " 15.812366485595703,\n",
       " 16.786279678344727,\n",
       " 8.209694862365723,\n",
       " 8.524859428405762,\n",
       " 16.198617935180664,\n",
       " 13.111818313598633,\n",
       " 17.490846633911133,\n",
       " 42.85334396362305,\n",
       " 9.830799102783203,\n",
       " 18.8314266204834,\n",
       " 13.832694053649902,\n",
       " 12.781755447387695,\n",
       " 14.963619232177734,\n",
       " 12.25667667388916,\n",
       " 15.194893836975098,\n",
       " 13.423351287841797,\n",
       " 18.47365951538086,\n",
       " 15.174413681030273,\n",
       " 13.024310111999512,\n",
       " 31.7904109954834,\n",
       " 10.487093925476074,\n",
       " 15.917614936828613,\n",
       " 9.426745414733887,\n",
       " 14.892796516418457,\n",
       " 9.716269493103027,\n",
       " 20.793682098388672,\n",
       " 13.964791297912598,\n",
       " 11.25097370147705,\n",
       " 8.751522064208984,\n",
       " 39.67639923095703,\n",
       " 9.051158905029297,\n",
       " 10.735374450683594,\n",
       " 14.896947860717773,\n",
       " 15.967572212219238,\n",
       " 9.30162525177002,\n",
       " 10.059508323669434,\n",
       " 14.035954475402832,\n",
       " 8.730210304260254,\n",
       " 15.771181106567383,\n",
       " 11.526229858398438,\n",
       " 7.970870494842529,\n",
       " 13.691450119018555,\n",
       " 13.06148910522461,\n",
       " 12.446720123291016,\n",
       " 13.17358684539795,\n",
       " 10.232640266418457,\n",
       " 9.17026424407959,\n",
       " 88.32855224609375,\n",
       " 12.93061351776123,\n",
       " 12.7854585647583,\n",
       " 12.096210479736328,\n",
       " 49.286834716796875,\n",
       " 15.106887817382812,\n",
       " 50.01146697998047,\n",
       " 17.92214584350586,\n",
       " 7.609434127807617,\n",
       " 10.46533203125,\n",
       " 18.008625030517578,\n",
       " 81.21482849121094,\n",
       " 17.028583526611328,\n",
       " 14.46327018737793,\n",
       " 19.01139259338379,\n",
       " 8.826202392578125,\n",
       " 9.07180118560791,\n",
       " 14.622529983520508,\n",
       " 8.380635261535645,\n",
       " 55.35602569580078,\n",
       " 8.258883476257324,\n",
       " 16.29073143005371,\n",
       " 10.455572128295898,\n",
       " 20.127586364746094,\n",
       " 13.133329391479492,\n",
       " 12.48072338104248,\n",
       " 12.868857383728027,\n",
       " 16.03815460205078,\n",
       " 13.329858779907227,\n",
       " 15.7769136428833,\n",
       " 15.428328514099121,\n",
       " 11.135578155517578,\n",
       " 13.181337356567383,\n",
       " 12.240649223327637,\n",
       " 75.84722137451172,\n",
       " 11.936358451843262,\n",
       " 15.444389343261719,\n",
       " 14.233091354370117,\n",
       " 11.60185432434082,\n",
       " 9.690330505371094,\n",
       " 14.526843070983887,\n",
       " 13.080111503601074,\n",
       " 7.118505477905273,\n",
       " 89.80426025390625,\n",
       " 12.168790817260742,\n",
       " 12.483967781066895,\n",
       " 15.006213188171387,\n",
       " 9.729013442993164,\n",
       " 9.72101879119873,\n",
       " 12.523168563842773,\n",
       " 10.507203102111816,\n",
       " 7.595111846923828,\n",
       " 77.05477142333984,\n",
       " 9.424782752990723,\n",
       " 18.071924209594727,\n",
       " 11.77208137512207,\n",
       " 10.902196884155273,\n",
       " 10.900819778442383,\n",
       " 12.065722465515137,\n",
       " 8.634777069091797,\n",
       " 11.419515609741211,\n",
       " 8.845199584960938,\n",
       " 10.086554527282715,\n",
       " 15.793200492858887,\n",
       " 10.966211318969727,\n",
       " 70.32830047607422,\n",
       " 13.865107536315918,\n",
       " 10.069563865661621,\n",
       " 10.509629249572754,\n",
       " 17.530712127685547,\n",
       " 12.491271018981934,\n",
       " 11.684494972229004,\n",
       " 111.14961242675781,\n",
       " 21.712448120117188,\n",
       " 20.153608322143555,\n",
       " 11.768848419189453,\n",
       " 7.244041919708252,\n",
       " 11.688608169555664,\n",
       " 113.57896423339844,\n",
       " 10.583222389221191,\n",
       " 14.719371795654297,\n",
       " 12.471319198608398,\n",
       " 13.271402359008789,\n",
       " 16.69657325744629,\n",
       " 10.362616539001465,\n",
       " 13.616548538208008,\n",
       " 16.907411575317383,\n",
       " 10.382896423339844,\n",
       " 14.459882736206055,\n",
       " 10.56044864654541,\n",
       " 108.70511627197266,\n",
       " 17.63241958618164,\n",
       " 9.403162956237793,\n",
       " 10.517181396484375,\n",
       " 16.527746200561523,\n",
       " 10.745828628540039,\n",
       " 17.336017608642578,\n",
       " 15.391510963439941,\n",
       " 21.459474563598633,\n",
       " 12.48100757598877,\n",
       " 18.437801361083984,\n",
       " 10.490355491638184,\n",
       " 15.3898286819458,\n",
       " 7.874648094177246,\n",
       " 18.88911247253418,\n",
       " 12.407785415649414,\n",
       " 13.909478187561035,\n",
       " 8.247156143188477,\n",
       " 76.63086700439453,\n",
       " 12.84585189819336,\n",
       " 8.043312072753906,\n",
       " 17.522844314575195,\n",
       " 17.319557189941406,\n",
       " 7.127760887145996,\n",
       " 69.98431396484375,\n",
       " 12.52329158782959,\n",
       " 11.43929672241211,\n",
       " 13.27674674987793,\n",
       " 13.405800819396973,\n",
       " 12.074376106262207,\n",
       " 13.440492630004883,\n",
       " 11.78515911102295,\n",
       " 74.97896575927734,\n",
       " 68.62285614013672,\n",
       " 10.852703094482422,\n",
       " 17.204923629760742,\n",
       " 14.232257843017578,\n",
       " 14.080656051635742,\n",
       " 12.955343246459961,\n",
       " 17.347497940063477,\n",
       " 9.534408569335938,\n",
       " 15.437414169311523,\n",
       " 16.932207107543945,\n",
       " 9.786357879638672,\n",
       " 9.494029998779297,\n",
       " 12.545324325561523,\n",
       " 10.179048538208008,\n",
       " 15.592337608337402,\n",
       " 6.58146333694458,\n",
       " 9.287921905517578,\n",
       " 12.201956748962402,\n",
       " 9.861615180969238,\n",
       " 14.916272163391113,\n",
       " 9.806845664978027,\n",
       " 82.7476806640625,\n",
       " 14.882879257202148,\n",
       " 12.183152198791504,\n",
       " 12.247210502624512,\n",
       " 9.964488983154297,\n",
       " 11.048604965209961,\n",
       " 17.309999465942383,\n",
       " 14.39520263671875,\n",
       " 9.582695007324219,\n",
       " 12.580489158630371,\n",
       " 6.145740509033203,\n",
       " 11.07127571105957,\n",
       " 8.488987922668457,\n",
       " 9.356037139892578,\n",
       " 13.377341270446777,\n",
       " 8.842772483825684,\n",
       " 36.42991256713867,\n",
       " 11.115800857543945,\n",
       " 14.033597946166992,\n",
       " 9.690781593322754,\n",
       " 9.241148948669434,\n",
       " 17.303897857666016,\n",
       " 16.15372085571289,\n",
       " 15.520454406738281,\n",
       " 49.242881774902344,\n",
       " 12.242438316345215,\n",
       " 11.96880054473877,\n",
       " 10.111326217651367,\n",
       " 86.84037017822266,\n",
       " 9.087281227111816,\n",
       " 11.062882423400879,\n",
       " 13.436206817626953,\n",
       " 16.39241600036621,\n",
       " 11.22412109375,\n",
       " 17.93040657043457,\n",
       " 16.474069595336914,\n",
       " 13.448121070861816,\n",
       " 15.356689453125,\n",
       " 13.23005485534668,\n",
       " 8.461274147033691,\n",
       " 10.107560157775879,\n",
       " 13.353038787841797,\n",
       " 12.003473281860352,\n",
       " 15.766562461853027,\n",
       " 8.282756805419922,\n",
       " 13.66427993774414,\n",
       " 12.264433860778809,\n",
       " 10.587611198425293,\n",
       " 11.153851509094238,\n",
       " 17.458417892456055,\n",
       " 10.502360343933105,\n",
       " 10.300375938415527,\n",
       " 15.748294830322266,\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtered_distances_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the list to a numpy array\n",
    "# cos_sim_array = np.array(cosine_similarities_random_graphs)\n",
    "\n",
    "# # Calculate the z-scores for each element in the array\n",
    "# z_scores = (cos_sim_array - np.mean(cos_sim_array)) / np.std(cos_sim_array)\n",
    "\n",
    "# # Define a threshold for outliers (e.g., z-score > 3)\n",
    "# threshold = 0.5\n",
    "\n",
    "# # Create a mask to identify outliers\n",
    "# outlier_mask = np.abs(z_scores) > threshold\n",
    "\n",
    "# # Remove outliers from the array\n",
    "# filtered_cos_sim = cos_sim_array[~outlier_mask]\n",
    "\n",
    "# # Convert the filtered array back to a list\n",
    "# filtered_cos_sim_list = filtered_cos_sim.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03925594690674916"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(filtered_cos_sim_list) / len(filtered_cos_sim_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_explainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

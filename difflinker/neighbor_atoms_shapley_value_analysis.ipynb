{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important neighobing atoms analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://web-proxy.informatik.uni-bonn.de:3128\"\n",
    "os.environ[\"https_proxy\"] = \"http://web-proxy.informatik.uni-bonn.de:3128\"\n",
    "\n",
    "import copy\n",
    "import yaml\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v2 as imageio\n",
    "import networkx as nx\n",
    "from pysmiles import read_smiles\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "from src.lightning import DDPM\n",
    "from src.datasets import get_dataloader\n",
    "from src.visualizer import load_molecule_xyz, load_xyz_files, save_xyz_file\n",
    "from src.molecule_builder import get_bond_order\n",
    "from src.utils import add_partial_mean_with_mask\n",
    "from src import const\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed:  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mastropietro/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.6.3 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint models/zinc_difflinker.ckpt`\n",
      "/home/mastropietro/Repositories/DiffSHAPer/difflinker/src/datasets.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data = torch.load(dataset_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:6\n",
      "Model DDPM(\n",
      "  (edm): EDM(\n",
      "    (gamma): PredefinedNoiseSchedule()\n",
      "    (dynamics): Dynamics(\n",
      "      (dynamics): EGNN(\n",
      "        (embedding): Linear(in_features=10, out_features=128, bias=True)\n",
      "        (embedding_out): Linear(in_features=128, out_features=10, bias=True)\n",
      "        (e_block_0): EquivariantBlock(\n",
      "          (gcl_0): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_1): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_equiv): EquivariantUpdate(\n",
      "            (coord_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "              (4): Linear(in_features=128, out_features=1, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (e_block_1): EquivariantBlock(\n",
      "          (gcl_0): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_1): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_equiv): EquivariantUpdate(\n",
      "            (coord_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "              (4): Linear(in_features=128, out_features=1, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (e_block_2): EquivariantBlock(\n",
      "          (gcl_0): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_1): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_equiv): EquivariantUpdate(\n",
      "            (coord_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "              (4): Linear(in_features=128, out_features=1, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (e_block_3): EquivariantBlock(\n",
      "          (gcl_0): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_1): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_equiv): EquivariantUpdate(\n",
      "            (coord_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "              (4): Linear(in_features=128, out_features=1, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (e_block_4): EquivariantBlock(\n",
      "          (gcl_0): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_1): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_equiv): EquivariantUpdate(\n",
      "            (coord_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "              (4): Linear(in_features=128, out_features=1, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (e_block_5): EquivariantBlock(\n",
      "          (gcl_0): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_1): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_equiv): EquivariantUpdate(\n",
      "            (coord_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "              (4): Linear(in_features=128, out_features=1, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (e_block_6): EquivariantBlock(\n",
      "          (gcl_0): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_1): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_equiv): EquivariantUpdate(\n",
      "            (coord_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "              (4): Linear(in_features=128, out_features=1, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (e_block_7): EquivariantBlock(\n",
      "          (gcl_0): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_1): GCL(\n",
      "            (edge_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "            )\n",
      "            (node_mlp): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (gcl_equiv): EquivariantUpdate(\n",
      "            (coord_mlp): Sequential(\n",
      "              (0): Linear(in_features=258, out_features=128, bias=True)\n",
      "              (1): SiLU()\n",
      "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (3): SiLU()\n",
      "              (4): Linear(in_features=128, out_features=1, bias=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Using anchors as context:  False\n",
      "Center of mass: fragments\n",
      "Timesteps: 500\n",
      "Norm values: [1, 4, 10]\n",
      "Norm biases: (None, 0.0, 0.0)\n",
      "Injection step: 50\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Load configuration from config.yml\n",
    "with open('config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "checkpoint = config['CHECKPOINT']\n",
    "chains = config['CHAINS']\n",
    "DATA = config['DATA']\n",
    "prefix = config['PREFIX']\n",
    "keep_frames = int(config['KEEP_FRAMES'])\n",
    "P = config['P']\n",
    "device = config['DEVICE'] if torch.cuda.is_available() else 'cpu'\n",
    "SEED = int(config['SEED'])\n",
    "REMOVAL = config['REMOVAL']\n",
    "ATOM_PERTURBATION = config['ATOM_PERTURBATION']\n",
    "ROTATE = config['ROTATE']\n",
    "TRANSLATE = config['TRANSLATE']\n",
    "REFLECT = config['REFLECT']\n",
    "TRANSFORMATION_SEED = int(config['TRANSFORMATION_SEED'])\n",
    "SAVE_VISUALIZATION = config['SAVE_VISUALIZATION']\n",
    "M = int(config['M'])\n",
    "NUM_SAMPLES = int(config['NUM_SAMPLES'])\n",
    "PARALLEL_STEPS = int(config['PARALLEL_STEPS'])\n",
    "TOP_K_PERTURBATION_REMOVAL = config['TOP_K_PERTURBATION_REMOVAL']\n",
    "LOCAL_MINIMUM_ANALYSIS = config['LOCAL_MINIMUM_ANALYSIS']\n",
    "\n",
    "print(\"Random seed: \", SEED)\n",
    "\n",
    "experiment_name = checkpoint.split('/')[-1].replace('.ckpt', '')\n",
    "\n",
    "assert (REMOVAL or ATOM_PERTURBATION) and not (REMOVAL and ATOM_PERTURBATION), \"Either REMOVAL or ATOM_PERTURBATION must be set to True, but not both or None\"\n",
    "\n",
    "#create output directories\n",
    "if REMOVAL:\n",
    "    chains_output_dir = os.path.join(chains, experiment_name, prefix, 'chains_' + P + '_seed_' + str(SEED) + '_neighbors_analysis_COM_addition/atom_removal')\n",
    "    final_states_output_dir = os.path.join(chains, experiment_name, prefix, 'final_states_' + P + '_seed_' + str(SEED) + '_neighbors_analysis_COM_addition/atom_removal')\n",
    "elif ATOM_PERTURBATION:\n",
    "    chains_output_dir = os.path.join(chains, experiment_name, prefix, 'chains_' + P + '_seed_' + str(SEED) + '_neighbors_analysis_COM_addition/atom_perturbation')\n",
    "    final_states_output_dir = os.path.join(chains, experiment_name, prefix, 'final_states_' + P + '_seed_' + str(SEED) + '_neighbors_analysis_COM_addition/atom_perturbation')\n",
    "else:\n",
    "    chains_output_dir = os.path.join(chains, experiment_name, prefix, 'chains_' + P + '_seed_' + str(SEED) + '_neighbors_analysis_COM_addition')\n",
    "    final_states_output_dir = os.path.join(chains, experiment_name, prefix, 'final_states_' + P + '_seed_' + str(SEED) + '_neighbors_analysis_COM_addition')\n",
    "\n",
    "if TOP_K_PERTURBATION_REMOVAL:\n",
    "    chains_output_dir = chains_output_dir.replace('atom', 'top_k_atom')\n",
    "    final_states_output_dir = final_states_output_dir.replace('atom', 'top_k_atom')\n",
    "    final_states_output_dir = final_states_output_dir.replace('atom', 'top_k_atom')\n",
    "\n",
    "if LOCAL_MINIMUM_ANALYSIS:\n",
    "    chains_output_dir = chains_output_dir.replace('atom', 'atom_local_min')\n",
    "    final_states_output_dir = final_states_output_dir.replace('atom', 'atom_local_min')\n",
    "    \n",
    "os.makedirs(chains_output_dir, exist_ok=True)\n",
    "os.makedirs(final_states_output_dir, exist_ok=True)\n",
    "\n",
    "# Loading model form checkpoint \n",
    "model = DDPM.load_from_checkpoint(checkpoint, map_location=device)\n",
    "\n",
    "# Possibility to evaluate on different datasets (e.g., on CASF instead of ZINC)\n",
    "model.val_data_prefix = prefix\n",
    "\n",
    "print(f\"Running on device: {device}\")\n",
    "# In case <Anonymous> will run my model or vice versa\n",
    "if DATA is not None:\n",
    "    model.data_path = DATA\n",
    "\n",
    "model = model.eval().to(device)\n",
    "model.setup(stage='val')\n",
    "dataloader = get_dataloader(\n",
    "    model.val_dataset,\n",
    "    batch_size=1, #@mastro, it was 32\n",
    "    # batch_size=len(model.val_dataset)\n",
    ")\n",
    "\n",
    "print(\"Model\", model)\n",
    "print(\"Using anchors as context: \", model.anchors_context)\n",
    "print(\"Center of mass:\", model.center_of_mass)\n",
    "print(\"Timesteps:\", model.edm.T)\n",
    "print(\"Norm values:\", model.edm.norm_values)\n",
    "print(\"Norm biases:\", model.edm.norm_biases)\n",
    "diffusion_steps = model.edm.T\n",
    "injection_step = diffusion_steps // 10\n",
    "print(\"Injection step:\", injection_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrestomomentum():\n",
    "    raise KeyboardInterrupt(\"Debug interrupt.\")\n",
    "\n",
    "def has_bond(atom1, atom2, distance, check_exists=True, margins=const.MARGINS_EDM):\n",
    "    distance = 100 * distance  # We change the metric\n",
    "\n",
    "    # Check exists for large molecules where some atom pairs do not have a\n",
    "    # typical bond length.\n",
    "    if check_exists:\n",
    "        if atom1 not in const.BONDS_1:\n",
    "            return 0\n",
    "        if atom2 not in const.BONDS_1[atom1]:\n",
    "            return 0\n",
    "\n",
    "    # margin1, margin2, margin3, and margin4 have been tuned to maximize stability\n",
    "    if distance < const.BONDS_1[atom1][atom2] + margins[0]:\n",
    "        # Check for aromatic bonds\n",
    "        return 1  # Single\n",
    "    return 0  # No bond\n",
    "\n",
    "# Visualize generated molecules as molecular graphs\n",
    "def visualize_generated_molecules(data_list, shapley_values_all_dict, generated_folder, COORDINATES_FOLDER):\n",
    "    for data_index, data in enumerate(data_list):\n",
    "        phi_values = shapley_values_all_dict[data_index][0]\n",
    "        # Load generated molecule positions and atom types\n",
    "        generated_file = os.path.join(generated_folder, f\"{data_index}_pred_.xyz\")\n",
    "        positions, one_hot, _ = load_molecule_xyz(generated_file, is_geom=False)\n",
    "        \n",
    "        atom_types = torch.argmax(one_hot, dim=1).cpu().numpy()\n",
    "    \n",
    "        # Convert positions and atom types to an RDKit molecule\n",
    "        mol = Chem.RWMol()\n",
    "        atom_map = {}\n",
    "\n",
    "        # Add atoms to the molecule\n",
    "        for idx, atom_type in enumerate(atom_types):\n",
    "            atom = Chem.Atom(const.IDX2ATOM[atom_type])\n",
    "            atom_idx = mol.AddAtom(atom)\n",
    "            atom_map[idx] = atom_idx\n",
    "\n",
    "        # Add bonds based on positions and bond order\n",
    "        for idx1 in range(len(positions)):\n",
    "            for idx2 in range(idx1 + 1, len(positions)):\n",
    "                dist = np.linalg.norm(positions[idx1] - positions[idx2])\n",
    "                bond_order = has_bond(const.IDX2ATOM[atom_types[idx1]], const.IDX2ATOM[atom_types[idx2]], dist)\n",
    "                \n",
    "                if bond_order > 0:\n",
    "                    bond_type = const.BOND_DICT[bond_order]\n",
    "                    mol.AddBond(atom_map[idx1], atom_map[idx2], bond_type)\n",
    "                    \n",
    "                    if bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "                        bond = mol.GetBondBetweenAtoms(atom_map[idx1], atom_map[idx2])\n",
    "                        bond.SetIsAromatic(True)\n",
    "\n",
    "        # Highlight fragment atoms and edges\n",
    "        fragment_mask = data['fragment_mask'][0].cpu().numpy()\n",
    "    \n",
    "        # Calculate the gradient colors based on phi values\n",
    "        phi_values_array = np.array(phi_values)\n",
    "        cmap = plt.cm.get_cmap('coolwarm_r')  # reversed heatmap for distance-based importance\n",
    "        norm = plt.Normalize(vmin=min(phi_values_array), vmax=max(phi_values_array))\n",
    "        highlight_colors = {idx: cmap(norm(phi_values_array[idx])) for idx, mask in enumerate(fragment_mask) if mask == 1}\n",
    "        \n",
    "        highlight_atoms = list(highlight_colors.keys())\n",
    "        highlight_bonds = []\n",
    "        for bond in mol.GetBonds():\n",
    "            if bond.GetBeginAtomIdx() in highlight_atoms and bond.GetEndAtomIdx() in highlight_atoms:\n",
    "                highlight_bonds.append(bond.GetIdx())\n",
    "        \n",
    "        # Assign bond colors based on the colors of the connected atoms\n",
    "        bond_colors = {}\n",
    "    \n",
    "        # Convert to RDKit molecule and draw\n",
    "        mol = mol.GetMol()\n",
    "        atom_colors = {idx: list(map(float, color[:3])) for idx, color in highlight_colors.items()}  # Convert to lists of floats\n",
    "        atom_colors = {key: [tuple(value)] for key, value in atom_colors.items()}\n",
    "        \n",
    "        # Draw linker bonds and atoms in emerald green\n",
    "        emerald_green = (0.25, 0.63, 0.38, 0.7)  # RGB for emerald green\n",
    "        linker_mask = data['linker_mask'][0].cpu().numpy()\n",
    "        \n",
    "        # Update atom colors for linker atoms\n",
    "        for idx, mask in enumerate(linker_mask):\n",
    "            if mask == 1:\n",
    "                atom_colors[idx] = [emerald_green[:3]]  # Set emerald green for linker atoms\n",
    "        \n",
    "        # Update bond colors for linker bonds\n",
    "        for bond in mol.GetBonds():\n",
    "            begin_idx = bond.GetBeginAtomIdx()\n",
    "            end_idx = bond.GetEndAtomIdx()\n",
    "            if linker_mask[begin_idx] == 1 and linker_mask[end_idx] == 1:\n",
    "                bond_colors[bond.GetIdx()] = [emerald_green]  # Set emerald green for linker bonds\n",
    "        \n",
    "        # Use DrawMoleculeWithHighlights for visualization\n",
    "        atom_radii = {idx: 0.5 for idx in range(len(positions))}  # Default atom radius\n",
    "        # Set radius 0.3 for linker atoms\n",
    "        for idx, mask in enumerate(linker_mask):\n",
    "            if mask == 1:\n",
    "                atom_radii[idx] = 0.3\n",
    "        \n",
    "        drawer = Draw.MolDraw2DCairo(800, 800)\n",
    "        draw_options = drawer.drawOptions()\n",
    "        draw_options.useBWAtomPalette()\n",
    "        draw_options.kekulize = False\n",
    "        \n",
    "        drawer.DrawMoleculeWithHighlights(\n",
    "            mol,\n",
    "            \"\",  # Legend\n",
    "            atom_colors,  # Atom colors (highlight_atom_map)\n",
    "            bond_colors,  # Bond colors (highlight_bond_map)\n",
    "            atom_radii,  # Atom radii\n",
    "            {}  # Bond linewidth multipliers\n",
    "        )\n",
    "\n",
    "        drawer.FinishDrawing()\n",
    "        # Convert the drawing to a PNG image\n",
    "        png_data = drawer.GetDrawingText()\n",
    "        with open(\"temp_image.png\", \"wb\") as f:\n",
    "            f.write(png_data)\n",
    "\n",
    "        # Load the PNG image using PIL\n",
    "        img = Image.open(\"temp_image.png\")\n",
    "        # img.show()\n",
    "        \n",
    "        output_generated_dir = os.path.join(COORDINATES_FOLDER, \"singlebonds\")\n",
    "        os.makedirs(output_generated_dir, exist_ok=True)\n",
    "        # Save the image in the \"generated_structures\" subfolder\n",
    "        output_file = os.path.join(output_generated_dir, f\"molecule_{data_index}.png\")\n",
    "        img.save(output_file, dpi=(300, 300))\n",
    "\n",
    "def compute_hausdorff_distance_batch(mol1, mol2, mask1 = None, mask2 = None, project = None, projection_mask1 = None, projection_mask2 = None,node_projection_mask = None):\n",
    "    \"\"\"\n",
    "    Compute the Hausdorff distance between two batches of molecules.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first batch of molecules.\n",
    "        mol2 (torch.Tensor): The second batch of molecules.\n",
    "        mask1 (torch.Tensor, optional): A mask indicating which atoms to consider for mol1. If not provided, all atoms will be considered.\n",
    "        mask2 (torch.Tensor, optional): A mask indicating which atoms to consider for mol2. If not provided, all atoms will be considered.\n",
    "        project (bool, optional): Whether to project the molecules to their mean-centered coordinates.\n",
    "        \n",
    "    Returns:\n",
    "        list: The Hausdorff distances between the corresponding molecules in the batches.\n",
    "    \"\"\"\n",
    "    # If fragment_mask is provided, only consider the atoms in the mask\n",
    "\n",
    "    #take only the positions\n",
    "    mol1 = mol1[:, :, :3]\n",
    "    mol2 = mol2[:, :, :3]\n",
    "\n",
    "    \n",
    "    # print(\"Mol 2 before projection: \", mol2[0])\n",
    "    if project is None:\n",
    "        pass\n",
    "    elif project == \"origin\":\n",
    "        mol1 = mol1 - mol1.mean(dim=1, keepdim=True)\n",
    "        mol2 = mol2 - mol2.mean(dim=1, keepdim=True)\n",
    "    elif project == \"com\":\n",
    "        assert(projection_mask1 is not None and projection_mask2 is not None)\n",
    "        mol1 = add_partial_mean_with_mask(mol1, node_projection_mask, projection_mask1)\n",
    "        mol2 = add_partial_mean_with_mask(mol2, node_projection_mask, projection_mask1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid projection type.\") \n",
    "\n",
    "    \n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        batch_size = mol1.shape[0]\n",
    "        masked_mol1 = []\n",
    "        for i in range(batch_size):\n",
    "            masked_mol1.append(mol1[i, mask1[i], :])\n",
    "        \n",
    "        if batch_size == 1:\n",
    "            mol1 = masked_mol1[0].unsqueeze(0)\n",
    "        else:    \n",
    "            mol1 = torch.stack(masked_mol1)\n",
    "        \n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mask2 = mask2.bool()\n",
    "        batch_size = mol2.shape[0]\n",
    "        masked_mol2 = []\n",
    "        for i in range(batch_size):\n",
    "            masked_mol2.append(mol2[i, mask2[i], :])\n",
    "        \n",
    "        if batch_size == 1:\n",
    "            mol2 = masked_mol2[0].unsqueeze(0)\n",
    "        else:    \n",
    "            mol2 = torch.stack(masked_mol2)\n",
    "\n",
    "    hausdorff_distances = []\n",
    "    for i in range(mol1.shape[0]):\n",
    "        hausdorff_distances.append(max(directed_hausdorff(mol1[i], mol2[i])[0], directed_hausdorff(mol2[i], mol1[i])[0]))\n",
    "\n",
    "    return hausdorff_distances\n",
    "\n",
    "def draw_sphere_xai(ax, x, y, z, size, color, alpha):\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "\n",
    "    xs = size * np.outer(np.cos(u), np.sin(v))\n",
    "    ys = size * np.outer(np.sin(u), np.sin(v)) #* 0.8\n",
    "    zs = size * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    ax.plot_surface(x + xs, y + ys, z + zs, rstride=2, cstride=2, color=color, alpha=alpha)\n",
    "\n",
    "# def plot_molecule_xai(ax, positions, atom_type, alpha, spheres_3d, hex_bg_color, is_geom, fragment_mask=None, phi_values=None, colors_fragment_shadow=None, draw_atom_indices = False):\n",
    "#     x = positions[:, 0]\n",
    "#     y = positions[:, 1]\n",
    "#     z = positions[:, 2]\n",
    "#     # Hydrogen, Carbon, Nitrogen, Oxygen, Flourine\n",
    "\n",
    "#     idx2atom = const.GEOM_IDX2ATOM if is_geom else const.IDX2ATOM\n",
    "\n",
    "#     colors_dic = np.array(const.COLORS)\n",
    "#     radius_dic = np.array(const.RADII)\n",
    "#     area_dic = 1500 * radius_dic ** 2\n",
    "\n",
    "#     areas = area_dic[atom_type]\n",
    "#     radii = radius_dic[atom_type]\n",
    "#     colors = colors_dic[atom_type]\n",
    "\n",
    "#     if fragment_mask is None:\n",
    "#         fragment_mask = torch.ones(len(x))\n",
    "\n",
    "#     for i in range(len(x)):\n",
    "#         for j in range(i + 1, len(x)):\n",
    "#             p1 = np.array([x[i], y[i], z[i]])\n",
    "#             p2 = np.array([x[j], y[j], z[j]])\n",
    "#             dist = np.sqrt(np.sum((p1 - p2) ** 2))\n",
    "#             atom1, atom2 = idx2atom[atom_type[i]], idx2atom[atom_type[j]]\n",
    "#             draw_edge_int = get_bond_order(atom1, atom2, dist)\n",
    "#             line_width = (3 - 2) * 2 * 2\n",
    "#             draw_edge = draw_edge_int > 0\n",
    "#             if draw_edge:\n",
    "#                 if draw_edge_int == 4:\n",
    "#                     linewidth_factor = 1.5\n",
    "#                 else:\n",
    "#                     linewidth_factor = 1\n",
    "#                 linewidth_factor *= 0.5\n",
    "#                 ax.plot(\n",
    "#                     [x[i], x[j]], [y[i], y[j]], [z[i], z[j]],\n",
    "#                     linewidth=line_width * linewidth_factor * 2,\n",
    "#                     c=hex_bg_color,\n",
    "#                     alpha=alpha\n",
    "#                 )\n",
    "\n",
    "    \n",
    "\n",
    "#     if spheres_3d:\n",
    "        \n",
    "#         for i, j, k, s, c, f, phi in zip(x, y, z, radii, colors, fragment_mask, phi_values):\n",
    "#             if f == 1:\n",
    "#                 alpha = 1.0\n",
    "#                 if phi > 0:\n",
    "#                     c = 'red'\n",
    "\n",
    "#             draw_sphere_xai(ax, i.item(), j.item(), k.item(), 0.5 * s, c, alpha)\n",
    "\n",
    "#     else:\n",
    "\n",
    "#         #draw fragments\n",
    "#         fragment_mask_on_cpu = fragment_mask.cpu().numpy()\n",
    "#         colors_fragment = colors[fragment_mask_on_cpu == 1]\n",
    "#         x_fragment = x[fragment_mask_on_cpu == 1]\n",
    "#         y_fragment = y[fragment_mask_on_cpu == 1]\n",
    "#         z_fragment = z[fragment_mask_on_cpu == 1]\n",
    "#         areas_fragment = areas[fragment_mask_on_cpu == 1]\n",
    "        \n",
    "#         if phi_values is not None and colors_fragment_shadow is None:\n",
    "#             phi_values_array = np.array(phi_values)\n",
    "#             # Calculate the gradient colors based on phi values\n",
    "#             cmap = plt.cm.get_cmap('coolwarm_r') #reversed heatmap for distance-based importance\n",
    "#             norm = plt.Normalize(vmin=min(phi_values_array), vmax=max(phi_values_array))\n",
    "#             colors_fragment_shadow = cmap(norm(phi_values_array))\n",
    "#         elif colors_fragment_shadow is not None and phi_values is None:\n",
    "#             colors_fragment_shadow = colors_fragment_shadow\n",
    "#         else:\n",
    "#             raise ValueError(\"Either phi_values or colors_fragment_shadow must be provided, not both.\")\n",
    "#         # ax.scatter(x_fragment, y_fragment, z_fragment, s=areas_fragment, alpha=0.9 * alpha, c=colors_fragment)\n",
    "\n",
    "#         ax.scatter(x_fragment, y_fragment, z_fragment, s=areas_fragment, alpha=0.9 * alpha, c=colors_fragment, edgecolors=colors_fragment_shadow, linewidths=5, rasterized=False)\n",
    "        \n",
    "#         if draw_atom_indices == \"original\":\n",
    "#             #get fragment indices using fragment mask\n",
    "#             fragment_indices = np.where(fragment_mask_on_cpu == 1)[0]\n",
    "#             for i, txt in enumerate(fragment_indices):\n",
    "#                 ax.text(x_fragment[i], y_fragment[i], z_fragment[i], str(txt), color='black', fontsize=15)\n",
    "        \n",
    "#         elif draw_atom_indices is None:\n",
    "#             pass\n",
    "\n",
    "#         else:\n",
    "#             for i, txt in enumerate(draw_atom_indices[0]):\n",
    "#                 ax.text(x_fragment[i], y_fragment[i], z_fragment[i], str(txt), color='black', fontsize=15)\n",
    "\n",
    "        \n",
    "\n",
    "#         #draw non-fragment atoms\n",
    "#         colors = colors[fragment_mask_on_cpu == 0]\n",
    "#         x = x[fragment_mask_on_cpu == 0]\n",
    "#         y = y[fragment_mask_on_cpu == 0]\n",
    "#         z = z[fragment_mask_on_cpu == 0]\n",
    "#         areas = areas[fragment_mask_on_cpu == 0]\n",
    "#         ax.scatter(x, y, z, s=areas, alpha=0.9 * alpha, c=colors, rasterized=False)\n",
    "\n",
    "#         if draw_atom_indices == \"original\":\n",
    "#             #get non-fragment indices using fragment mask\n",
    "#             non_fragment_indices = np.where(fragment_mask_on_cpu == 0)[0]\n",
    "#             for i, txt in enumerate(non_fragment_indices):\n",
    "#                 ax.text(x[i], y[i], z[i], str(txt), color='black', fontsize=15)\n",
    "#         elif draw_atom_indices is None:\n",
    "#             pass\n",
    "#         else:\n",
    "#             for i, txt in enumerate(draw_atom_indices[1]):\n",
    "#                 ax.text(x[i], y[i], z[i], str(txt), color='black', fontsize=15)\n",
    "\n",
    "def plot_molecule_xai(ax, positions, atom_type, alpha, spheres_3d, hex_bg_color, is_geom, fragment_mask=None, phi_values=None, colors_fragment_shadow=None, draw_atom_indices = False):\n",
    "    x = positions[:, 0]\n",
    "    y = positions[:, 1]\n",
    "    z = positions[:, 2]\n",
    "    # Hydrogen, Carbon, Nitrogen, Oxygen, Flourine\n",
    "\n",
    "    idx2atom = const.GEOM_IDX2ATOM if is_geom else const.IDX2ATOM\n",
    "\n",
    "    colors_dic = np.array(const.COLORS)\n",
    "    radius_dic = np.array(const.RADII)\n",
    "    area_dic = 1500 * radius_dic ** 2\n",
    "\n",
    "    areas = area_dic[atom_type]\n",
    "    radii = radius_dic[atom_type]\n",
    "    colors = colors_dic[atom_type]\n",
    "\n",
    "    if fragment_mask is None:\n",
    "        fragment_mask = torch.ones(len(x))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        for j in range(i + 1, len(x)):\n",
    "            p1 = np.array([x[i], y[i], z[i]])\n",
    "            p2 = np.array([x[j], y[j], z[j]])\n",
    "            dist = np.sqrt(np.sum((p1 - p2) ** 2))\n",
    "            atom1, atom2 = idx2atom[atom_type[i]], idx2atom[atom_type[j]]\n",
    "            draw_edge_int = get_bond_order(atom1, atom2, dist)\n",
    "            line_width = (3 - 2) * 2 * 2\n",
    "            draw_edge = draw_edge_int > 0\n",
    "            if draw_edge:\n",
    "                if draw_edge_int == 4:\n",
    "                    linewidth_factor = 1.5\n",
    "                else:\n",
    "                    linewidth_factor = 1\n",
    "                linewidth_factor *= 0.5\n",
    "\n",
    "                # Check if at least one atom is a linker atom\n",
    "                if fragment_mask[i] == 0 or fragment_mask[j] == 0:\n",
    "                    edge_color = 'gray'\n",
    "                    current_alpha = 0.5 * alpha\n",
    "                else:\n",
    "                    edge_color = hex_bg_color\n",
    "                    current_alpha = 0.7 * alpha\n",
    "                \n",
    "                ax.plot(\n",
    "                    [x[i], x[j]], [y[i], y[j]], [z[i], z[j]],\n",
    "                    linewidth=line_width * linewidth_factor * 2,\n",
    "                    c=edge_color,\n",
    "                    alpha=current_alpha\n",
    "                )\n",
    "\n",
    "    \n",
    "\n",
    "    if spheres_3d:\n",
    "        \n",
    "        for i, j, k, s, c, f, phi in zip(x, y, z, radii, colors, fragment_mask, phi_values):\n",
    "            if f == 1:\n",
    "                alpha = 1.0\n",
    "                if phi > 0:\n",
    "                    c = 'red'\n",
    "\n",
    "            draw_sphere_xai(ax, i.item(), j.item(), k.item(), 0.5 * s, c, alpha)\n",
    "\n",
    "    else:\n",
    "\n",
    "        #draw fragments\n",
    "        fragment_mask_on_cpu = fragment_mask.cpu().numpy()\n",
    "        colors_fragment = colors[fragment_mask_on_cpu == 1]\n",
    "        x_fragment = x[fragment_mask_on_cpu == 1]\n",
    "        y_fragment = y[fragment_mask_on_cpu == 1]\n",
    "        z_fragment = z[fragment_mask_on_cpu == 1]\n",
    "        areas_fragment = areas[fragment_mask_on_cpu == 1]\n",
    "        \n",
    "        if phi_values is not None and colors_fragment_shadow is None:\n",
    "            phi_values_array = np.array(phi_values)\n",
    "            # Calculate the gradient colors based on phi values\n",
    "            cmap = plt.cm.get_cmap('coolwarm_r') #reversed heatmap for distance-based importance\n",
    "            norm = plt.Normalize(vmin=min(phi_values_array), vmax=max(phi_values_array))\n",
    "            colors_fragment_shadow = cmap(norm(phi_values_array))\n",
    "        elif colors_fragment_shadow is not None and phi_values is None:\n",
    "            colors_fragment_shadow = colors_fragment_shadow\n",
    "        else:\n",
    "            raise ValueError(\"Either phi_values or colors_fragment_shadow must be provided, not both.\")\n",
    "        # ax.scatter(x_fragment, y_fragment, z_fragment, s=areas_fragment, alpha=0.9 * alpha, c=colors_fragment)\n",
    "\n",
    "        ax.scatter(x_fragment, y_fragment, z_fragment, s=areas_fragment, alpha=0.9 * alpha, c=colors_fragment_shadow, edgecolors=colors_fragment_shadow, linewidths=2.5, rasterized=False)\n",
    "        \n",
    "        if draw_atom_indices == \"original\":\n",
    "            #get fragment indices using fragment mask\n",
    "            fragment_indices = np.where(fragment_mask_on_cpu == 1)[0]\n",
    "            for i, txt in enumerate(fragment_indices):\n",
    "                ax.text(x_fragment[i], y_fragment[i], z_fragment[i], str(txt), color='black', fontsize=15)\n",
    "        \n",
    "        elif draw_atom_indices is None:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            for i, txt in enumerate(draw_atom_indices[0]):\n",
    "                ax.text(x_fragment[i], y_fragment[i], z_fragment[i], str(txt), color='black', fontsize=15)\n",
    "\n",
    "        \n",
    "\n",
    "        #draw non-fragment atoms\n",
    "        colors = np.array([0.25, 0.63, 0.38, 1]) \n",
    "        x = x[fragment_mask_on_cpu == 0]\n",
    "        y = y[fragment_mask_on_cpu == 0]\n",
    "        z = z[fragment_mask_on_cpu == 0]\n",
    "        areas = areas[fragment_mask_on_cpu == 0]\n",
    "        ax.scatter(x, y, z, s=areas, alpha=0.5 * alpha, color=colors, rasterized=False)\n",
    "\n",
    "        if draw_atom_indices == \"original\":\n",
    "            #get non-fragment indices using fragment mask\n",
    "            non_fragment_indices = np.where(fragment_mask_on_cpu == 0)[0]\n",
    "            for i, txt in enumerate(non_fragment_indices):\n",
    "                ax.text(x[i], y[i], z[i], str(txt), color='black', fontsize=15)\n",
    "        elif draw_atom_indices is None:\n",
    "            pass\n",
    "        else:\n",
    "            for i, txt in enumerate(draw_atom_indices[1]):\n",
    "                ax.text(x[i], y[i], z[i], str(txt), color='black', fontsize=15)        \n",
    "\n",
    "\n",
    "\n",
    "def plot_data3d_xai(positions, atom_type, is_geom, camera_elev=0, camera_azim=0, save_path=None, spheres_3d=False,\n",
    "                bg='black', alpha=1., fragment_mask=None, phi_values=None, colors_fragment_shadow=None, draw_atom_indices = False):\n",
    "    black = (0, 0, 0)\n",
    "    white = (1, 1, 1)\n",
    "    hex_bg_color = '#FFFFFF' if bg == 'black' else '#000000' #'#666666'\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.view_init(elev=camera_elev, azim=camera_azim)\n",
    "    if bg == 'black':\n",
    "        ax.set_facecolor(black)\n",
    "    else:\n",
    "        ax.set_facecolor(white)\n",
    "    ax.xaxis.pane.set_alpha(0)\n",
    "    ax.yaxis.pane.set_alpha(0)\n",
    "    ax.zaxis.pane.set_alpha(0)\n",
    "    ax._axis3don = False\n",
    "\n",
    "    if bg == 'black':\n",
    "        ax.w_xaxis.line.set_color(\"black\")\n",
    "    else:\n",
    "        ax.w_xaxis.line.set_color(\"white\")\n",
    "\n",
    "    plot_molecule_xai(\n",
    "        ax, positions, atom_type, alpha, spheres_3d, hex_bg_color, is_geom=is_geom, fragment_mask=fragment_mask, phi_values=phi_values, colors_fragment_shadow=colors_fragment_shadow, draw_atom_indices = draw_atom_indices\n",
    "    )\n",
    "\n",
    "    max_value = positions.abs().max().item()\n",
    "    axis_lim = min(40, max(max_value / 1.5 + 0.3, 3.2))\n",
    "    ax.set_xlim(-axis_lim, axis_lim)\n",
    "    ax.set_ylim(-axis_lim, axis_lim)\n",
    "    ax.set_zlim(-axis_lim, axis_lim)\n",
    "    dpi = 300 if spheres_3d else 300 #it was 120 and 50\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0.0, dpi=dpi)\n",
    "        # plt.savefig(save_path, bbox_inches='tight', pad_inches=0.0, dpi=dpi, transparent=True)\n",
    "\n",
    "        if spheres_3d:\n",
    "            img = imageio.imread(save_path)\n",
    "            img_brighter = np.clip(img * 1.4, 0, 255).astype('uint8')\n",
    "            imageio.imsave(save_path, img_brighter)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def visualize_chain_xai(\n",
    "        path, spheres_3d=False, bg=\"black\", alpha=1.0, wandb=None, mode=\"chain\", is_geom=False, fragment_mask=None, phi_values=None, colors_fragment_shadow=None, draw_atom_indices = False, file_indices = None\n",
    "):\n",
    "    files = load_xyz_files(path, file_indices=file_indices)\n",
    "    \n",
    "    save_paths = []\n",
    "\n",
    "    # Fit PCA to the final molecule â€“ to obtain the best orientation for visualization\n",
    "    positions, one_hot, charges = load_molecule_xyz(files[-1], is_geom=is_geom)\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(positions)\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        file = files[i]\n",
    "\n",
    "        positions, one_hot, charges = load_molecule_xyz(file, is_geom=is_geom)\n",
    "        atom_type = torch.argmax(one_hot, dim=1).numpy()\n",
    "\n",
    "        # Transform positions of each frame according to the best orientation of the last frame\n",
    "        positions = pca.transform(positions)\n",
    "        positions = torch.tensor(positions)\n",
    "\n",
    "        fn = file[:-4] + '.png'\n",
    "        plot_data3d_xai(\n",
    "            positions, atom_type,\n",
    "            save_path=fn,\n",
    "            spheres_3d=spheres_3d,\n",
    "            alpha=alpha,\n",
    "            bg=bg,\n",
    "            camera_elev=90,\n",
    "            camera_azim=90,\n",
    "            is_geom=is_geom,\n",
    "            fragment_mask=fragment_mask,\n",
    "            phi_values=phi_values,\n",
    "            colors_fragment_shadow=colors_fragment_shadow,\n",
    "            draw_atom_indices = draw_atom_indices\n",
    "        )\n",
    "        save_paths.append(fn)\n",
    "\n",
    "    imgs = [imageio.imread(fn) for fn in save_paths]\n",
    "    dirname = os.path.dirname(save_paths[0])\n",
    "    gif_path = dirname + '/output.gif'\n",
    "    imageio.mimsave(gif_path, imgs, subrectangles=True)\n",
    "\n",
    "    if wandb is not None:\n",
    "        wandb.log({mode: [wandb.Video(gif_path, caption=gif_path)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important atom analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = NUM_SAMPLES\n",
    "sampled = 0\n",
    "start = 0\n",
    "\n",
    "INTIAL_DISTIBUTION_PATH = \"initial_distributions/seed_\" + str(SEED)\n",
    "SHAPLEY_VALUES_FOLDER = \"results/shapley_values/\"\n",
    "\n",
    "data_list = []\n",
    "for data in dataloader:\n",
    "\n",
    "    if sampled < num_samples:\n",
    "        data_list.append(data)\n",
    "        sampled += 1\n",
    "\n",
    "\n",
    "# load initial distrubution of noisy features and positions\n",
    "noisy_features = torch.load(INTIAL_DISTIBUTION_PATH + \"/noisy_features_seed_\" + str(SEED) + \".pt\", map_location=device, weights_only=True)\n",
    "noisy_positions = torch.load(INTIAL_DISTIBUTION_PATH + \"/noisy_positions_seed_\" + str(SEED) + \".pt\", map_location=device, weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atom Perturbation/Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b68cf42229641c09e5a2f82c71dcb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:56:40] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[16:56:40] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7babdb0726b747bbbd6735ea2cef4140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:57:10] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[16:57:38] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50437918d5df4dc09194bc9a0850d299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:57:46] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[16:57:46] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[16:58:07] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[16:58:07] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[16:58:07] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[16:58:35] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf0493dc3ba426e921a79f7e32d36c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:59:06] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[16:59:06] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "Atom \"[C@@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b101eb04dae64a77b16cebf97f96843e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708aa719f08345d2a3079a78a785b088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:00:53] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6b7b19a9c4479ab77290b7e58455e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "[17:02:14] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:02:15] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a347de07f0334f13bc641ed0dbf5d6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:02:23] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "[17:03:12] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:03:12] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:03:12] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f64fe2cad94712b826ce8420bf2763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:03:20] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:03:40] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:03:41] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:03:41] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:04:09] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:04:09] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:04:09] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bbbd325f4c4697975e67d6ca910d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:04:17] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:04:35] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:04:36] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:04:36] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:04:36] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:04:36] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:04:36] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "[17:05:02] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "[17:05:02] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134224b469294a509c3b7a25a0b99c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:05:27] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n",
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "[17:05:52] WARNING: could not find number of expected rings. Switching to an approximate ring finding algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05eddeebfde442c28b03a411a6573cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_k_neighs_dict = {3:5, 4:3, 7:8, 10: 6, 13: 10, 14:5,  22: 5, 23: 9, 27: 10, 28:7, 29: 8}\n",
    "num_atom_type_perturbations = 1\n",
    "\n",
    "for data_index, data in enumerate(tqdm(data_list)):\n",
    "\n",
    "    if data_index not in top_k_neighs_dict.keys():\n",
    "        continue\n",
    "\n",
    "    top_k_neighs = top_k_neighs_dict[data_index]\n",
    "\n",
    "    smile = data[\"name\"][0]\n",
    "    mol = read_smiles(smile)\n",
    "\n",
    "    noisy_positions_present_atoms = noisy_positions.clone()\n",
    "    noisy_features_present_atoms = noisy_features.clone()\n",
    "\n",
    "    noisy_positions_present_atoms = noisy_positions_present_atoms[:, :data[\"positions\"].shape[1], :]\n",
    "    noisy_features_present_atoms = noisy_features_present_atoms[:, :data[\"one_hot\"].shape[1], :]\n",
    "\n",
    "    num_fragment_atoms = int(data[\"fragment_mask\"].sum().item())\n",
    "\n",
    "    #generate sample chain using original fragment atoms\n",
    "    \n",
    "    # print(\"Original molecule positions: \", data[\"positions\"])\n",
    "    \n",
    "    chain_batch_original, node_mask_original = model.sample_chain(data, keep_frames=keep_frames, noisy_positions=noisy_positions_present_atoms, noisy_features=noisy_features_present_atoms)\n",
    "    \n",
    "    #load Shapley values for Hausdorff distance\n",
    "    phi_values = []\n",
    "    \n",
    "    \n",
    "    with open(f\"{SHAPLEY_VALUES_FOLDER}explanations_hausdorff_distance_{P}_seed_{str(SEED)}_no_transform_transformation_seed_42_COM_addition/phi_atoms_{data_index}.txt\", \"r\") as read_file:\n",
    "        read_file.readline()\n",
    "        read_file.readline()\n",
    "        for row in read_file:\n",
    "            if row.strip() == \"\":\n",
    "                break\n",
    "            line = row.strip().split(\",\")\n",
    "            phi_values.append(float(line[1])) \n",
    "\n",
    "    \n",
    "    phi_values_array = np.array(phi_values)\n",
    "    cmap = plt.cm.get_cmap('coolwarm_r') #reversed heatmap for distance-based importance\n",
    "    norm = plt.Normalize(vmin=min(phi_values_array), vmax=max(phi_values_array))\n",
    "    colors_fragment_shadow = cmap(norm(phi_values_array))\n",
    "\n",
    "    #take first and only molecule\n",
    "    chain_batch_original_molecule = chain_batch_original[:, 0, :, :]\n",
    "    \n",
    "    chain_final_frame_0 = chain_batch_original_molecule[0, :, :]\n",
    "    chain_final_frame_0_batch = chain_final_frame_0.repeat(keep_frames, 1, 1)\n",
    "    original_linker_mask_batch = data[\"linker_mask\"][0].squeeze().repeat(keep_frames, 1).cpu()\n",
    "\n",
    "    # hausdorff_distance_original = compute_hausdorff_distance_batch(chain_final_frame_0_batch.cpu(), chain_final_frame_0_batch.cpu(), mask1=original_linker_mask_batch, mask2=original_linker_mask_batch)\n",
    "    \n",
    "    # print(\"Hausdorff distance between the frame 0 and the frame 0: \", hausdorff_distance_original)\n",
    "    # arrestomomentum()\n",
    "    # Compute the difference between the original positions and the positions in chain_batch_original_molecule\n",
    "    original_positions = data[\"positions\"][0]\n",
    "    chain_positions = chain_batch_original_molecule[0, :, :3]  # Assuming the first 3 columns are the positions\n",
    "\n",
    "    position_differences = original_positions - chain_positions\n",
    "    position_differences = position_differences[data[\"fragment_mask\"].squeeze().bool()][0]\n",
    "    \n",
    "    #add position differences to the chain_positions positions\n",
    "    chain_final_frame_0_batch[:, :, :3] = chain_final_frame_0_batch[:, :, :3] + position_differences\n",
    "    chain_batch_original_molecule[:, :, :3] = chain_batch_original_molecule[:, :, :3] + position_differences\n",
    "    \n",
    "    #compute Hausdorff distance between the frame 0 and the rest of the frames\n",
    "    hausdorff_distances_original = compute_hausdorff_distance_batch(chain_final_frame_0_batch.cpu(), chain_batch_original_molecule.cpu(), mask1=original_linker_mask_batch, mask2=original_linker_mask_batch) #the linker atoms are the same since those are the frames of a single molecule\n",
    "    # print(\"Node mask original: \", node_mask_original)\n",
    "    # hausdorff_distances_original_projected = compute_hausdorff_distance_batch(chain_final_frame_0_batch.cpu(), chain_batch_original_molecule.cpu(), mask1=original_linker_mask_batch, mask2=original_linker_mask_batch) #the linker atoms are the same since those are the frames of a single molecule\n",
    "    # hausdorff_distances_original_projected = compute_hausdorff_distance_batch(chain_final_frame_0_batch.cpu(), chain_batch_original_molecule.cpu(), mask1=original_linker_mask_batch, mask2=original_linker_mask_batch, project=\"origin\")\n",
    "    # print(\"Hausdorff distances: \", hausdorff_distances_original)\n",
    "    \n",
    "    \n",
    "\n",
    "    #save and visualize original chain\n",
    "\n",
    "    for i in range(len(data['positions'])):\n",
    "            chain = chain_batch_original[:, i, :, :]\n",
    "            assert chain.shape[0] == keep_frames\n",
    "            assert chain.shape[1] == data['positions'].shape[1]\n",
    "            assert chain.shape[2] == data['positions'].shape[2] + data['one_hot'].shape[2] + model.include_charges\n",
    "\n",
    "            # Saving chains\n",
    "            name = str(i + start)\n",
    "            if ATOM_PERTURBATION:\n",
    "                chain_output = os.path.join(chains_output_dir, str(data_index), \"original\")\n",
    "            elif REMOVAL:\n",
    "                chain_output = os.path.join(chains_output_dir, str(data_index), \"original\")\n",
    "            os.makedirs(chain_output, exist_ok=True)\n",
    "            \n",
    "            #save initial random distrubution with noise\n",
    "            positions_combined = torch.zeros_like(data['positions'])\n",
    "            one_hot_combined = torch.zeros_like(data['one_hot'])\n",
    "\n",
    "            # Iterate over each atom and decide whether to use original or noisy data\n",
    "            for atom_idx in range(data['positions'].shape[1]):\n",
    "                if data['fragment_mask'][0, atom_idx] == 1:\n",
    "                    # Use original positions and features for fragment atoms\n",
    "                    positions_combined[:, atom_idx, :] = data['positions'][:, atom_idx, :]\n",
    "                    one_hot_combined[:, atom_idx, :] = data['one_hot'][:, atom_idx, :]\n",
    "                    # atom_mask_combined[:, atom_idx] = data['atom_mask'][:, atom_idx]\n",
    "                else:\n",
    "                    # Use noisy positions and features for linker atoms\n",
    "                    positions_combined[:, atom_idx, :] = noisy_positions_present_atoms[:, atom_idx, :]\n",
    "                    one_hot_combined[:, atom_idx, :] = noisy_features_present_atoms[:, atom_idx, :]\n",
    "\n",
    "            #save initial distribution TODO: fix positions, they are not centered\n",
    "            \n",
    "            save_xyz_file(\n",
    "                chain_output,\n",
    "                one_hot_combined,\n",
    "                positions_combined,\n",
    "                node_mask_original[i].unsqueeze(0),\n",
    "                names=[f'{name}_' + str(keep_frames)],\n",
    "                is_geom=model.is_geom\n",
    "            )\n",
    "\n",
    "            \n",
    "            # one_hot = chain[:, :, 3:-1]\n",
    "            one_hot = chain[:, :, 3:] #@mastro, added last atom type (not sure whyt it was not included...) However, TODO check again\n",
    "            positions = chain[:, :, :3]\n",
    "            chain_node_mask = torch.cat([node_mask_original[i].unsqueeze(0) for _ in range(keep_frames)], dim=0)\n",
    "            names = [f'{name}_{j}' for j in range(keep_frames)]\n",
    "\n",
    "            save_xyz_file(chain_output, one_hot, positions, chain_node_mask, names=names, is_geom=model.is_geom)\n",
    "\n",
    "            visualize_chain_xai(\n",
    "                chain_output,\n",
    "                spheres_3d=False,\n",
    "                alpha=1.0,\n",
    "                bg='white',\n",
    "                is_geom=model.is_geom,\n",
    "                fragment_mask=data['fragment_mask'][i].squeeze(),\n",
    "                phi_values=None,\n",
    "                colors_fragment_shadow=colors_fragment_shadow,\n",
    "                draw_atom_indices=\"original\"\n",
    "            )\n",
    "\n",
    "            names.append(f\"{name}_{keep_frames}\")\n",
    "            for the_name in names:\n",
    "                generated_file = os.path.join(chain_output, the_name +\"_.xyz\")\n",
    "                positions, one_hot, _ = load_molecule_xyz(generated_file, is_geom=False)\n",
    "                \n",
    "                atom_types = torch.argmax(one_hot, dim=1).cpu().numpy()\n",
    "            \n",
    "                # Convert positions and atom types to an RDKit molecule\n",
    "                mol = Chem.RWMol()\n",
    "                atom_map = {}\n",
    "\n",
    "                # Add atoms to the molecule\n",
    "                for idx, atom_type in enumerate(atom_types):\n",
    "                    atom = Chem.Atom(const.IDX2ATOM[atom_type])\n",
    "                    atom_idx = mol.AddAtom(atom)\n",
    "                    atom_map[idx] = atom_idx\n",
    "\n",
    "                # Add bonds based on positions and bond order\n",
    "                for idx1 in range(len(positions)):\n",
    "                    for idx2 in range(idx1 + 1, len(positions)):\n",
    "                        dist = np.linalg.norm(positions[idx1] - positions[idx2])\n",
    "                        bond_order = has_bond(const.IDX2ATOM[atom_types[idx1]], const.IDX2ATOM[atom_types[idx2]], dist)\n",
    "                        \n",
    "                        if bond_order > 0:\n",
    "                            bond_type = const.BOND_DICT[bond_order]\n",
    "                            mol.AddBond(atom_map[idx1], atom_map[idx2], bond_type)\n",
    "                            \n",
    "                            if bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "                                bond = mol.GetBondBetweenAtoms(atom_map[idx1], atom_map[idx2])\n",
    "                                bond.SetIsAromatic(True)\n",
    "\n",
    "                # Highlight fragment atoms and edges\n",
    "                fragment_mask_highlight = data['fragment_mask'][0].cpu().numpy()\n",
    "                \n",
    "                linker_mask = data[\"linker_mask\"].squeeze().bool()\n",
    "                #\n",
    "                linker_color = (0.25, 0.63, 0.38, 0.7)  # Emerald green color\n",
    "                \n",
    "                linker_colors = np.tile(linker_color, (linker_mask.sum().item(), 1))  # Repeat emerald green for each linker atom\n",
    "                colors_fragment_shadow_padded = np.vstack([colors_fragment_shadow, linker_colors])  # Append linker colors\n",
    "                \n",
    "\n",
    "                # highlight_colors = {idx: colors_fragment_shadow_padded[idx] for idx, mask in enumerate(fragment_mask_highlight) if mask == 1}\n",
    "                highlight_colors = {idx: color for idx, color in enumerate(colors_fragment_shadow_padded)}\n",
    "\n",
    "                highlight_atoms = list(highlight_colors.keys())\n",
    "                highlight_bonds = []\n",
    "                for bond in mol.GetBonds():\n",
    "                    if bond.GetBeginAtomIdx() in highlight_atoms and bond.GetEndAtomIdx() in highlight_atoms:\n",
    "                        highlight_bonds.append(bond.GetIdx())\n",
    "                \n",
    "                # Assign bond colors based on the colors of the connected atoms\n",
    "                bond_colors = {}\n",
    "            \n",
    "                # Convert to RDKit molecule and draw\n",
    "                mol = mol.GetMol()\n",
    "                atom_colors = {idx: list(map(float, color[:3])) for idx, color in highlight_colors.items()}  # Convert to lists of floats\n",
    "                atom_colors = {key: [tuple(value)] for key, value in atom_colors.items()}\n",
    "                \n",
    "                # Draw linker bonds and atoms in emerald green\n",
    "                \n",
    "                linker_mask_highlight = data['linker_mask'][0].cpu().numpy()\n",
    "                \n",
    "                # Update atom colors for linker atoms\n",
    "                # for idx, mask in enumerate(linker_mask_highlight):\n",
    "                #     if mask == 1:\n",
    "                #         atom_colors[idx] = [0.25, 0.63, 0.38]  # Set emerald green for linker atoms\n",
    "                \n",
    "                # Update bond colors for linker bonds\n",
    "                n_linker_atoms = linker_mask.sum().item()\n",
    "                linker_atoms_indices_in_color_fragment_shadow = np.arange(len(colors_fragment_shadow_padded) - n_linker_atoms, len(colors_fragment_shadow_padded))\n",
    "                \n",
    "                for bond in mol.GetBonds():\n",
    "                    begin_idx = bond.GetBeginAtomIdx()\n",
    "                    end_idx = bond.GetEndAtomIdx()\n",
    "                    if begin_idx in linker_atoms_indices_in_color_fragment_shadow and end_idx in linker_atoms_indices_in_color_fragment_shadow:\n",
    "                        bond_colors[bond.GetIdx()] = [linker_color]  # Set emerald green for linker bonds\n",
    "                \n",
    "                # Use DrawMoleculeWithHighlights for visualization\n",
    "                atom_radii = {idx: 0.5 for idx in range(len(colors_fragment_shadow_padded))}  # Default atom radius for fragment atoms\n",
    "                # Set radius 0.3 for linker atoms\n",
    "                n_linker_atoms = linker_mask.sum().item()\n",
    "                for idx in range(len(atom_radii) - n_linker_atoms, len(atom_radii)):\n",
    "                    atom_radii[idx] = 0.3\n",
    "                    \n",
    "                # print(\"Atom radii: \", atom_radii)\n",
    "                # print(\"Bond colors: \", bond_colors)\n",
    "                # print(\"color fragmen shadow length: \", len(colors_fragment_shadow_padded))\n",
    "                # arrestomomentum()\n",
    "                drawer = Draw.MolDraw2DCairo(800, 800)\n",
    "                draw_options = drawer.drawOptions()\n",
    "                draw_options.useBWAtomPalette()\n",
    "                draw_options.kekulize = False\n",
    "                \n",
    "                drawer.DrawMoleculeWithHighlights(\n",
    "                    mol,\n",
    "                    \"\",  # Legend\n",
    "                    atom_colors,  # Atom colors (highlight_atom_map)\n",
    "                    bond_colors,  # Bond colors (highlight_bond_map)\n",
    "                    atom_radii,  # Atom radii\n",
    "                    {}  # Bond linewidth multipliers\n",
    "                )\n",
    "\n",
    "                drawer.FinishDrawing()\n",
    "                # Convert the drawing to a PNG image\n",
    "                png_data = drawer.GetDrawingText()\n",
    "                with open(\"temp_image.png\", \"wb\") as f:\n",
    "                    f.write(png_data)\n",
    "\n",
    "                # Load the PNG image using PIL\n",
    "                img = Image.open(\"temp_image.png\")\n",
    "                # img.show()\n",
    "                \n",
    "                output_file = os.path.join(chain_output, the_name + \"_structure.png\")\n",
    "                img.save(output_file, dpi=(300, 300))\n",
    "\n",
    "            # Visualize the generated molecule\n",
    "            \n",
    "            # Saving final prediction and ground truth separately\n",
    "            true_one_hot = data['one_hot'][i].unsqueeze(0)\n",
    "            true_positions = data['positions'][i].unsqueeze(0)\n",
    "            true_node_mask = data['atom_mask'][i].unsqueeze(0)\n",
    "\n",
    "            #TODO chech if the final positions are saved in the correct folder\n",
    "            final_states_output_dir_current = None\n",
    "\n",
    "            if REMOVAL:\n",
    "                final_states_output_dir_current = os.path.join(final_states_output_dir, str(data_index), \"original\")\n",
    "            if ATOM_PERTURBATION:\n",
    "                final_states_output_dir_current = os.path.join(final_states_output_dir, str(data_index), \"original\")\n",
    "           \n",
    "            os.makedirs(final_states_output_dir_current, exist_ok=True)\n",
    "            save_xyz_file(\n",
    "                final_states_output_dir_current,\n",
    "                true_one_hot,\n",
    "                true_positions,\n",
    "                true_node_mask,\n",
    "                names=[f'{name}_true'],\n",
    "                is_geom=model.is_geom,\n",
    "            )\n",
    "\n",
    "            pred_one_hot = chain[0, :, 3:-1].unsqueeze(0)\n",
    "            pred_positions = chain[0, :, :3].unsqueeze(0)\n",
    "            pred_node_mask = chain_node_mask[0].unsqueeze(0)\n",
    "            save_xyz_file(\n",
    "                final_states_output_dir_current,\n",
    "                pred_one_hot,\n",
    "                pred_positions,\n",
    "                pred_node_mask,\n",
    "                names=[f'{name}_pred'],\n",
    "                is_geom=model.is_geom\n",
    "            )\n",
    "\n",
    "    \n",
    "    # Create a line plot for Hausdorff distances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.gca().set_facecolor('white')\n",
    "    #reverse hausdorff distances\n",
    "    hausdorff_distances_original = hausdorff_distances_original[::-1]\n",
    "    sns.lineplot(data=hausdorff_distances_original, marker='o')\n",
    "    #plt.title('Hausdorff Distance Trend')\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Hausdorff Distance')\n",
    "    plt.xticks(ticks=range(keep_frames), labels=range(keep_frames-1, -1, -1))  # Show all 10 frames on the x-axis\n",
    "    plt.ylim(bottom=0)  # Ensure the y-axis starts at 0\n",
    "    #add white background\n",
    "\n",
    "\n",
    "\n",
    "    SAVE_PATH = f\"results/plots/neighbor_analysis_COM_addition/{data_index}/\"\n",
    "\n",
    "    if ATOM_PERTURBATION:\n",
    "        if TOP_K_PERTURBATION_REMOVAL:\n",
    "            SAVE_PATH += \"perturbation_top_k/\"\n",
    "        else:\n",
    "            SAVE_PATH += \"perturbation/\"\n",
    "\n",
    "    elif REMOVAL:\n",
    "        if TOP_K_PERTURBATION_REMOVAL:\n",
    "            SAVE_PATH += \"removal_top_k/\"\n",
    "        else:\n",
    "            SAVE_PATH += \"removal/\"\n",
    "\n",
    "    if LOCAL_MINIMUM_ANALYSIS:\n",
    "        SAVE_PATH = SAVE_PATH.replace(\"neighbor_analysis_COM_addition\", \"neighbor_analysis_COM_addition_local_min_analysis\")\n",
    "\n",
    "\n",
    "    os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "    plt.savefig(SAVE_PATH + \"hausdorff_distance_trend_original.png\", dpi = 300)\n",
    "    plt.savefig(SAVE_PATH + \"hausdorff_distance_trend_original.pdf\", dpi = 300)\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "    # Save hausdorff_distances_original to a file using pickle\n",
    "    hausdorff_distances_original_path = os.path.join(SAVE_PATH, \"hausdorff_distances_original.pkl\")\n",
    "    with open(hausdorff_distances_original_path, \"wb\") as f:\n",
    "        pickle.dump(hausdorff_distances_original, f)\n",
    "        \n",
    "    fragment_mask = data[\"fragment_mask\"].squeeze().bool()\n",
    "    linker_mask = data[\"linker_mask\"].squeeze().bool()\n",
    "    phi_values_tensor = torch.tensor(phi_values)\n",
    "\n",
    "    #get indices of phi_values_tensor from lower to higher\n",
    "    sorted_phi_values, sorted_indices = torch.sort(phi_values_tensor)\n",
    "    # reversed_indices = torch.flip(sorted_indices, [0])\n",
    "\n",
    "    #take top k neighbors\n",
    "    shapley_value_indices_keep = sorted_indices[top_k_neighs:]\n",
    "    top_indices_to_perturb = sorted_indices[:top_k_neighs]\n",
    "    sorted_phi_values = sorted_phi_values[:top_k_neighs]\n",
    "    # print(\"Top k neighbors: \", top_indices_to_perturb)\n",
    "    # print(\"shapley_value_indices_keep: \", shapley_value_indices_keep)\n",
    "    # #print linker atoms\n",
    "    # print(\"Linker atoms: \", torch.where(linker_mask)[0])\n",
    "    # #print fragment atoms\n",
    "    # print(\"Fragment atoms: \", torch.where(fragment_mask)[0])\n",
    "    \n",
    "    for swap_num in tqdm(range(num_atom_type_perturbations)):\n",
    "        # data_temp = data.copy()\n",
    "        data_temp = copy.deepcopy(data)\n",
    "        \n",
    "\n",
    "        noisy_positions_present_atoms_temp = noisy_positions_present_atoms.clone()\n",
    "        noisy_features_present_atoms_temp = noisy_features_present_atoms.clone()\n",
    "        \n",
    "    \n",
    "        \n",
    "        #retrieve indices of fragment and linker atoms from atom_mask\n",
    "        fragment_atoms_indices = torch.where(fragment_mask)[0]\n",
    "        fragment_atoms_indices = fragment_atoms_indices.to(device)\n",
    "        linker_atoms_indices = torch.where(linker_mask)[0]\n",
    "        linker_atoms_indices = linker_atoms_indices.to(device)\n",
    "        \n",
    "        # Randomly change atom type (one_hot) for the atoms at the indices top_indices_to_perturb\n",
    "\n",
    "        if ATOM_PERTURBATION:\n",
    "\n",
    "            if not TOP_K_PERTURBATION_REMOVAL:\n",
    "                for idx in top_indices_to_perturb:\n",
    "                    if data_temp[\"anchors\"][0, idx] == 1: #we leave anchor atoms as they are since we are analyzing the neighbors\n",
    "                        continue\n",
    "                    current_atom_type = torch.argmax(data_temp[\"one_hot\"][:, idx, :], dim=1, keepdim=True)\n",
    "                    stop = False\n",
    "                    while not stop:\n",
    "                        random_atom_type = torch.randint(0, data_temp[\"one_hot\"].shape[2], (1,), device=device)\n",
    "                        if random_atom_type != current_atom_type:\n",
    "                            stop = True\n",
    "                    data_temp[\"one_hot\"][:, idx, :] = 0\n",
    "                    data_temp[\"one_hot\"][:, idx, random_atom_type] = 1\n",
    "            else:\n",
    "                if swap_num == 0:\n",
    "                    for idx in top_indices_to_perturb:\n",
    "                        if data_temp[\"anchors\"][0, idx] == 1: #we leave anchor atoms as they are since we are analyzing the neighbors\n",
    "                            continue\n",
    "                        current_atom_type = torch.argmax(data_temp[\"one_hot\"][:, idx, :], dim=1, keepdim=True)\n",
    "                        stop = False\n",
    "                        while not stop:\n",
    "                            random_atom_type = torch.randint(0, data_temp[\"one_hot\"].shape[2], (1,), device=device)\n",
    "                            if random_atom_type != current_atom_type:\n",
    "                                stop = True\n",
    "                        data_temp[\"one_hot\"][:, idx, :] = 0\n",
    "                        data_temp[\"one_hot\"][:, idx, random_atom_type] = 1\n",
    "                else:                    \n",
    "                    num_atoms_to_perturb = min(swap_num, len(top_indices_to_perturb))\n",
    "                    \n",
    "                    if num_atoms_to_perturb > len(top_indices_to_perturb):\n",
    "                        continue\n",
    "                    else:\n",
    "                        for idx in top_indices_to_perturb[:num_atoms_to_perturb]:\n",
    "                            if data_temp[\"anchors\"][0, idx] == 1:  # we leave anchor atoms as they are since we are analyzing the neighbors\n",
    "                                continue\n",
    "                            current_atom_type = torch.argmax(data_temp[\"one_hot\"][:, idx, :], dim=1, keepdim=True)\n",
    "                            stop = False\n",
    "                            while not stop:\n",
    "                                random_atom_type = torch.randint(0, data_temp[\"one_hot\"].shape[2], (1,), device=device)\n",
    "                                if random_atom_type != current_atom_type:\n",
    "                                    stop = True\n",
    "                            data_temp[\"one_hot\"][:, idx, :] = 0\n",
    "                            data_temp[\"one_hot\"][:, idx, random_atom_type] = 1\n",
    "\n",
    "    \n",
    "        if REMOVAL:\n",
    "\n",
    "            #keep only elements from fragment_atoms_indices at the indices in shapley_value_indices_keep\n",
    "            fragment_atoms_indices_keep = None\n",
    "\n",
    "            # if swap_num == 0:\n",
    "            #     #no atom is removed\n",
    "            #     fragment_atoms_indices_keep = fragment_atoms_indices\n",
    "            if not TOP_K_PERTURBATION_REMOVAL:\n",
    "                if swap_num == 0: #at the first iteration, we remove all top k and make sure anchor atoms are kept\n",
    "                    fragment_atoms_indices_keep = torch.cat((shapley_value_indices_keep.to(device), torch.where(data_temp[\"anchors\"].squeeze() == 1)[0].to(device)))\n",
    "                \n",
    "                else:\n",
    "                    # num_atoms_to_add = min(len(top_indices_to_perturb), 3)  # Number of atoms to randomly select and add\n",
    "                    num_atoms_to_add = np.random.randint(1, len(top_indices_to_perturb))\n",
    "                    random_atoms_to_add = np.random.choice(top_indices_to_perturb.cpu().numpy(), num_atoms_to_add, replace=False)\n",
    "                    fragment_atoms_indices_keep = torch.cat((shapley_value_indices_keep.to(device), torch.tensor(random_atoms_to_add, device=device)))\n",
    "            else:\n",
    "                if swap_num == 0:\n",
    "                    #at the first iteration, we remove all top k and make sure anchor atoms are kept\n",
    "                    fragment_atoms_indices_keep = torch.cat((shapley_value_indices_keep.to(device), torch.where(data_temp[\"anchors\"].squeeze() == 1)[0].to(device)))\n",
    "                else:\n",
    "                    num_atoms_to_perturb = min(swap_num , len(top_indices_to_perturb))\n",
    "                        \n",
    "                    if num_atoms_to_perturb > len(top_indices_to_perturb):\n",
    "                        continue\n",
    "                    else:\n",
    "                        fragment_atoms_indices_keep = torch.cat((shapley_value_indices_keep.to(device), top_indices_to_perturb[num_atoms_to_perturb:].to(device)))\n",
    "                            \n",
    "            \n",
    "            #remove duplicates\n",
    "            fragment_atoms_indices_keep = torch.unique(fragment_atoms_indices_keep)\n",
    "                \n",
    "            # print(\"Anchor atoms: \", torch.where(data_temp[\"anchors\"].squeeze() == 1)[0])\n",
    "            # print(\"fragment_atoms_indices_keep: \", fragment_atoms_indices_keep)\n",
    "\n",
    "            # fragment_atoms_indices_keep = fragment_atoms_indices[shapley_value_indices_keep]\n",
    "            fragment_atoms_indices_keep_tensor = torch.Tensor(fragment_atoms_indices_keep).to(device)\n",
    "            \n",
    "            #keep only fragment_atoms_indices_keep and linker_atoms_indices\n",
    "            atom_indices_to_keep = torch.cat((fragment_atoms_indices_keep_tensor, linker_atoms_indices)).to(device)\n",
    "\n",
    "            #remove atoms from molecule\n",
    "            data_temp[\"positions\"] = data_temp[\"positions\"][:, atom_indices_to_keep, :]\n",
    "            data_temp[\"one_hot\"] = data_temp[\"one_hot\"][:, atom_indices_to_keep, :]\n",
    "            data_temp[\"charges\"] = data_temp[\"charges\"][:, atom_indices_to_keep]\n",
    "            data_temp[\"fragment_mask\"] = data_temp[\"fragment_mask\"][:, atom_indices_to_keep]\n",
    "            data_temp[\"linker_mask\"] = data_temp[\"linker_mask\"][:, atom_indices_to_keep]\n",
    "            data_temp[\"atom_mask\"] = data_temp[\"atom_mask\"][:, atom_indices_to_keep]\n",
    "            data_temp[\"anchors\"] = data_temp[\"anchors\"][:, atom_indices_to_keep]\n",
    "            edge_mask_to_keep = (data_temp[\"atom_mask\"].unsqueeze(1) * data_temp[\"atom_mask\"]).flatten()\n",
    "            data_temp[\"edge_mask\"] = edge_mask_to_keep\n",
    "\n",
    "            #remove atoms from noisy features and positions\n",
    "            noisy_positions_present_atoms_temp = noisy_positions_present_atoms_temp[:, atom_indices_to_keep, :]\n",
    "            noisy_features_present_atoms_temp = noisy_features_present_atoms_temp[:, atom_indices_to_keep, :]\n",
    "\n",
    "        phi_values_array = np.array(phi_values)\n",
    "        cmap = plt.cm.get_cmap('coolwarm_r') #reversed heatmap for distance-based importance\n",
    "        norm = plt.Normalize(vmin=min(phi_values_array), vmax=max(phi_values_array))\n",
    "        colors_fragment_shadow_original = cmap(norm(phi_values_array))\n",
    "        # print(\"Colors fragment shadow original shape: \", colors_fragment_shadow_original.shape)\n",
    "        colors_fragment_shadow = cmap(norm(phi_values_array))\n",
    "        #remove atoms from color array\n",
    "        \n",
    "        molecule_perturbation_original_positions = data_temp[\"positions\"].clone()[0]\n",
    "\n",
    "        if REMOVAL:\n",
    "            # print(\"Color fragment shadow shape: \", colors_fragment_shadow.shape)\n",
    "            colors_fragment_shadow = colors_fragment_shadow[fragment_atoms_indices_keep.cpu().numpy()]\n",
    "            # print(\"Color fragment shadow shape after: \", colors_fragment_shadow.shape)\n",
    "        if not LOCAL_MINIMUM_ANALYSIS:\n",
    "            chain_batch, node_mask = model.sample_chain(data_temp, keep_frames=keep_frames, noisy_positions=noisy_positions_present_atoms_temp, noisy_features=noisy_features_present_atoms_temp)\n",
    "        else:\n",
    "            chain_before_injection, node_mask_before_injection, chain_after_injection, node_mask_after_injection = model.sample_chain_atom_injection(data_temp, keep_frames=keep_frames, noisy_positions=noisy_positions_present_atoms_temp, noisy_features=noisy_features_present_atoms_temp, orginal_data = data, noisy_positions_original = noisy_positions_present_atoms, noisy_features_original = noisy_features_present_atoms, atom_indices_kept = atom_indices_to_keep, injection_step = injection_step)\n",
    "\n",
    "            \n",
    "        \n",
    "        if not LOCAL_MINIMUM_ANALYSIS:\n",
    "            #compute Hausdorff distance with orignal linker\n",
    "            chain_batch_molecule_pertubation = chain_batch[:, 0, :, :]\n",
    "        else:\n",
    "            chain_batch_molecule_pertubation_before_injection = chain_before_injection[:, 0, :, :]\n",
    "            chain_batch_molecule_pertubation_after_injection = chain_after_injection[:, 0, :, :]\n",
    "\n",
    "            # Get the indices of tensors with all zero elements for the two chains\n",
    "            # Remove tensors with all zero elements from chain_batch_molecule_pertubation_before_injection\n",
    "            non_zero_indices_before_injection = torch.any(chain_batch_molecule_pertubation_before_injection != 0, dim=(1, 2))\n",
    "            chain_batch_molecule_pertubation_before_injection = chain_batch_molecule_pertubation_before_injection[non_zero_indices_before_injection]\n",
    "\n",
    "            # Remove tensors with all zero elements from chain_batch_molecule_pertubation_after_injection\n",
    "            non_zero_indices_after_injection = torch.any(chain_batch_molecule_pertubation_after_injection != 0, dim=(1, 2))\n",
    "            chain_batch_molecule_pertubation_after_injection = chain_batch_molecule_pertubation_after_injection[non_zero_indices_after_injection]\n",
    "\n",
    "            # print(\"Chain batch molecule perturbation before injection shape: \", chain_batch_molecule_pertubation_before_injection.shape)\n",
    "            # print(\"Chain batch molecule perturbation after injection shape: \", chain_batch_molecule_pertubation_after_injection.shape)\n",
    "            \n",
    "\n",
    "        mask_to_use = None\n",
    "        if not LOCAL_MINIMUM_ANALYSIS:\n",
    "            if REMOVAL:\n",
    "                mask_to_use = data_temp[\"linker_mask\"][0].squeeze().repeat(keep_frames, 1).cpu()\n",
    "            else:\n",
    "                mask_to_use = original_linker_mask_batch\n",
    "\n",
    "            chain_perturbation_positions = chain_batch_molecule_pertubation[0, :, :3]  # Assuming the first 3 columns are the positions\n",
    "\n",
    "            position_differences_perturb = molecule_perturbation_original_positions - chain_perturbation_positions\n",
    "            position_differences_perturb = position_differences_perturb[data_temp[\"fragment_mask\"].squeeze().bool()][0]\n",
    "\n",
    "            chain_batch_molecule_pertubation[:, :, :3] = chain_batch_molecule_pertubation[:, :, :3] + position_differences_perturb\n",
    "\n",
    "            hausdorff_distances_perturbation = compute_hausdorff_distance_batch(chain_final_frame_0_batch.cpu(), chain_batch_molecule_pertubation.cpu(), mask1=original_linker_mask_batch, mask2=mask_to_use) #the linker atoms are the same since those are the frames of a single molecule\n",
    "        else:\n",
    "            mask_to_use_before_injection = data_temp[\"linker_mask\"][0].squeeze().repeat(keep_frames, 1).cpu()\n",
    "            mask_to_use_after_injection = original_linker_mask_batch\n",
    "            \n",
    "            chain_perturbation_positions_before_injection = chain_batch_molecule_pertubation_before_injection[0, :, :3]  # Assuming the first 3 columns are the positions\n",
    "            chain_perturbation_positions_after_injection = chain_batch_molecule_pertubation_after_injection[0, :, :3]  # Assuming the first 3 columns are the positions\n",
    "\n",
    "            position_differences_perturb_before_injection = molecule_perturbation_original_positions - chain_perturbation_positions_before_injection\n",
    "            position_differences_perturb_before_injection = position_differences_perturb_before_injection[data_temp[\"fragment_mask\"].squeeze().bool()][0]\n",
    "\n",
    "            position_differences_perturb_after_injection = original_positions - chain_perturbation_positions_after_injection\n",
    "            position_differences_perturb_after_injection = position_differences_perturb_after_injection[data[\"fragment_mask\"].squeeze().bool()][0]\n",
    "\n",
    "            chain_batch_molecule_pertubation_before_injection[:, :, :3] = chain_batch_molecule_pertubation_before_injection[:, :, :3] + position_differences_perturb_before_injection\n",
    "            chain_batch_molecule_pertubation_after_injection[:, :, :3] = chain_batch_molecule_pertubation_after_injection[:, :, :3] + position_differences_perturb_after_injection\n",
    "\n",
    "            chain_final_frame_0_batch_before_injection = chain_final_frame_0.repeat(chain_batch_molecule_pertubation_before_injection.shape[0], 1, 1)\n",
    "            # print(\"chain_final_frame_0_batch_before_injection shape: \", chain_final_frame_0_batch_before_injection.shape)\n",
    "            # print(\"chain_batch_molecule_pertubation_before_injection shape: \", chain_batch_molecule_pertubation_before_injection.shape)\n",
    "            hausdorff_distances_perturbation_before_injection = compute_hausdorff_distance_batch(chain_final_frame_0_batch_before_injection.cpu(), chain_batch_molecule_pertubation_before_injection.cpu(), mask1=original_linker_mask_batch, mask2=mask_to_use_before_injection) #the linker atoms are the same since those are the frames of a single molecule\n",
    "\n",
    "            chain_final_frame_0_batch_after_injection = chain_final_frame_0.repeat(chain_batch_molecule_pertubation_after_injection.shape[0], 1, 1)\n",
    "            hausdorff_distances_perturbation_after_injection = compute_hausdorff_distance_batch(chain_final_frame_0_batch_after_injection.cpu(), chain_batch_molecule_pertubation_after_injection.cpu(), mask1=original_linker_mask_batch, mask2=mask_to_use_after_injection) #the linker atoms are the same since those are the frames of a single molecule\n",
    "\n",
    "            #the two hausdorff distance lists should be concatenated\n",
    "            #TODO check if the concatenation is correct!\n",
    "            hausdorff_distances_perturbation = hausdorff_distances_perturbation_after_injection + hausdorff_distances_perturbation_before_injection\n",
    "\n",
    "            # print(\"Hausdorff distances before injection: \", hausdorff_distances_perturbation_before_injection)\n",
    "            # print(\"Hausdorff distances after injection: \", hausdorff_distances_perturbation_after_injection)\n",
    "            # print(\"Hausdorff distances after perturbation: \", hausdorff_distances_perturbation)\n",
    "\n",
    "            \n",
    "        # print(\"Hausdorff distances after perturbation: \", hausdorff_distances_perturbation)\n",
    "        \n",
    "        \n",
    "        # Create a line plot for Hausdorff distances\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.gca().set_facecolor('white')\n",
    "        #reverse hausdorff distances\n",
    "        hausdorff_distances_perturbation = hausdorff_distances_perturbation[::-1]\n",
    "        sns.lineplot(data=hausdorff_distances_perturbation, marker='o')\n",
    "        #plt.title('Hausdorff Distance Trend')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Hausdorff Distance')\n",
    "        plt.xticks(ticks=range(keep_frames), labels=range(keep_frames-1, -1, -1))  # Show all 10 frames on the x-axis\n",
    "        plt.ylim(bottom=0)  # Ensure the y-axis starts at 0\n",
    "        \n",
    "\n",
    "        os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "        plt.savefig(SAVE_PATH + f\"hausdorff_distance_trend_{swap_num}.png\", dpi = 300)\n",
    "        plt.savefig(SAVE_PATH + f\"hausdorff_distance_trend_{swap_num}.pdf\", dpi = 300)\n",
    "        # chain_with_full_fragments = chain_batch[0, :, :, :]\n",
    "        plt.close()\n",
    "        #save and visualize chain (only for the linker use noisy positions for the initial distribution)\n",
    "        \n",
    "        # Save hausdorff_distances_perturbation to a file using pickle\n",
    "        hausdorff_distances_perturbation_path = os.path.join(SAVE_PATH, f\"hausdorff_distances_perturbation_{swap_num}.pkl\")\n",
    "        with open(hausdorff_distances_perturbation_path, \"wb\") as f:\n",
    "            pickle.dump(hausdorff_distances_perturbation, f)\n",
    "            \n",
    "        if not LOCAL_MINIMUM_ANALYSIS:\n",
    "            for i in range(len(data_temp['positions'])):\n",
    "                chain = chain_batch[:, i, :, :]\n",
    "                assert chain.shape[0] == keep_frames\n",
    "                assert chain.shape[1] == data_temp['positions'].shape[1]\n",
    "                assert chain.shape[2] == data_temp['positions'].shape[2] + data_temp['one_hot'].shape[2] + model.include_charges\n",
    "\n",
    "                # Saving chains\n",
    "                name = str(i + start)\n",
    "                if ATOM_PERTURBATION:\n",
    "                    chain_output = os.path.join(chains_output_dir, str(data_index), \"perturbation_\" + str(swap_num))\n",
    "                elif REMOVAL:\n",
    "                    chain_output = os.path.join(chains_output_dir, str(data_index), \"removal_\" + str(swap_num))\n",
    "                os.makedirs(chain_output, exist_ok=True)\n",
    "                \n",
    "                #save initial random distrubution with noise\n",
    "                positions_combined = torch.zeros_like(data_temp['positions'])\n",
    "                one_hot_combined = torch.zeros_like(data_temp['one_hot'])\n",
    "\n",
    "                # Iterate over each atom and decide whether to use original or noisy data\n",
    "                for atom_idx in range(data_temp['positions'].shape[1]):\n",
    "                    if data_temp['fragment_mask'][0, atom_idx] == 1:\n",
    "                        # Use original positions and features for fragment atoms\n",
    "                        positions_combined[:, atom_idx, :] = data_temp['positions'][:, atom_idx, :]\n",
    "                        one_hot_combined[:, atom_idx, :] = data_temp['one_hot'][:, atom_idx, :]\n",
    "                        # atom_mask_combined[:, atom_idx] = data_temp['atom_mask'][:, atom_idx]\n",
    "                    else:\n",
    "                        # Use noisy positions and features for linker atoms\n",
    "                        positions_combined[:, atom_idx, :] = noisy_positions_present_atoms_temp[:, atom_idx, :]\n",
    "                        one_hot_combined[:, atom_idx, :] = noisy_features_present_atoms_temp[:, atom_idx, :]\n",
    "\n",
    "                #save initial distribution\n",
    "            \n",
    "                save_xyz_file(\n",
    "                    chain_output,\n",
    "                    one_hot_combined,\n",
    "                    positions_combined,\n",
    "                    node_mask[i].unsqueeze(0),\n",
    "                    names=[f'{name}_' + str(keep_frames)],\n",
    "                    is_geom=model.is_geom\n",
    "                )\n",
    "\n",
    "                # one_hot = chain[:, :, 3:-1]\n",
    "                one_hot = chain[:, :, 3:] #@mastro, added last atom type (not sure whyt it was not included...) However, TODO check again\n",
    "                positions = chain[:, :, :3]\n",
    "                chain_node_mask = torch.cat([node_mask[i].unsqueeze(0) for _ in range(keep_frames)], dim=0)\n",
    "                names = [f'{name}_{j}' for j in range(keep_frames)]\n",
    "\n",
    "                save_xyz_file(chain_output, one_hot, positions, chain_node_mask, names=names, is_geom=model.is_geom)\n",
    "\n",
    "                if REMOVAL:\n",
    "                    draw_atom_indices = (fragment_atoms_indices_keep.tolist(), linker_atoms_indices.tolist())\n",
    "                \n",
    "                else:\n",
    "                    draw_atom_indices = \"original\"\n",
    "\n",
    "                visualize_chain_xai(\n",
    "                    chain_output,\n",
    "                    spheres_3d=False,\n",
    "                    alpha=1.0,\n",
    "                    bg='white',\n",
    "                    is_geom=model.is_geom,\n",
    "                    fragment_mask=data_temp['fragment_mask'][i].squeeze(),\n",
    "                    phi_values=None,\n",
    "                    colors_fragment_shadow=colors_fragment_shadow,\n",
    "                    draw_atom_indices=draw_atom_indices\n",
    "                )\n",
    "\n",
    "                \n",
    "                # Load generated molecule positions and atom types\n",
    "                names.append(f\"{name}_{keep_frames}\")\n",
    "                for the_name in names:\n",
    "                    generated_file = os.path.join(chain_output, the_name +\"_.xyz\")\n",
    "                    positions, one_hot, _ = load_molecule_xyz(generated_file, is_geom=False)\n",
    "                    \n",
    "                    atom_types = torch.argmax(one_hot, dim=1).cpu().numpy()\n",
    "                \n",
    "                    # Convert positions and atom types to an RDKit molecule\n",
    "                    mol = Chem.RWMol()\n",
    "                    atom_map = {}\n",
    "\n",
    "                    # Add atoms to the molecule\n",
    "                    for idx, atom_type in enumerate(atom_types):\n",
    "                        atom = Chem.Atom(const.IDX2ATOM[atom_type])\n",
    "                        atom_idx = mol.AddAtom(atom)\n",
    "                        atom_map[idx] = atom_idx\n",
    "\n",
    "                    # Add bonds based on positions and bond order\n",
    "                    for idx1 in range(len(positions)):\n",
    "                        for idx2 in range(idx1 + 1, len(positions)):\n",
    "                            dist = np.linalg.norm(positions[idx1] - positions[idx2])\n",
    "                            bond_order = has_bond(const.IDX2ATOM[atom_types[idx1]], const.IDX2ATOM[atom_types[idx2]], dist)\n",
    "                            \n",
    "                            if bond_order > 0:\n",
    "                                bond_type = const.BOND_DICT[bond_order]\n",
    "                                mol.AddBond(atom_map[idx1], atom_map[idx2], bond_type)\n",
    "                                \n",
    "                                if bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "                                    bond = mol.GetBondBetweenAtoms(atom_map[idx1], atom_map[idx2])\n",
    "                                    bond.SetIsAromatic(True)\n",
    "\n",
    "                    # Highlight fragment atoms and edges\n",
    "                    fragment_mask_highlight = data['fragment_mask'][0].cpu().numpy()\n",
    "                \n",
    "                    #\n",
    "                    linker_color = (0.25, 0.63, 0.38, 0.7)  # Emerald green color\n",
    "                    \n",
    "                    linker_colors = np.tile(linker_color, (linker_mask.sum().item(), 1))  # Repeat emerald green for each linker atom\n",
    "                    colors_fragment_shadow_padded = np.vstack([colors_fragment_shadow, linker_colors])  # Append linker colors\n",
    "                    \n",
    "\n",
    "                    # highlight_colors = {idx: colors_fragment_shadow_padded[idx] for idx, mask in enumerate(fragment_mask_highlight) if mask == 1}\n",
    "                    highlight_colors = {idx: color for idx, color in enumerate(colors_fragment_shadow_padded)}\n",
    "\n",
    "                    highlight_atoms = list(highlight_colors.keys())\n",
    "                    highlight_bonds = []\n",
    "                    for bond in mol.GetBonds():\n",
    "                        if bond.GetBeginAtomIdx() in highlight_atoms and bond.GetEndAtomIdx() in highlight_atoms:\n",
    "                            highlight_bonds.append(bond.GetIdx())\n",
    "                    \n",
    "                    # Assign bond colors based on the colors of the connected atoms\n",
    "                    bond_colors = {}\n",
    "                \n",
    "                    # Convert to RDKit molecule and draw\n",
    "                    mol = mol.GetMol()\n",
    "                    atom_colors = {idx: list(map(float, color[:3])) for idx, color in highlight_colors.items()}  # Convert to lists of floats\n",
    "                    atom_colors = {key: [tuple(value)] for key, value in atom_colors.items()}\n",
    "                    \n",
    "                    # Draw linker bonds and atoms in emerald green\n",
    "                    \n",
    "                    linker_mask_highlight = data['linker_mask'][0].cpu().numpy()\n",
    "                    \n",
    "                    # Update atom colors for linker atoms\n",
    "                    # for idx, mask in enumerate(linker_mask_highlight):\n",
    "                    #     if mask == 1:\n",
    "                    #         atom_colors[idx] = [0.25, 0.63, 0.38]  # Set emerald green for linker atoms\n",
    "                    \n",
    "                    # Update bond colors for linker bonds\n",
    "                    n_linker_atoms = linker_mask.sum().item()\n",
    "                    linker_atoms_indices_in_color_fragment_shadow = np.arange(len(colors_fragment_shadow_padded) - n_linker_atoms, len(colors_fragment_shadow_padded))\n",
    "                    \n",
    "                    for bond in mol.GetBonds():\n",
    "                        begin_idx = bond.GetBeginAtomIdx()\n",
    "                        end_idx = bond.GetEndAtomIdx()\n",
    "                        if begin_idx in linker_atoms_indices_in_color_fragment_shadow and end_idx in linker_atoms_indices_in_color_fragment_shadow:\n",
    "                            bond_colors[bond.GetIdx()] = [linker_color]  # Set emerald green for linker bonds\n",
    "                    \n",
    "                    # Use DrawMoleculeWithHighlights for visualization\n",
    "                    atom_radii = {idx: 0.5 for idx in range(len(colors_fragment_shadow_padded))}  # Default atom radius for fragment atoms\n",
    "                    # Set radius 0.3 for linker atoms\n",
    "                    n_linker_atoms = linker_mask.sum().item()\n",
    "                    for idx in range(len(atom_radii) - n_linker_atoms, len(atom_radii)):\n",
    "                        atom_radii[idx] = 0.3\n",
    "                        \n",
    "                    # print(\"Atom radii: \", atom_radii)\n",
    "                    # print(\"Bond colors: \", bond_colors)\n",
    "                    # print(\"color fragmen shadow length: \", len(colors_fragment_shadow_padded))\n",
    "                    # arrestomomentum()\n",
    "                    drawer = Draw.MolDraw2DCairo(800, 800)\n",
    "                    draw_options = drawer.drawOptions()\n",
    "                    draw_options.useBWAtomPalette()\n",
    "                    draw_options.kekulize = False\n",
    "                    \n",
    "                    drawer.DrawMoleculeWithHighlights(\n",
    "                        mol,\n",
    "                        \"\",  # Legend\n",
    "                        atom_colors,  # Atom colors (highlight_atom_map)\n",
    "                        bond_colors,  # Bond colors (highlight_bond_map)\n",
    "                        atom_radii,  # Atom radii\n",
    "                        {}  # Bond linewidth multipliers\n",
    "                    )\n",
    "\n",
    "                    drawer.FinishDrawing()\n",
    "                    # Convert the drawing to a PNG image\n",
    "                    png_data = drawer.GetDrawingText()\n",
    "                    with open(\"temp_image.png\", \"wb\") as f:\n",
    "                        f.write(png_data)\n",
    "\n",
    "                    # Load the PNG image using PIL\n",
    "                    img = Image.open(\"temp_image.png\")\n",
    "                    # img.show()\n",
    "                    \n",
    "                    output_file = os.path.join(chain_output, the_name + \"_structure.png\")\n",
    "                    img.save(output_file, dpi=(300, 300))\n",
    "\n",
    "                # Saving final prediction and ground truth separately\n",
    "                true_one_hot = data_temp['one_hot'][i].unsqueeze(0)\n",
    "                true_positions = data_temp['positions'][i].unsqueeze(0)\n",
    "                true_node_mask = data_temp['atom_mask'][i].unsqueeze(0)\n",
    "\n",
    "                #TODO chech if the final positions are saved in the correct folder\n",
    "                final_states_output_dir_current = None\n",
    "\n",
    "                if REMOVAL:\n",
    "                    final_states_output_dir_current = os.path.join(final_states_output_dir, str(data_index), \"removal_\" + str(swap_num))\n",
    "                if ATOM_PERTURBATION:\n",
    "                    final_states_output_dir_current = os.path.join(final_states_output_dir, str(data_index), \"perturbation_\" + str(swap_num))\n",
    "            \n",
    "                os.makedirs(final_states_output_dir_current, exist_ok=True)\n",
    "                save_xyz_file(\n",
    "                    final_states_output_dir_current,\n",
    "                    true_one_hot,\n",
    "                    true_positions,\n",
    "                    true_node_mask,\n",
    "                    names=[f'{name}_true'],\n",
    "                    is_geom=model.is_geom,\n",
    "                )\n",
    "\n",
    "                pred_one_hot = chain[0, :, 3:-1].unsqueeze(0)\n",
    "                pred_positions = chain[0, :, :3].unsqueeze(0)\n",
    "                pred_node_mask = chain_node_mask[0].unsqueeze(0)\n",
    "                save_xyz_file(\n",
    "                    final_states_output_dir_current,\n",
    "                    pred_one_hot,\n",
    "                    pred_positions,\n",
    "                    pred_node_mask,\n",
    "                    names=[f'{name}_pred'],\n",
    "                    is_geom=model.is_geom\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            for i in range(len(data_temp['positions'])):\n",
    "                # chain_before_injection = chain_batch_molecule_pertubation_before_injection[:, i, :, :]\n",
    "                # assert chain_batch_molecule_pertubation_before_injection.shape[0] == keep_frames - diffusion_steps//4 + 1\n",
    "                # print(\"chain_batch_molecule_pertubation_before_injection shape: \", chain_batch_molecule_pertubation_before_injection.shape)\n",
    "                assert chain_batch_molecule_pertubation_before_injection.shape[1] == data_temp['positions'].shape[1]\n",
    "                assert chain_batch_molecule_pertubation_before_injection.shape[2] == data_temp['positions'].shape[2] + data_temp['one_hot'].shape[2] + model.include_charges\n",
    "\n",
    "                # Saving chains\n",
    "                name = str(i + start)\n",
    "                if ATOM_PERTURBATION:\n",
    "                    chain_output = os.path.join(chains_output_dir, str(data_index), \"perturbation_\" + str(swap_num))\n",
    "                elif REMOVAL:\n",
    "                    chain_output = os.path.join(chains_output_dir, str(data_index), \"removal_\" + str(swap_num))\n",
    "                os.makedirs(chain_output, exist_ok=True)\n",
    "                \n",
    "                #save initial random distrubution with noise\n",
    "                positions_combined = torch.zeros_like(data_temp['positions'])\n",
    "                one_hot_combined = torch.zeros_like(data_temp['one_hot'])\n",
    "\n",
    "                # Iterate over each atom and decide whether to use original or noisy data\n",
    "                for atom_idx in range(data_temp['positions'].shape[1]):\n",
    "                    if data_temp['fragment_mask'][0, atom_idx] == 1:\n",
    "                        # Use original positions and features for fragment atoms\n",
    "                        positions_combined[:, atom_idx, :] = data_temp['positions'][:, atom_idx, :]\n",
    "                        one_hot_combined[:, atom_idx, :] = data_temp['one_hot'][:, atom_idx, :]\n",
    "                    else:\n",
    "                        # Use noisy positions and features for linker atoms\n",
    "                        positions_combined[:, atom_idx, :] = noisy_positions_present_atoms_temp[:, atom_idx, :]\n",
    "                        one_hot_combined[:, atom_idx, :] = noisy_features_present_atoms_temp[:, atom_idx, :]\n",
    "\n",
    "                #save initial distribution\n",
    "\n",
    "                save_xyz_file(\n",
    "                    chain_output,\n",
    "                    one_hot_combined,\n",
    "                    positions_combined,\n",
    "                    node_mask_before_injection[i].unsqueeze(0),\n",
    "                    names=[f'{name}_' + str(keep_frames)],\n",
    "                    is_geom=model.is_geom\n",
    "                )\n",
    "\n",
    "                # one_hot = chain[:, :, 3:-1]\n",
    "                one_hot_before_injection = chain_batch_molecule_pertubation_before_injection[:, :, 3:]\n",
    "                positions_before_injection = chain_batch_molecule_pertubation_before_injection[:, :, :3]\n",
    "                chain_node_mask_before_injection = torch.cat([node_mask_before_injection[i].unsqueeze(0) for _ in range(chain_batch_molecule_pertubation_before_injection.shape[0])], dim=0)\n",
    "                names_before_injection = [f'{name}_{j}' for j in range(chain_batch_molecule_pertubation_after_injection.shape[0],keep_frames)]\n",
    "\n",
    "                # print(\"Names before injection: \", names_before_injection)\n",
    "\n",
    "                save_xyz_file(chain_output, one_hot_before_injection, positions_before_injection, chain_node_mask_before_injection, names=names_before_injection, is_geom=model.is_geom)\n",
    "\n",
    "                if REMOVAL:\n",
    "                    draw_atom_indices = (fragment_atoms_indices_keep.tolist(), linker_atoms_indices.tolist())\n",
    "                \n",
    "                else:\n",
    "                    draw_atom_indices = \"original\"\n",
    "\n",
    "                # Load generated molecule positions and atom types\n",
    "                names_before_injection.append(f\"{name}_{keep_frames}\")\n",
    "                for the_name in names_before_injection: \n",
    "                    generated_file = os.path.join(chain_output, the_name + \"_.xyz\")\n",
    "                    positions, one_hot, _ = load_molecule_xyz(generated_file, is_geom=False)\n",
    "                    \n",
    "                    atom_types = torch.argmax(one_hot, dim=1).cpu().numpy()\n",
    "                \n",
    "                    # Convert positions and atom types to an RDKit molecule\n",
    "                    mol = Chem.RWMol()\n",
    "                    atom_map = {}\n",
    "\n",
    "                    # Add atoms to the molecule\n",
    "                    for idx, atom_type in enumerate(atom_types):\n",
    "                        atom = Chem.Atom(const.IDX2ATOM[atom_type])\n",
    "                        atom_idx = mol.AddAtom(atom)\n",
    "                        atom_map[idx] = atom_idx\n",
    "\n",
    "                    # Add bonds based on positions and bond order\n",
    "                    for idx1 in range(len(positions)):\n",
    "                        for idx2 in range(idx1 + 1, len(positions)):\n",
    "                            dist = np.linalg.norm(positions[idx1] - positions[idx2])\n",
    "                            bond_order = has_bond(const.IDX2ATOM[atom_types[idx1]], const.IDX2ATOM[atom_types[idx2]], dist)\n",
    "                            \n",
    "                            if bond_order > 0:\n",
    "                                bond_type = const.BOND_DICT[bond_order]\n",
    "                                mol.AddBond(atom_map[idx1], atom_map[idx2], bond_type)\n",
    "                                \n",
    "                                if bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "                                    bond = mol.GetBondBetweenAtoms(atom_map[idx1], atom_map[idx2])\n",
    "                                    bond.SetIsAromatic(True)\n",
    "\n",
    "                    # Highlight fragment atoms and edges\n",
    "                    fragment_mask_highlight = data['fragment_mask'][0].cpu().numpy()\n",
    "                \n",
    "                    #\n",
    "                    linker_color = (0.25, 0.63, 0.38, 0.7)  # Emerald green color\n",
    "                    \n",
    "                    linker_colors = np.tile(linker_color, (linker_mask.sum().item(), 1))  # Repeat emerald green for each linker atom\n",
    "                    colors_fragment_shadow_padded = np.vstack([colors_fragment_shadow, linker_colors])  # Append linker colors\n",
    "                    \n",
    "\n",
    "                    # highlight_colors = {idx: colors_fragment_shadow_padded[idx] for idx, mask in enumerate(fragment_mask_highlight) if mask == 1}\n",
    "                    highlight_colors = {idx: color for idx, color in enumerate(colors_fragment_shadow_padded)}\n",
    "\n",
    "                    highlight_atoms = list(highlight_colors.keys())\n",
    "                    highlight_bonds = []\n",
    "                    for bond in mol.GetBonds():\n",
    "                        if bond.GetBeginAtomIdx() in highlight_atoms and bond.GetEndAtomIdx() in highlight_atoms:\n",
    "                            highlight_bonds.append(bond.GetIdx())\n",
    "                    \n",
    "                    # Assign bond colors based on the colors of the connected atoms\n",
    "                    bond_colors = {}\n",
    "                \n",
    "                    # Convert to RDKit molecule and draw\n",
    "                    mol = mol.GetMol()\n",
    "                    atom_colors = {idx: list(map(float, color[:3])) for idx, color in highlight_colors.items()}  # Convert to lists of floats\n",
    "                    atom_colors = {key: [tuple(value)] for key, value in atom_colors.items()}\n",
    "                    \n",
    "                    # Draw linker bonds and atoms in emerald green\n",
    "                    \n",
    "                    linker_mask_highlight = data['linker_mask'][0].cpu().numpy()\n",
    "                    \n",
    "                    # Update atom colors for linker atoms\n",
    "                    # for idx, mask in enumerate(linker_mask_highlight):\n",
    "                    #     if mask == 1:\n",
    "                    #         atom_colors[idx] = [0.25, 0.63, 0.38]  # Set emerald green for linker atoms\n",
    "                    \n",
    "                    # Update bond colors for linker bonds\n",
    "                    n_linker_atoms = linker_mask.sum().item()\n",
    "                    linker_atoms_indices_in_color_fragment_shadow = np.arange(len(colors_fragment_shadow_padded) - n_linker_atoms, len(colors_fragment_shadow_padded))\n",
    "                    \n",
    "                    for bond in mol.GetBonds():\n",
    "                        begin_idx = bond.GetBeginAtomIdx()\n",
    "                        end_idx = bond.GetEndAtomIdx()\n",
    "                        if begin_idx in linker_atoms_indices_in_color_fragment_shadow and end_idx in linker_atoms_indices_in_color_fragment_shadow:\n",
    "                            bond_colors[bond.GetIdx()] = [linker_color]  # Set emerald green for linker bonds\n",
    "                    \n",
    "                    # Use DrawMoleculeWithHighlights for visualization\n",
    "                    atom_radii = {idx: 0.5 for idx in range(len(colors_fragment_shadow_padded))}  # Default atom radius for fragment atoms\n",
    "                    # Set radius 0.3 for linker atoms\n",
    "                    n_linker_atoms = linker_mask.sum().item()\n",
    "                    for idx in range(len(atom_radii) - n_linker_atoms, len(atom_radii)):\n",
    "                        atom_radii[idx] = 0.3\n",
    "                        \n",
    "                    # print(\"Atom radii: \", atom_radii)\n",
    "                    # print(\"Bond colors: \", bond_colors)\n",
    "                    # print(\"color fragmen shadow length: \", len(colors_fragment_shadow_padded))\n",
    "                    # arrestomomentum()\n",
    "                    drawer = Draw.MolDraw2DCairo(800, 800)\n",
    "                    draw_options = drawer.drawOptions()\n",
    "                    draw_options.useBWAtomPalette()\n",
    "                    draw_options.kekulize = False\n",
    "                    \n",
    "                    drawer.DrawMoleculeWithHighlights(\n",
    "                        mol,\n",
    "                        \"\",  # Legend\n",
    "                        atom_colors,  # Atom colors (highlight_atom_map)\n",
    "                        bond_colors,  # Bond colors (highlight_bond_map)\n",
    "                        atom_radii,  # Atom radii\n",
    "                        {}  # Bond linewidth multipliers\n",
    "                    )\n",
    "\n",
    "                    drawer.FinishDrawing()\n",
    "                    # Convert the drawing to a PNG image\n",
    "                    png_data = drawer.GetDrawingText()\n",
    "                    with open(\"temp_image.png\", \"wb\") as f:\n",
    "                        f.write(png_data)\n",
    "\n",
    "                    # Load the PNG image using PIL\n",
    "                    img = Image.open(\"temp_image.png\")\n",
    "                    # img.show()\n",
    "                    \n",
    "                    # output_generated_dir = os.path.join(SAVE_PATH, \"singlebonds\")\n",
    "                    # os.makedirs(output_generated_dir, exist_ok=True)\n",
    "                    # Save the image in the \"generated_structures\" subfolder\n",
    "                    output_file = os.path.join(chain_output, the_name + \"_structure.png\")\n",
    "                    img.save(output_file, dpi=(300, 300))\n",
    "\n",
    "                visualize_chain_xai(\n",
    "                    chain_output,\n",
    "                    spheres_3d=False,\n",
    "                    alpha=1.0,\n",
    "                    bg='white',\n",
    "                    is_geom=model.is_geom,\n",
    "                    fragment_mask=data_temp['fragment_mask'][i].squeeze(),\n",
    "                    phi_values=None,\n",
    "                    colors_fragment_shadow=colors_fragment_shadow,\n",
    "                    draw_atom_indices=draw_atom_indices,\n",
    "                    file_indices=range(chain_batch_molecule_pertubation_after_injection.shape[0],keep_frames+1)\n",
    "                )\n",
    "\n",
    "            \n",
    "            #save for after injection\n",
    "            for i in range(len(data[\"positions\"])):\n",
    "\n",
    "                # chain_after_injection = chain_after_injection[:, i, :, :]\n",
    "                # assert chain_batch_molecule_pertubation_after_injection.shape[0] == keep_frames\n",
    "                # print(\"chain_batch_molecule_pertubation_after_injection shape: \", chain_batch_molecule_pertubation_after_injection.shape)\n",
    "                assert chain_batch_molecule_pertubation_after_injection.shape[1] == data[\"positions\"].shape[1]\n",
    "                assert chain_batch_molecule_pertubation_after_injection.shape[2] == data[\"positions\"].shape[2] + data[\"one_hot\"].shape[2] + model.include_charges\n",
    "\n",
    "                # Saving chains\n",
    "                name = str(i + start)\n",
    "                if ATOM_PERTURBATION:\n",
    "                    chain_output = os.path.join(chains_output_dir, str(data_index), \"perturbation_\" + str(swap_num))\n",
    "                elif REMOVAL:\n",
    "                    chain_output = os.path.join(chains_output_dir, str(data_index), \"removal_\" + str(swap_num))\n",
    "                os.makedirs(chain_output, exist_ok=True)\n",
    "                \n",
    "                #save initial random distrubution with noise\n",
    "                positions_combined = torch.zeros_like(data['positions'])\n",
    "                one_hot_combined = torch.zeros_like(data['one_hot'])\n",
    "\n",
    "                # Iterate over each atom and decide whether to use original or noisy data\n",
    "                for atom_idx in range(data['positions'].shape[1]):\n",
    "                    if data['fragment_mask'][0, atom_idx] == 1:\n",
    "                        # Use original positions and features for fragment atoms\n",
    "                        positions_combined[:, atom_idx, :] = data['positions'][:, atom_idx, :]\n",
    "                        one_hot_combined[:, atom_idx, :] = data['one_hot'][:, atom_idx, :]\n",
    "                    else:\n",
    "                        # Use noisy positions and features for linker atoms\n",
    "                        positions_combined[:, atom_idx, :] = noisy_positions_present_atoms[:, atom_idx, :]\n",
    "                        one_hot_combined[:, atom_idx, :] = noisy_features_present_atoms[:, atom_idx, :]\n",
    "\n",
    "                \n",
    "                one_hot_after_injection = chain_batch_molecule_pertubation_after_injection[:, :, 3:]\n",
    "                positions_after_injection = chain_batch_molecule_pertubation_after_injection[:, :, :3]\n",
    "                chain_node_mask_after_injection = torch.cat([node_mask_after_injection[i].unsqueeze(0) for _ in range(chain_batch_molecule_pertubation_after_injection.shape[0])], dim=0)\n",
    "                names_after_injection = [f'{name}_{j}' for j in range(chain_batch_molecule_pertubation_after_injection.shape[0])]\n",
    "\n",
    "                # print(\"Names after injection: \", names_after_injection)\n",
    "\n",
    "                save_xyz_file(chain_output, one_hot_after_injection, positions_after_injection, chain_node_mask_after_injection, names=names_after_injection, is_geom=model.is_geom)\n",
    "\n",
    "\n",
    "                visualize_chain_xai(\n",
    "                    chain_output,\n",
    "                    spheres_3d=False,\n",
    "                    alpha=1.0,\n",
    "                    bg='white',\n",
    "                    is_geom=model.is_geom,\n",
    "                    fragment_mask=data['fragment_mask'][i].squeeze(),\n",
    "                    phi_values=None,\n",
    "                    colors_fragment_shadow=colors_fragment_shadow_original,\n",
    "                    draw_atom_indices=\"original\",\n",
    "                    file_indices=range(chain_batch_molecule_pertubation_after_injection.shape[0])\n",
    "                )\n",
    "\n",
    "                # Load generated molecule positions and atom types\n",
    "                for the_name in names_after_injection: \n",
    "                    generated_file = os.path.join(chain_output, the_name + \"_.xyz\")\n",
    "                    positions, one_hot, _ = load_molecule_xyz(generated_file, is_geom=False)\n",
    "                    \n",
    "                    atom_types = torch.argmax(one_hot, dim=1).cpu().numpy()\n",
    "                \n",
    "                    # Convert positions and atom types to an RDKit molecule\n",
    "                    mol = Chem.RWMol()\n",
    "                    atom_map = {}\n",
    "\n",
    "                    # Add atoms to the molecule\n",
    "                    for idx, atom_type in enumerate(atom_types):\n",
    "                        atom = Chem.Atom(const.IDX2ATOM[atom_type])\n",
    "                        atom_idx = mol.AddAtom(atom)\n",
    "                        atom_map[idx] = atom_idx\n",
    "\n",
    "                    # Add bonds based on positions and bond order\n",
    "                    for idx1 in range(len(positions)):\n",
    "                        for idx2 in range(idx1 + 1, len(positions)):\n",
    "                            dist = np.linalg.norm(positions[idx1] - positions[idx2])\n",
    "                            bond_order = has_bond(const.IDX2ATOM[atom_types[idx1]], const.IDX2ATOM[atom_types[idx2]], dist)\n",
    "                            \n",
    "                            if bond_order > 0:\n",
    "                                bond_type = const.BOND_DICT[bond_order]\n",
    "                                mol.AddBond(atom_map[idx1], atom_map[idx2], bond_type)\n",
    "                                \n",
    "                                if bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "                                    bond = mol.GetBondBetweenAtoms(atom_map[idx1], atom_map[idx2])\n",
    "                                    bond.SetIsAromatic(True)\n",
    "\n",
    "                    # Highlight fragment atoms and edges\n",
    "                    fragment_mask_highlight = data['fragment_mask'][0].cpu().numpy()\n",
    "                \n",
    "                    #\n",
    "                    linker_color = (0.25, 0.63, 0.38, 0.7)  # Emerald green color\n",
    "                    \n",
    "                    linker_colors = np.tile(linker_color, (linker_mask.sum().item(), 1))  # Repeat emerald green for each linker atom\n",
    "                    colors_fragment_shadow_padded = np.vstack([colors_fragment_shadow_original, linker_colors])  # Append linker colors\n",
    "                    \n",
    "\n",
    "                    # highlight_colors = {idx: colors_fragment_shadow_padded[idx] for idx, mask in enumerate(fragment_mask_highlight) if mask == 1}\n",
    "                    highlight_colors = {idx: color for idx, color in enumerate(colors_fragment_shadow_padded)}\n",
    "\n",
    "                    highlight_atoms = list(highlight_colors.keys())\n",
    "                    highlight_bonds = []\n",
    "                    for bond in mol.GetBonds():\n",
    "                        if bond.GetBeginAtomIdx() in highlight_atoms and bond.GetEndAtomIdx() in highlight_atoms:\n",
    "                            highlight_bonds.append(bond.GetIdx())\n",
    "                    \n",
    "                    # Assign bond colors based on the colors of the connected atoms\n",
    "                    bond_colors = {}\n",
    "                \n",
    "                    # Convert to RDKit molecule and draw\n",
    "                    mol = mol.GetMol()\n",
    "                    atom_colors = {idx: list(map(float, color[:3])) for idx, color in highlight_colors.items()}  # Convert to lists of floats\n",
    "                    atom_colors = {key: [tuple(value)] for key, value in atom_colors.items()}\n",
    "                    \n",
    "                    # Draw linker bonds and atoms in emerald green\n",
    "                    \n",
    "                    linker_mask_highlight = data['linker_mask'][0].cpu().numpy()\n",
    "                    \n",
    "                    # Update atom colors for linker atoms\n",
    "                    # for idx, mask in enumerate(linker_mask_highlight):\n",
    "                    #     if mask == 1:\n",
    "                    #         atom_colors[idx] = [0.25, 0.63, 0.38]  # Set emerald green for linker atoms\n",
    "                    \n",
    "                    # Update bond colors for linker bonds\n",
    "                    n_linker_atoms = linker_mask.sum().item()\n",
    "                    linker_atoms_indices_in_color_fragment_shadow = np.arange(len(colors_fragment_shadow_padded) - n_linker_atoms, len(colors_fragment_shadow_padded))\n",
    "                    \n",
    "                    for bond in mol.GetBonds():\n",
    "                        begin_idx = bond.GetBeginAtomIdx()\n",
    "                        end_idx = bond.GetEndAtomIdx()\n",
    "                        if begin_idx in linker_atoms_indices_in_color_fragment_shadow and end_idx in linker_atoms_indices_in_color_fragment_shadow:\n",
    "                            bond_colors[bond.GetIdx()] = [linker_color]  # Set emerald green for linker bonds\n",
    "                    \n",
    "                    # Use DrawMoleculeWithHighlights for visualization\n",
    "                    atom_radii = {idx: 0.5 for idx in range(len(colors_fragment_shadow_padded))}  # Default atom radius for fragment atoms\n",
    "                    # Set radius 0.3 for linker atoms\n",
    "                    n_linker_atoms = linker_mask.sum().item()\n",
    "                    for idx in range(len(atom_radii) - n_linker_atoms, len(atom_radii)):\n",
    "                        atom_radii[idx] = 0.3\n",
    "                        \n",
    "                    # print(\"Atom radii: \", atom_radii)\n",
    "                    # print(\"Bond colors: \", bond_colors)\n",
    "                    # print(\"color fragmen shadow length: \", len(colors_fragment_shadow_padded))\n",
    "                    # arrestomomentum()\n",
    "                    drawer = Draw.MolDraw2DCairo(800, 800)\n",
    "                    draw_options = drawer.drawOptions()\n",
    "                    draw_options.useBWAtomPalette()\n",
    "                    draw_options.kekulize = False\n",
    "                    \n",
    "                    drawer.DrawMoleculeWithHighlights(\n",
    "                        mol,\n",
    "                        \"\",  # Legend\n",
    "                        atom_colors,  # Atom colors (highlight_atom_map)\n",
    "                        bond_colors,  # Bond colors (highlight_bond_map)\n",
    "                        atom_radii,  # Atom radii\n",
    "                        {}  # Bond linewidth multipliers\n",
    "                    )\n",
    "\n",
    "                    drawer.FinishDrawing()\n",
    "                    # Convert the drawing to a PNG image\n",
    "                    png_data = drawer.GetDrawingText()\n",
    "                    with open(\"temp_image.png\", \"wb\") as f:\n",
    "                        f.write(png_data)\n",
    "\n",
    "                    # Load the PNG image using PIL\n",
    "                    img = Image.open(\"temp_image.png\")\n",
    "                    # img.show()\n",
    "                    \n",
    "                    # output_generated_dir = os.path.join(SAVE_PATH, \"singlebonds\")\n",
    "                    # os.makedirs(output_generated_dir, exist_ok=True)\n",
    "                    # Save the image in the \"generated_structures\" subfolder\n",
    "                    output_file = os.path.join(chain_output, the_name + \"_structure.png\")\n",
    "                    img.save(output_file, dpi=(300, 300))\n",
    "\n",
    "                # Saving final prediction and ground truth separately\n",
    "                true_one_hot = data['one_hot'][i].unsqueeze(0)\n",
    "                true_positions = data['positions'][i].unsqueeze(0)\n",
    "                true_node_mask = data['atom_mask'][i].unsqueeze(0)\n",
    "\n",
    "                \n",
    "                final_states_output_dir_current = None\n",
    "\n",
    "                if REMOVAL:\n",
    "                    final_states_output_dir_current = os.path.join(final_states_output_dir, str(data_index), \"removal_\" + str(swap_num))\n",
    "                if ATOM_PERTURBATION:\n",
    "                    final_states_output_dir_current = os.path.join(final_states_output_dir, str(data_index), \"perturbation_\" + str(swap_num))\n",
    "            \n",
    "                os.makedirs(final_states_output_dir_current, exist_ok=True)\n",
    "                save_xyz_file(\n",
    "                    final_states_output_dir_current,\n",
    "                    true_one_hot,\n",
    "                    true_positions,\n",
    "                    true_node_mask,\n",
    "                    names=[f'{name}_true'],\n",
    "                    is_geom=model.is_geom,\n",
    "                )\n",
    "\n",
    "                pred_one_hot = chain_batch_molecule_pertubation_after_injection[0, :, 3:-1].unsqueeze(0)\n",
    "                pred_positions = chain_batch_molecule_pertubation_after_injection[0, :, :3].unsqueeze(0)\n",
    "                pred_node_mask = chain_batch_molecule_pertubation_after_injection[0].unsqueeze(0)\n",
    "\n",
    "                save_xyz_file(\n",
    "                    final_states_output_dir_current,\n",
    "                    pred_one_hot,\n",
    "                    pred_positions,\n",
    "                    pred_node_mask,\n",
    "                    names=[f'{name}_pred'],\n",
    "                    is_geom=model.is_geom\n",
    "                )\n",
    "\n",
    "             \n",
    "        del data_temp\n",
    "        del noisy_features_present_atoms_temp\n",
    "        del noisy_positions_present_atoms_temp\n",
    "    start += len(data['positions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_explainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abaltion study on important/opposing features\n",
    "\n",
    "Abaltion study consisting in keeping only important atoms for the generation to inspect the model's behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read molecules from dataset\n",
    "2. Load initial random distributions for atoms and features\n",
    "3. Read shapley values\n",
    "4. Mask out atoms whose Shapley values is TODO: find criterion\n",
    "\n",
    "Possible criteria for atom removal:\n",
    "* Remove atoms with Shapley value above/below average\n",
    "* Keep only the most (top k or %?) Shapley values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://web-proxy.informatik.uni-bonn.de:3128\"\n",
    "os.environ[\"https_proxy\"] = \"http://web-proxy.informatik.uni-bonn.de:3128\"\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v2 as imageio\n",
    "import networkx as nx\n",
    "from pysmiles import read_smiles\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from src.lightning import DDPM\n",
    "from src.datasets import get_dataloader\n",
    "from src.visualizer import load_molecule_xyz, load_xyz_files, save_xyz_file\n",
    "from src.molecule_builder import get_bond_order\n",
    "from src import const\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "\n",
    "# density = sys.argv[sys.argv.index(\"--P\") + 1]\n",
    "# seed = sys.argv[sys.argv.index(\"--seed\") + 1]\n",
    "\n",
    "# Load configuration from config.yml\n",
    "with open('config.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "checkpoint = config['CHECKPOINT']\n",
    "chains = config['CHAINS']\n",
    "DATA = config['DATA']\n",
    "prefix = config['PREFIX']\n",
    "keep_frames = int(config['KEEP_FRAMES'])\n",
    "P = config['P']\n",
    "device = config['DEVICE'] if torch.cuda.is_available() else 'cpu'\n",
    "SEED = int(config['SEED'])\n",
    "REMOVAL = config['REMOVAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mastropietro/anaconda3/envs/diff_explainer/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.6.3 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint models/zinc_difflinker.ckpt`\n",
      "/home/mastropietro/Repositories/DiffSHAPer/difflinker/src/datasets.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data = torch.load(dataset_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:7\n"
     ]
    }
   ],
   "source": [
    "experiment_name = checkpoint.split('/')[-1].replace('.ckpt', '')\n",
    "\n",
    "#create output directories\n",
    "chains_output_dir = os.path.join(chains, experiment_name, prefix, 'chains_' + P + '_seed_' + str(SEED) + '_ablation_study')\n",
    "final_states_output_dir = os.path.join(chains, experiment_name, prefix, 'final_states_' + P + '_seed_' + str(SEED) + '_ablation_study')\n",
    "os.makedirs(chains_output_dir, exist_ok=True)\n",
    "os.makedirs(final_states_output_dir, exist_ok=True)\n",
    "\n",
    "# Loading model form checkpoint \n",
    "model = DDPM.load_from_checkpoint(checkpoint, map_location=device)\n",
    "\n",
    "# Possibility to evaluate on different datasets (e.g., on CASF instead of ZINC)\n",
    "model.val_data_prefix = prefix\n",
    "\n",
    "print(f\"Running on device: {device}\")\n",
    "# In case <Anonymous> will run my model or vice versa\n",
    "if DATA is not None:\n",
    "    model.data_path = DATA\n",
    "\n",
    "model = model.eval().to(device)\n",
    "model.setup(stage='val')\n",
    "dataloader = get_dataloader(\n",
    "    model.val_dataset,\n",
    "    batch_size=1, #@mastro, it was 32\n",
    "    # batch_size=len(model.val_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrestomomentum():\n",
    "    raise KeyboardInterrupt(\"Debug interrupt.\")\n",
    "\n",
    "def draw_sphere_xai(ax, x, y, z, size, color, alpha):\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "\n",
    "    xs = size * np.outer(np.cos(u), np.sin(v))\n",
    "    ys = size * np.outer(np.sin(u), np.sin(v)) #* 0.8\n",
    "    zs = size * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    ax.plot_surface(x + xs, y + ys, z + zs, rstride=2, cstride=2, color=color, alpha=alpha)\n",
    "\n",
    "def plot_molecule_xai(ax, positions, atom_type, alpha, spheres_3d, hex_bg_color, is_geom, fragment_mask=None, phi_values=None, invert_colormap = False):\n",
    "    x = positions[:, 0]\n",
    "    y = positions[:, 1]\n",
    "    z = positions[:, 2]\n",
    "    # Hydrogen, Carbon, Nitrogen, Oxygen, Flourine\n",
    "\n",
    "    idx2atom = const.GEOM_IDX2ATOM if is_geom else const.IDX2ATOM\n",
    "\n",
    "    colors_dic = np.array(const.COLORS)\n",
    "    radius_dic = np.array(const.RADII)\n",
    "    area_dic = 1500 * radius_dic ** 2\n",
    "\n",
    "    areas = area_dic[atom_type]\n",
    "    radii = radius_dic[atom_type]\n",
    "    colors = colors_dic[atom_type]\n",
    "\n",
    "    if fragment_mask is None:\n",
    "        fragment_mask = torch.ones(len(x))\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        for j in range(i + 1, len(x)):\n",
    "            p1 = np.array([x[i], y[i], z[i]])\n",
    "            p2 = np.array([x[j], y[j], z[j]])\n",
    "            dist = np.sqrt(np.sum((p1 - p2) ** 2))\n",
    "            atom1, atom2 = idx2atom[atom_type[i]], idx2atom[atom_type[j]]\n",
    "            draw_edge_int = get_bond_order(atom1, atom2, dist)\n",
    "            line_width = (3 - 2) * 2 * 2\n",
    "            draw_edge = draw_edge_int > 0\n",
    "            if draw_edge:\n",
    "                if draw_edge_int == 4:\n",
    "                    linewidth_factor = 1.5\n",
    "                else:\n",
    "                    linewidth_factor = 1\n",
    "                linewidth_factor *= 0.5\n",
    "                ax.plot(\n",
    "                    [x[i], x[j]], [y[i], y[j]], [z[i], z[j]],\n",
    "                    linewidth=line_width * linewidth_factor * 2,\n",
    "                    c=hex_bg_color,\n",
    "                    alpha=alpha\n",
    "                )\n",
    "\n",
    "    \n",
    "\n",
    "    if spheres_3d:\n",
    "        \n",
    "        for i, j, k, s, c, f, phi in zip(x, y, z, radii, colors, fragment_mask, phi_values):\n",
    "            if f == 1:\n",
    "                alpha = 1.0\n",
    "                if phi > 0:\n",
    "                    c = 'red'\n",
    "\n",
    "            draw_sphere_xai(ax, i.item(), j.item(), k.item(), 0.5 * s, c, alpha)\n",
    "\n",
    "    else:\n",
    "        phi_values_array = np.array(list(phi_values.values()))\n",
    "\n",
    "        #draw fragments\n",
    "        fragment_mask_on_cpu = fragment_mask.cpu().numpy()\n",
    "        colors_fragment = colors[fragment_mask_on_cpu == 1]\n",
    "        x_fragment = x[fragment_mask_on_cpu == 1]\n",
    "        y_fragment = y[fragment_mask_on_cpu == 1]\n",
    "        z_fragment = z[fragment_mask_on_cpu == 1]\n",
    "        areas_fragment = areas[fragment_mask_on_cpu == 1]\n",
    "        \n",
    "        # Calculate the gradient colors based on phi values\n",
    "        # cmap = plt.cm.get_cmap('coolwarm_r') #reversed heatmap for distance-based importance\n",
    "        cmap = plt.cm.get_cmap('coolwarm') #heatmap for distance-based importance trying non reversed -> high shapley value mean more imporant, that drive the generation.\n",
    "        #@mastro added invert_colormap to invert the colormap if average/expected value in higher than original prediction\n",
    "        if invert_colormap:\n",
    "            cmap = plt.cm.get_cmap('coolwarm_r')\n",
    "\n",
    "        norm = plt.Normalize(vmin=min(phi_values_array), vmax=max(phi_values_array))\n",
    "        colors_fragment_shadow = cmap(norm(phi_values_array))\n",
    "        \n",
    "        # ax.scatter(x_fragment, y_fragment, z_fragment, s=areas_fragment, alpha=0.9 * alpha, c=colors_fragment)\n",
    "\n",
    "        ax.scatter(x_fragment, y_fragment, z_fragment, s=areas_fragment, alpha=0.9 * alpha, c=colors_fragment, edgecolors=colors_fragment_shadow, linewidths=5, rasterized=False)\n",
    "\n",
    "        #draw non-fragment atoms\n",
    "        colors = colors[fragment_mask_on_cpu == 0]\n",
    "        x = x[fragment_mask_on_cpu == 0]\n",
    "        y = y[fragment_mask_on_cpu == 0]\n",
    "        z = z[fragment_mask_on_cpu == 0]\n",
    "        areas = areas[fragment_mask_on_cpu == 0]\n",
    "        ax.scatter(x, y, z, s=areas, alpha=0.9 * alpha, c=colors, rasterized=False)\n",
    "\n",
    "\n",
    "def plot_data3d_xai(positions, atom_type, is_geom, camera_elev=0, camera_azim=0, save_path=None, spheres_3d=False,\n",
    "                bg='black', alpha=1., fragment_mask=None, phi_values=None, invert_colormap = False):\n",
    "    black = (0, 0, 0)\n",
    "    white = (1, 1, 1)\n",
    "    hex_bg_color = '#FFFFFF' if bg == 'black' else '#000000' #'#666666'\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.view_init(elev=camera_elev, azim=camera_azim)\n",
    "    if bg == 'black':\n",
    "        ax.set_facecolor(black)\n",
    "    else:\n",
    "        ax.set_facecolor(white)\n",
    "    ax.xaxis.pane.set_alpha(0)\n",
    "    ax.yaxis.pane.set_alpha(0)\n",
    "    ax.zaxis.pane.set_alpha(0)\n",
    "    ax._axis3don = False\n",
    "\n",
    "    if bg == 'black':\n",
    "        ax.w_xaxis.line.set_color(\"black\")\n",
    "    else:\n",
    "        ax.w_xaxis.line.set_color(\"white\")\n",
    "\n",
    "    plot_molecule_xai(\n",
    "        ax, positions, atom_type, alpha, spheres_3d, hex_bg_color, is_geom=is_geom, fragment_mask=fragment_mask, phi_values=phi_values, invert_colormap=invert_colormap\n",
    "    )\n",
    "\n",
    "    max_value = positions.abs().max().item()\n",
    "    axis_lim = min(40, max(max_value / 1.5 + 0.3, 3.2))\n",
    "    ax.set_xlim(-axis_lim, axis_lim)\n",
    "    ax.set_ylim(-axis_lim, axis_lim)\n",
    "    ax.set_zlim(-axis_lim, axis_lim)\n",
    "    dpi = 300 if spheres_3d else 300 #it was 120 and 50\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0.0, dpi=dpi)\n",
    "        # plt.savefig(save_path, bbox_inches='tight', pad_inches=0.0, dpi=dpi, transparent=True)\n",
    "\n",
    "        if spheres_3d:\n",
    "            img = imageio.imread(save_path)\n",
    "            img_brighter = np.clip(img * 1.4, 0, 255).astype('uint8')\n",
    "            imageio.imsave(save_path, img_brighter)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def visualize_chain_xai(\n",
    "        path, spheres_3d=False, bg=\"black\", alpha=1.0, wandb=None, mode=\"chain\", is_geom=False, fragment_mask=None, phi_values=None, invert_colormap = False\n",
    "):\n",
    "    files = load_xyz_files(path)\n",
    "    save_paths = []\n",
    "\n",
    "    # Fit PCA to the final molecule – to obtain the best orientation for visualization\n",
    "    positions, one_hot, charges = load_molecule_xyz(files[-1], is_geom=is_geom)\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(positions)\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        file = files[i]\n",
    "\n",
    "        positions, one_hot, charges = load_molecule_xyz(file, is_geom=is_geom)\n",
    "        atom_type = torch.argmax(one_hot, dim=1).numpy()\n",
    "\n",
    "        # Transform positions of each frame according to the best orientation of the last frame\n",
    "        positions = pca.transform(positions)\n",
    "        positions = torch.tensor(positions)\n",
    "\n",
    "        fn = file[:-4] + '.png'\n",
    "        plot_data3d_xai(\n",
    "            positions, atom_type,\n",
    "            save_path=fn,\n",
    "            spheres_3d=spheres_3d,\n",
    "            alpha=alpha,\n",
    "            bg=bg,\n",
    "            camera_elev=90,\n",
    "            camera_azim=90,\n",
    "            is_geom=is_geom,\n",
    "            fragment_mask=fragment_mask,\n",
    "            phi_values=phi_values,\n",
    "            invert_colormap=invert_colormap\n",
    "        )\n",
    "        save_paths.append(fn)\n",
    "\n",
    "    imgs = [imageio.imread(fn) for fn in save_paths]\n",
    "    dirname = os.path.dirname(save_paths[0])\n",
    "    gif_path = dirname + '/output.gif'\n",
    "    imageio.mimsave(gif_path, imgs, subrectangles=True)\n",
    "\n",
    "    if wandb is not None:\n",
    "        wandb.log({mode: [wandb.Video(gif_path, caption=gif_path)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation and Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 30\n",
    "sampled = 0\n",
    "start = 0\n",
    "\n",
    "SAVE_VISUALIZATIONS = config['SAVE_VISUALIZATIONS']\n",
    "INTIAL_DISTIBUTION_PATH = \"results/explanations_\" + P + \"_seed_\" + str(SEED)\n",
    "\n",
    "data_list = []\n",
    "for data in dataloader:\n",
    "\n",
    "    if sampled < num_samples:\n",
    "        data_list.append(data)\n",
    "        sampled += 1\n",
    "\n",
    "max_num_atoms = max(data[\"positions\"].shape[1] for data in data_list)\n",
    "\n",
    "# load initial distrubution of noisy features and positions\n",
    "noisy_features = torch.load(INTIAL_DISTIBUTION_PATH + \"/noisy_features_seed_\" + str(SEED) + \".pt\", map_location=device, weights_only=True)\n",
    "noisy_positions = torch.load(INTIAL_DISTIBUTION_PATH + \"/noisy_positions_seed_\" + str(SEED) + \".pt\", map_location=device, weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental generation by adding atoms according to thier Shapley values (for the more to the less important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ade382e009b44b280f8bcd29e2ab388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe1c6c6a4124368818d13d39553cbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5de4070fa73412fab080a209120d45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4128e79db2e64fc2a277acd9bd5812e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1014e158c3584fe98cba3e0f6a9be481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cac8931379b4afb948aa4c0cb2e7069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdfce5a2c345444a90a6d48cddb2c0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88daa96a4dba436cb888fa9b07e8ed10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb046b7db4934cbb8ef6dff55df1c7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620a907b542042f3a0779ae095c3697d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8ef61c88984c1cb6ee34f75830966a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "Atom \"[C@@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3099dcecc11444f8b27b9f0a129ffc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E/Z stereochemical information, which is specified by \"/\", will be discarded\n",
      "E/Z stereochemical information, which is specified by \"/\", will be discarded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc491793dec54cb5956af3c00cad4fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7416e55f080476dbad340c02cc904f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c01cd29905242df87b76a0d419c1450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4624c00e12477bb9664a0678435569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2aa01e405a4e49814a4115c2cd2c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229ae45bf432427191794bc6067f9c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f687aa904c2a41e29693888fb639f18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58377520addf4bd3b2d33a95e8245db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd20f64a33ad491ab1dbb5ac1fee0c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27ad6e9666047dea9300036f4c9a3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9442b3b8f6a4c6fb33f714ee318c5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec1364fabf14f888f204b215dc5ca63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94c4e52ae014b44afe96c76120ff152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "Atom \"[C@@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759fec341f0d43b7af064a67c26e4f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n",
      "Atom \"[C@@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89779382ca24141b7c38c119724f490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b478ce128c74740a2445a26de1b7aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c67111d48b45f8a50a5a38dec3e86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58f1003fdd745758b46ac7d316160bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Atom \"[C@H]\" contains stereochemical information that will be discarded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d42d7ff8f9c42889e1aeec71efb09a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create output directories\n",
    "# chains_output_dir = os.path.join(chains, experiment_name, prefix, 'chains_' + P + '_seed_' + str(SEED) + '_ablation_study_minimal_sets')\n",
    "# final_states_output_dir = os.path.join(chains, experiment_name, prefix, 'final_states_' + P + '_seed_' + str(SEED) + '_ablation_study_minimal_sets')\n",
    "\n",
    "if REMOVAL:\n",
    "    chains_output_dir = os.path.join(chains, experiment_name, prefix, 'chains_' + P + '_seed_' + str(SEED) + '_ablation_study_coulomb_matrix_minimal_sets_removal')\n",
    "    final_states_output_dir = os.path.join(chains, experiment_name, prefix, 'final_states_' + P + '_seed_' + str(SEED) + '_ablation_study_coulomb_matrix_minimal_sets_removal')\n",
    "else:\n",
    "    chains_output_dir = os.path.join(chains, experiment_name, prefix, 'chains_' + P + '_seed_' + str(SEED) + '_ablation_study_coulomb_matrix_minimal_sets')\n",
    "    final_states_output_dir = os.path.join(chains, experiment_name, prefix, 'final_states_' + P + '_seed_' + str(SEED) + '_ablation_study_coulomb_matrix_minimal_sets')\n",
    "    \n",
    "os.makedirs(chains_output_dir, exist_ok=True)\n",
    "os.makedirs(final_states_output_dir, exist_ok=True)\n",
    "\n",
    "for data_index, data in enumerate(tqdm(data_list)):\n",
    "\n",
    "    smile = data[\"name\"][0]\n",
    "    mol = read_smiles(smile)\n",
    "    chain_with_full_fragments = None\n",
    "\n",
    "    noisy_positions_present_atoms = noisy_positions.clone()\n",
    "    noisy_features_present_atoms = noisy_features.clone()\n",
    "\n",
    "    noisy_positions_present_atoms = noisy_positions_present_atoms[:, :data[\"positions\"].shape[1], :]\n",
    "    noisy_features_present_atoms = noisy_features_present_atoms[:, :data[\"one_hot\"].shape[1], :]\n",
    "\n",
    "    num_fragment_atoms = int(data[\"fragment_mask\"].sum().item())\n",
    "\n",
    "    #load Shapley values for Hausdorff distance\n",
    "    phi_values = []\n",
    "    \n",
    "    \n",
    "    with open(INTIAL_DISTIBUTION_PATH + \"/phi_atoms_\" + str(data_index) + \".txt\", \"r\") as read_file:\n",
    "        read_file.readline()\n",
    "        read_file.readline()\n",
    "        for row in read_file:\n",
    "            if row.strip() == \"\":\n",
    "                break\n",
    "            line = row.strip().split(\",\")\n",
    "            phi_values.append(float(line[3])) #3 for hausdorff distance-based Shapley values\n",
    "\n",
    "    #retrieve original and average Frobenius norm from file\n",
    "    original_frobenius_norm = None\n",
    "    average_frobenius_norm = None\n",
    "    with open(INTIAL_DISTIBUTION_PATH + \"/phi_atoms_\" + str(data_index) + \".txt\", \"r\") as read_file:\n",
    "        read_file.readline()\n",
    "        read_file.readline()\n",
    "        for row in read_file:\n",
    "            if row.strip().startswith(\"Original Frobenius norm\"):\n",
    "                line = row.strip().split(\":\")\n",
    "                original_frobenius_norm = float(line[1])\n",
    "            if row.strip().startswith(\"Average Frobenius norm\"):\n",
    "                line = row.strip().split(\":\")\n",
    "                average_frobenius_norm = float(line[1])    \n",
    "            if average_frobenius_norm is not None and original_frobenius_norm is not None:\n",
    "                break\n",
    "    # Remove fragment atoms whose Shapley values are above the average Shapley value\n",
    "    fragment_mask = data[\"fragment_mask\"].squeeze().bool()\n",
    "    linker_mask = data[\"linker_mask\"].squeeze().bool()\n",
    "    phi_values_tensor = torch.tensor(phi_values)\n",
    "\n",
    "    #get indices of phi_values_tensor from lower to higher\n",
    "    sorted_indices = torch.argsort(phi_values_tensor)\n",
    "    # reversed_indices = torch.flip(sorted_indices, [0])\n",
    "\n",
    "    \n",
    "    \n",
    "    for sorted_index in tqdm(range(len(sorted_indices))):\n",
    "        data_temp = data.copy()\n",
    "        noisy_positions_present_atoms_temp = noisy_positions_present_atoms.clone()\n",
    "        noisy_features_present_atoms_temp = noisy_features_present_atoms.clone()\n",
    "        \n",
    "        #keep indices from 0 to sorted_index\n",
    "        # shapley_value_indices_keep = sorted_indices[:sorted_index+1] #for addition\n",
    "        shapley_value_indices_keep = None\n",
    "        if REMOVAL:\n",
    "            shapley_value_indices_keep = sorted_indices[sorted_index:] #for removal\n",
    "        else:\n",
    "            shapley_value_indices_keep = sorted_indices[:sorted_index+1] #for addition\n",
    "        # print(\"fragment_atoms_indices_keep\", fragment_atoms_indices_keep)\n",
    "        # print(\"len fragment_atoms_indices_keep\", len(fragment_atoms_indices_keep))\n",
    "        # print(\"phi_values_tensor\", phi_values_tensor)\n",
    "        \n",
    "        #retrieve indices of fragment and linker atoms from atom_mask\n",
    "        fragment_atoms_indices = torch.where(fragment_mask)[0]\n",
    "        fragment_atoms_indices = fragment_atoms_indices.to(device)\n",
    "        linker_atoms_indices = torch.where(linker_mask)[0]\n",
    "        linker_atoms_indices = linker_atoms_indices.to(device)\n",
    "        \n",
    "        #keep only elements from fragment_atoms_indices at the indices in shapley_value_indices_keep\n",
    "        fragment_atoms_indices_keep = fragment_atoms_indices[shapley_value_indices_keep]\n",
    "        fragment_atoms_indices_keep_tensor = torch.Tensor(fragment_atoms_indices_keep).to(device)\n",
    "\n",
    "        #retrieve indices of fragment atoms with Shapley values above the average Shapley value\n",
    "        # fragment_atoms_to_remove_indices = torch.where(phi_values_tensor > average_phi_value)[0]\n",
    "        # fragment_atoms_to_remove_indices = fragment_atoms_to_remove_indices.to(device)\n",
    "\n",
    "        # fragment_atoms_indices_keep = torch.tensor([i for i in fragment_atoms_indices if i not in fragment_atoms_to_remove_indices])\n",
    "        # fragment_atoms_indices_keep = fragment_atoms_indices_keep.to(device)\n",
    "\n",
    "        #keep only fragment_atoms_indices_keep and linker_atoms_indices\n",
    "        atom_indices_to_keep = torch.cat((fragment_atoms_indices_keep_tensor, linker_atoms_indices)).to(device)\n",
    "\n",
    "        #remove atoms from molecule\n",
    "        data_temp[\"positions\"] = data_temp[\"positions\"][:, atom_indices_to_keep, :]\n",
    "        data_temp[\"one_hot\"] = data_temp[\"one_hot\"][:, atom_indices_to_keep, :]\n",
    "        data_temp[\"charges\"] = data_temp[\"charges\"][:, atom_indices_to_keep]\n",
    "        data_temp[\"fragment_mask\"] = data_temp[\"fragment_mask\"][:, atom_indices_to_keep]\n",
    "        data_temp[\"linker_mask\"] = data_temp[\"linker_mask\"][:, atom_indices_to_keep]\n",
    "        data_temp[\"atom_mask\"] = data_temp[\"atom_mask\"][:, atom_indices_to_keep]\n",
    "        data_temp[\"anchors\"] = data_temp[\"anchors\"][:, atom_indices_to_keep]\n",
    "        edge_mask_to_keep = (data_temp[\"atom_mask\"].unsqueeze(1) * data_temp[\"atom_mask\"]).flatten()\n",
    "        data_temp[\"edge_mask\"] = edge_mask_to_keep\n",
    "\n",
    "        #remove atoms from noisy features and positions\n",
    "        noisy_positions_present_atoms_temp = noisy_positions_present_atoms_temp[:, atom_indices_to_keep, :]\n",
    "        noisy_features_present_atoms_temp = noisy_features_present_atoms_temp[:, atom_indices_to_keep, :]\n",
    "\n",
    "        #remove atom from phi_values\n",
    "        phi_values_array = np.array(phi_values)\n",
    "        cmap = plt.cm.get_cmap('coolwarm_r') #reversed heatmap for distance-based importance\n",
    "        norm = plt.Normalize(vmin=min(phi_values_array), vmax=max(phi_values_array))\n",
    "        colors_fragment_shadow = cmap(norm(phi_values_array))\n",
    "        #remove atoms from color array\n",
    "        colors_fragment_shadow = colors_fragment_shadow[fragment_atoms_indices_keep.cpu().numpy()]\n",
    "        \n",
    "        chain_batch, node_mask = model.sample_chain(data_temp, keep_frames=keep_frames, noisy_positions=noisy_positions_present_atoms_temp, noisy_features=noisy_features_present_atoms_temp)\n",
    "\n",
    "        # chain_with_full_fragments = chain_batch[0, :, :, :]\n",
    "\n",
    "        #save and visualize chain (only for the linker use noisy positions for the initial distribution)\n",
    "        \n",
    "\n",
    "        for i in range(len(data_temp['positions'])):\n",
    "            chain = chain_batch[:, i, :, :]\n",
    "            assert chain.shape[0] == keep_frames\n",
    "            assert chain.shape[1] == data_temp['positions'].shape[1]\n",
    "            assert chain.shape[2] == data_temp['positions'].shape[2] + data_temp['one_hot'].shape[2] + model.include_charges\n",
    "\n",
    "            # Saving chains\n",
    "            name = str(i + start)\n",
    "            chain_output = os.path.join(chains_output_dir, name, name + \"_atoms_\" + str(len(fragment_atoms_indices_keep)))\n",
    "            os.makedirs(chain_output, exist_ok=True)\n",
    "            \n",
    "            #save initial random distrubution with noise\n",
    "            positions_combined = torch.zeros_like(data_temp['positions'])\n",
    "            one_hot_combined = torch.zeros_like(data_temp['one_hot'])\n",
    "\n",
    "            # Iterate over each atom and decide whether to use original or noisy data\n",
    "            for atom_idx in range(data_temp['positions'].shape[1]):\n",
    "                if data_temp['fragment_mask'][0, atom_idx] == 1:\n",
    "                    # Use original positions and features for fragment atoms\n",
    "                    positions_combined[:, atom_idx, :] = data_temp['positions'][:, atom_idx, :]\n",
    "                    one_hot_combined[:, atom_idx, :] = data_temp['one_hot'][:, atom_idx, :]\n",
    "                    # atom_mask_combined[:, atom_idx] = data_temp['atom_mask'][:, atom_idx]\n",
    "                else:\n",
    "                    # Use noisy positions and features for linker atoms\n",
    "                    positions_combined[:, atom_idx, :] = noisy_positions_present_atoms_temp[:, atom_idx, :]\n",
    "                    one_hot_combined[:, atom_idx, :] = noisy_features_present_atoms_temp[:, atom_idx, :]\n",
    "\n",
    "            #save initial distribution TODO: fix positions, they are not centered\n",
    "            save_xyz_file(\n",
    "                chain_output,\n",
    "                one_hot_combined,\n",
    "                positions_combined,\n",
    "                node_mask[i].unsqueeze(0),\n",
    "                names=[f'{name}_' + str(keep_frames)],\n",
    "                is_geom=model.is_geom\n",
    "            )\n",
    "\n",
    "            # one_hot = chain[:, :, 3:-1]\n",
    "            one_hot = chain[:, :, 3:] #@mastro, added last atom type (not sure whyt it was not included...) However, TODO check again\n",
    "            positions = chain[:, :, :3]\n",
    "            chain_node_mask = torch.cat([node_mask[i].unsqueeze(0) for _ in range(keep_frames)], dim=0)\n",
    "            names = [f'{name}_{j}' for j in range(keep_frames)]\n",
    "\n",
    "            save_xyz_file(chain_output, one_hot, positions, chain_node_mask, names=names, is_geom=model.is_geom)\n",
    "\n",
    "            invert_colormap = False\n",
    "            if average_frobenius_norm > original_frobenius_norm:\n",
    "                invert_colormap = True\n",
    "\n",
    "            visualize_chain_xai(\n",
    "                chain_output,\n",
    "                spheres_3d=False,\n",
    "                alpha=0.7,\n",
    "                bg='white',\n",
    "                is_geom=model.is_geom,\n",
    "                fragment_mask=data_temp['fragment_mask'][i].squeeze(),\n",
    "                phi_values=None,\n",
    "                colors_fragment_shadow=colors_fragment_shadow,\n",
    "                invert_colormap=invert_colormap\n",
    "            )\n",
    "\n",
    "            # Saving final prediction and ground truth separately\n",
    "            true_one_hot = data_temp['one_hot'][i].unsqueeze(0)\n",
    "            true_positions = data_temp['positions'][i].unsqueeze(0)\n",
    "            true_node_mask = data_temp['atom_mask'][i].unsqueeze(0)\n",
    "\n",
    "            final_states_output_dir_current = os.path.join(final_states_output_dir, name)\n",
    "            save_xyz_file(\n",
    "                final_states_output_dir,\n",
    "                true_one_hot,\n",
    "                true_positions,\n",
    "                true_node_mask,\n",
    "                names=[f'{name}_true_atoms_' + str(len(fragment_atoms_indices_keep))],\n",
    "                is_geom=model.is_geom,\n",
    "            )\n",
    "\n",
    "            pred_one_hot = chain[0, :, 3:-1].unsqueeze(0)\n",
    "            pred_positions = chain[0, :, :3].unsqueeze(0)\n",
    "            pred_node_mask = chain_node_mask[0].unsqueeze(0)\n",
    "            save_xyz_file(\n",
    "                final_states_output_dir,\n",
    "                pred_one_hot,\n",
    "                pred_positions,\n",
    "                pred_node_mask,\n",
    "                names=[f'{name}_pred_atoms_' + str(len(fragment_atoms_indices_keep))],\n",
    "                is_geom=model.is_geom\n",
    "            )\n",
    "\n",
    "        del data_temp\n",
    "        del noisy_features_present_atoms_temp\n",
    "        del noisy_positions_present_atoms_temp\n",
    "    start += len(data['positions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_explainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mastro\\anaconda3\\envs\\diff_explainer\\lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.6.3 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Repositories\\DiffLinker\\models\\zinc_difflinker.ckpt`\n",
      "c:\\Repositories\\DiffLinker\\src\\datasets.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data = torch.load(dataset_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from src.datasets import get_dataloader\n",
    "from src.lightning import DDPM\n",
    "from src.molecule_builder import get_bond_order\n",
    "from src.visualizer import save_xyz_file, visualize_chain\n",
    "from tqdm.auto import tqdm\n",
    "from pdb import set_trace\n",
    "import sys #@mastro\n",
    "from src import const #@mastro\n",
    "import numpy as np #@mastro\n",
    "from numpy.random import default_rng\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    'ipykernel_launcher.py',\n",
    "    '--checkpoint', 'models/zinc_difflinker.ckpt',\n",
    "    '--chains', 'trajectories',\n",
    "    '--data', 'datasets',\n",
    "    '--prefix', 'zinc_final_test',\n",
    "    '--keep_frames', '1',\n",
    "    '--device', 'cuda:0'\n",
    "]\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--checkpoint', action='store', type=str, required=True)\n",
    "parser.add_argument('--chains', action='store', type=str, required=True)\n",
    "parser.add_argument('--prefix', action='store', type=str, required=True)\n",
    "parser.add_argument('--data', action='store', type=str, required=False, default=None)\n",
    "parser.add_argument('--keep_frames', action='store', type=int, required=True)\n",
    "parser.add_argument('--device', action='store', type=str, required=True)\n",
    "args = parser.parse_args()\n",
    "\n",
    "experiment_name = args.checkpoint.split('/')[-1].replace('.ckpt', '')\n",
    "chains_output_dir = os.path.join(args.chains, experiment_name, args.prefix, 'chains')\n",
    "final_states_output_dir = os.path.join(args.chains, experiment_name, args.prefix, 'final_states')\n",
    "os.makedirs(chains_output_dir, exist_ok=True)\n",
    "os.makedirs(final_states_output_dir, exist_ok=True)\n",
    "\n",
    "# Loading model form checkpoint (all hparams will be automatically set)\n",
    "model = DDPM.load_from_checkpoint(args.checkpoint, map_location=args.device)\n",
    "\n",
    "# Possibility to evaluate on different datasets (e.g., on CASF instead of ZINC)\n",
    "model.val_data_prefix = args.prefix\n",
    "\n",
    "# In case <Anonymous> will run my model or vice versa\n",
    "if args.data is not None:\n",
    "    model.data_path = args.data\n",
    "\n",
    "model = model.eval().to(args.device)\n",
    "model.setup(stage='val')\n",
    "dataloader = get_dataloader(\n",
    "    model.val_dataset,\n",
    "    batch_size=1, #@mastro, it was 32\n",
    "    # batch_size=len(model.val_dataset)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_molecular_similarity(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on distances and atom type.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        float: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    # If fragmen_mask is provided, only consider the atoms in the mask\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        mol1 = mol1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mol2 = mol2[mask2,:]\n",
    "\n",
    "    return 1 - torch.norm(mol1 - mol2)\n",
    "\n",
    "def compute_molecular_distance(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on distances and atom type.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        float: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    # If fragmen_mask is provided, only consider the atoms in the mask\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        mol1 = mol1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mol2 = mol2[mask2,:]\n",
    "\n",
    "    return torch.norm(mol1 - mol2).item()\n",
    "\n",
    "def compute_cosine_similarity(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on distances and atom type.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        float: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    # If fragmen_mask is provided, only consider the atoms in the mask\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        mol1 = mol1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mol2 = mol2[mask2,:]\n",
    "\n",
    "    return cosine_similarity(mol1.flatten().reshape(1, -1), mol2.flatten().reshape(1, -1)).item()\n",
    "\n",
    "def compute_molecular_similarity_positions(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Compute the similarity between two molecules based on positions.\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first molecule.\n",
    "        mol2 (torch.Tensor): The second molecule.\n",
    "        mask (torch.Tensor, optional): A mask indicating which atoms to consider. If not provided, all atoms will be considered.\n",
    "        \n",
    "    Returns:\n",
    "        float: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    # If fragmen_mask is provided, only consider the atoms in the mask\n",
    "    positions1 = mol1[:, :3].squeeze()\n",
    "    positions2 = mol2[:, :3].squeeze()\n",
    "\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        positions1 = positions1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        positions2 = positions2[mask2,:]\n",
    "\n",
    "\n",
    "    return 1 - torch.norm(positions1 - positions2) #choose if distance or similarity, need to check what it the better choice\n",
    "\n",
    "def compute_one_hot_similarity(mol1, mol2, mask1 = None, mask2 = None):\n",
    "    \"\"\"\n",
    "    Computes the similarity between two one-hot encoded molecules. The one-hot encoding indicates the atom type\n",
    "    \n",
    "    Args:\n",
    "        mol1 (torch.Tensor): The first one-hot encoded molecule.\n",
    "        mol2 (torch.Tensor): The second one-hot encoded molecule.\n",
    "        mask (torch.Tensor, optional): A mask to apply on the atoms. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: The similarity between the two molecules.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply mask if provided\n",
    "    if mask1 is not None:\n",
    "        mask1 = mask1.bool()\n",
    "        mol1 = mol1[mask1,:]\n",
    "\n",
    "    if mask2 is not None:\n",
    "        mask2 = mask2.bool()\n",
    "        mol2 = mol2[mask2,:]\n",
    "    \n",
    "    # Compute similarity by comparing the one-hot encoded features\n",
    "    similarity = torch.sum(mol1[:,3:-1] == mol2[:,3:-1]) / mol1[:, 3:-1].numel()\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the two chains: 1.0\n",
      "Similarity between the two chains based on positions: 1.0\n",
      "Similarity between the two one-hot vectors: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcf2b2ac5a84add90813c9c80cdf52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b6b3ab43e94906ac4f49b4832e5b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cc1ccc(CCNC(=O)NCCc2csc(N3CCCC3)n2)c(C)c1']\n",
      "Similarity between the two chains: 1.0\n",
      "Similarity between the two chains based on positions: 1.0\n",
      "Similarity between the two one-hot vectors: 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3845570284f64fafb85a72fbf51066d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf3b1fcb326455fa6c7efb4b389f985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cc1ccc(CCNC(=O)NCCc2csc(N3CCCC3)n2)c(C)c1']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#@mastro\n",
    "num_samples = 5\n",
    "sampled = 0\n",
    "#end @mastro\n",
    "start = 0\n",
    "bond_order_dict = {0:0, 1:0, 2:0, 3:0}\n",
    "ATOM_SAMPLER = False\n",
    "SAVE_ORIGINAL_PREDICTION = True\n",
    "chain_with_full_fragments = None\n",
    "M = 100 #number of Monte Carlo Sampling steps\n",
    "P = 0.2 #probability of atom to exist in random graph (also edge in the future)\n",
    "SEED = 42 #seed for random sampling\n",
    "# Create the folder if it does not exist\n",
    "folder_save_path = \"results/explanations\"\n",
    "if not os.path.exists(folder_save_path):\n",
    "    os.makedirs(folder_save_path)\n",
    "\n",
    "for data in dataloader:\n",
    "    \n",
    "    if sampled < num_samples:\n",
    "        chain_with_full_fragments = None\n",
    "        sampled += 1\n",
    "        \n",
    "        # generate chain with original and full fragments\n",
    "\n",
    "        chain_batch, node_mask = model.sample_chain(data, keep_frames=args.keep_frames)\n",
    "        \n",
    "        #get the generated molecule and store it in a variable\n",
    "        chain_with_full_fragments = chain_batch[:, 0, :, :]\n",
    "\n",
    "        # Compute distance of two chains\n",
    "        mol_similarity = compute_molecular_similarity(chain_with_full_fragments.squeeze(), chain_with_full_fragments.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data[\"linker_mask\"][0].squeeze())\n",
    "        print(\"Similarity between the two chains:\", mol_similarity.item())\n",
    "        # compute similarity of one-hot vectors\n",
    "        positional_similarity = compute_molecular_similarity_positions(chain_with_full_fragments.squeeze(), chain_with_full_fragments.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data[\"linker_mask\"][0].squeeze())\n",
    "        print(\"Similarity between the two chains based on positions:\", positional_similarity.item())\n",
    "        one_hot_similarity = compute_one_hot_similarity(chain_with_full_fragments.squeeze(), chain_with_full_fragments.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data[\"linker_mask\"][0].squeeze())\n",
    "        print(\"Similarity between the two one-hot vectors:\", one_hot_similarity.item())\n",
    "        \n",
    "    \n",
    "        if SAVE_ORIGINAL_PREDICTION:\n",
    "            for i in range(len(data['positions'])):\n",
    "                chain = chain_batch[:, i, :, :]\n",
    "                assert chain.shape[0] == args.keep_frames\n",
    "                assert chain.shape[1] == data['positions'].shape[1]\n",
    "                assert chain.shape[2] == data['positions'].shape[2] + data['one_hot'].shape[2] + model.include_charges\n",
    "\n",
    "                # Saving chains\n",
    "                name = str(i + start)\n",
    "                chain_output = os.path.join(chains_output_dir, name)\n",
    "                os.makedirs(chain_output, exist_ok=True)\n",
    "\n",
    "                one_hot = chain[:, :, 3:-1]\n",
    "                positions = chain[:, :, :3]\n",
    "                chain_node_mask = torch.cat([node_mask[i].unsqueeze(0) for _ in range(args.keep_frames)], dim=0)\n",
    "                names = [f'{name}_{j}' for j in range(args.keep_frames)]\n",
    "\n",
    "                save_xyz_file(chain_output, one_hot, positions, chain_node_mask, names=names, is_geom=model.is_geom)\n",
    "                visualize_chain(\n",
    "                    chain_output,\n",
    "                    spheres_3d=True,\n",
    "                    alpha=0.7,\n",
    "                    bg='white',\n",
    "                    is_geom=model.is_geom,\n",
    "                    fragment_mask=data['fragment_mask'][i].squeeze()\n",
    "                )\n",
    "\n",
    "                # Saving final prediction and ground truth separately\n",
    "                true_one_hot = data['one_hot'][i].unsqueeze(0)\n",
    "                true_positions = data['positions'][i].unsqueeze(0)\n",
    "                true_node_mask = data['atom_mask'][i].unsqueeze(0)\n",
    "                save_xyz_file(\n",
    "                    final_states_output_dir,\n",
    "                    true_one_hot,\n",
    "                    true_positions,\n",
    "                    true_node_mask,\n",
    "                    names=[f'{name}_true'],\n",
    "                    is_geom=model.is_geom,\n",
    "                )\n",
    "\n",
    "                pred_one_hot = chain[0, :, 3:-1].unsqueeze(0)\n",
    "                pred_positions = chain[0, :, :3].unsqueeze(0)\n",
    "                pred_node_mask = chain_node_mask[0].unsqueeze(0)\n",
    "                save_xyz_file(\n",
    "                    final_states_output_dir,\n",
    "                    pred_one_hot,\n",
    "                    pred_positions,\n",
    "                    pred_node_mask,\n",
    "                    names=[f'{name}_pred'],\n",
    "                    is_geom=model.is_geom\n",
    "                )\n",
    "\n",
    "            start += len(data['positions'])\n",
    "        # display(data[\"fragment_mask\"])\n",
    "        # display(data[\"fragment_mask\"].shape)\n",
    "\n",
    "        # display(data[\"linker_mask\"])\n",
    "        # display(data[\"linker_mask\"].shape)\n",
    "        \n",
    "        # display(data[\"edge_mask\"])\n",
    "        # display(data[\"edge_mask\"].shape)\n",
    "\n",
    "        #mask out all edges that are not bonds\n",
    "        # idx2atom = const.GEOM_IDX2ATOM if model.is_geom else const.IDX2ATOM\n",
    "      \n",
    "        # positions = data[\"positions\"][0].detach().cpu().numpy()\n",
    "        # x  = positions[:,0]\n",
    "        # y  = positions[:,1]\n",
    "        # z  = positions[:,2]\n",
    "        # # print(x)\n",
    "       \n",
    "        # atom_type = torch.argmax(data[\"one_hot\"][0], dim=1)\n",
    "        # print(\"Number of edges\", len(x) * len(x))\n",
    "        # sys.exit()\n",
    "        #uncomment to work on edge_mask (not huge effect, tho)\n",
    "        # for i in range(len(x)):\n",
    "        #     for j in range(i+1, len(x)):\n",
    "        #         p1 = np.array([x[i], y[i], z[i]])\n",
    "        #         p2 = np.array([x[j], y[j], z[j]])\n",
    "        #         dist =  np.sqrt(np.sum((p1 - p2) ** 2)) #np.linalg.norm(p1-p2)\n",
    "                \n",
    "        #         atom1, atom2 = idx2atom[atom_type[i].item()], idx2atom[atom_type[j].item()]\n",
    "        #         bond_order = get_bond_order(atom1, atom2, dist)\n",
    "                \n",
    "        #         bond_order_dict[bond_order] += 1\n",
    "        #         # if bond_order <= 0: #TODO debug. Why not all set to 0?\n",
    "        #         if True:\n",
    "        #             data[\"edge_mask\"][i * len(x) + j] = 0\n",
    "        #             data[\"edge_mask\"][j * len(x) + i] = 0\n",
    "        #         #set all edge_mask indices to 0\n",
    "        #         data[\"edge_mask\"] = torch.zeros_like(data[\"edge_mask\"])\n",
    "\n",
    "        #randomly mask out 50% of atoms\n",
    "        # mask = torch.rand(data[\"atom_mask\"].shape) > 0.5\n",
    "        # data[\"atom_mask\"] = data[\"atom_mask\"] * mask.to(model.device)\n",
    "        #mask out all atoms\n",
    "        # data[\"atom_mask\"] = torch.zeros_like(data[\"atom_mask\"])\n",
    "        \n",
    "        #variables that will become function/class arguments/variables\n",
    "\n",
    "        \n",
    "        num_fragment_atoms = torch.sum(data[\"fragment_mask\"] == 1)\n",
    "\n",
    "        rng = default_rng(seed = SEED)\n",
    "        phi_atoms = {}\n",
    "        fragment_indices = torch.where(data[\"fragment_mask\"] == 1)[1]\n",
    "        num_fragment_atoms = len(fragment_indices)\n",
    "        num_atoms = data[\"positions\"].shape[1]\n",
    "\n",
    "        distances_random_samples = []\n",
    "        cosine_similarities_random_samples = []\n",
    "\n",
    "        for j in tqdm(range(num_fragment_atoms)[:1]): #@mastro to DELETE the [:1] to run on all atoms\n",
    "            \n",
    "            marginal_contrib_distance = 0\n",
    "            marginal_contrib_cosine_similarity = 0\n",
    "            marginal_contrib_hausdorff = 0\n",
    "\n",
    "            for step in tqdm(range(M)):\n",
    "                data_j_plus = data.copy()\n",
    "                data_j_minus = data.copy()\n",
    "                data_random = data.copy()\n",
    "\n",
    "                N_z_mask = rng.binomial(1, P, size = num_fragment_atoms)\n",
    "\n",
    "                # print(\"N_z_mask\", N_z_mask)\n",
    "\n",
    "                N_mask = torch.ones(num_fragment_atoms, dtype=torch.int)\n",
    "\n",
    "                pi = torch.randperm(num_fragment_atoms)\n",
    "\n",
    "                N_j_plus_index = torch.ones(num_fragment_atoms, dtype=torch.int)\n",
    "                N_j_minus_index = torch.ones(num_fragment_atoms, dtype=torch.int)\n",
    "                selected_node_index = np.where(pi == j)[0].item()\n",
    "                \n",
    "                # print(\"Selected node index\", selected_node_index)\n",
    "                for k in range(num_fragment_atoms):\n",
    "                    if k <= selected_node_index:\n",
    "                        N_j_plus_index[pi[k]] = N_mask[pi[k]]\n",
    "                    else:\n",
    "                        N_j_plus_index[pi[k]] = N_z_mask[pi[k]]\n",
    "\n",
    "                for k in range(num_fragment_atoms):\n",
    "                    if k < selected_node_index:\n",
    "                        N_j_minus_index[pi[k]] = N_mask[pi[k]]\n",
    "                    else:\n",
    "                        N_j_minus_index[pi[k]] = N_z_mask[pi[k]]\n",
    "\n",
    "\n",
    "                # print(\"N_j_plus_index\", N_j_plus_index)\n",
    "                # print(\"N_j_minus_index\", N_j_minus_index)\n",
    "                # print(N_j_plus_index == N_j_minus_index)\n",
    "                \n",
    "                N_j_plus = fragment_indices[N_j_plus_index.bool()] #fragement indices to keep in molecule j plus\n",
    "                N_j_minus = fragment_indices[N_j_minus_index.bool()] #fragement indices to keep in molecule j minus\n",
    "\n",
    "                N_random_sample = fragment_indices[torch.IntTensor(N_z_mask).bool()] #fragement indices to keep in random molecule\n",
    "                # print(\"N_j_plus\", N_j_plus)\n",
    "                # print(\"N_j_minus\", N_j_minus)\n",
    "                # print(N_j_plus == N_j_minus)\n",
    "                atom_mask_j_plus = torch.zeros(num_atoms, dtype=torch.bool)\n",
    "                atom_mask_j_minus = torch.zeros(num_atoms, dtype=torch.bool)\n",
    "\n",
    "                atom_mask_random_molecule = torch.zeros(num_atoms, dtype=torch.bool)\n",
    "\n",
    "                atom_mask_j_plus[N_j_plus] = True\n",
    "                #set to true also linker atoms\n",
    "                atom_mask_j_plus[data[\"linker_mask\"][0].squeeze().to(torch.int) == 1] = True\n",
    "                atom_mask_j_minus[N_j_minus] = True\n",
    "                #set to true also linker atoms\n",
    "                atom_mask_j_minus[data[\"linker_mask\"][0].squeeze().to(torch.int) == 1] = True\n",
    "\n",
    "                atom_mask_random_molecule[N_random_sample] = True\n",
    "                #set to true also linker atoms\n",
    "                atom_mask_random_molecule[data[\"linker_mask\"][0].squeeze().to(torch.int) == 1] = True\n",
    "\n",
    "                # print(\"Atom mask j plus\", atom_mask_j_plus)\n",
    "                # print(\"Atom mask j minus\", atom_mask_j_minus)\n",
    "                # print(atom_mask_j_minus==atom_mask_j_plus)\n",
    "\n",
    "                #for sample containing j\n",
    "                #remove positions of atoms in random_indices\n",
    "                data_j_plus[\"positions\"] = data_j_plus[\"positions\"][:, atom_mask_j_plus]\n",
    "                #remove one_hot of atoms in random_indices\n",
    "                data_j_plus[\"one_hot\"] = data_j_plus[\"one_hot\"][:, atom_mask_j_plus]\n",
    "                #remove atom_mask of atoms in random_indices\n",
    "                data_j_plus[\"atom_mask\"] = data_j_plus[\"atom_mask\"][:, atom_mask_j_plus]\n",
    "                #remove fragment_mask of atoms in random_indices\n",
    "                data_j_plus[\"fragment_mask\"] =  data_j_plus[\"fragment_mask\"][:, atom_mask_j_plus]\n",
    "                #remove linker_mask of atoms in random_indices\n",
    "                data_j_plus[\"linker_mask\"] = data_j_plus[\"linker_mask\"][:, atom_mask_j_plus]\n",
    "                #remove edge_mask of atoms in random_indices\n",
    "                for index in N_j_plus:\n",
    "                    for i in range(num_atoms):\n",
    "                        data_j_plus[\"edge_mask\"][index * num_atoms + i] = 0\n",
    "                        data_j_plus[\"edge_mask\"][i * num_atoms + index] = 0\n",
    "\n",
    "                #remove all values in edge_mask that are 0\n",
    "                data_j_plus[\"edge_mask\"] = data_j_plus[\"edge_mask\"][data_j_plus[\"edge_mask\"] != 0]  #to be checked, but working on atoms has as effect. For the moment we stick to atoms, then we move to edges (need to edit internal function for this, or redefine everything...)\n",
    "\n",
    "                # print(\"After removal j plus:\", data_j_plus[\"positions\"])\n",
    "                # print(data_j_plus[\"positions\"].shape)\n",
    "                \n",
    "                #for sample not containing j\n",
    "                #remove positions of atoms in random_indices\n",
    "                data_j_minus[\"positions\"] = data_j_minus[\"positions\"][:, atom_mask_j_minus]\n",
    "                #remove one_hot of atoms in random_indices\n",
    "                data_j_minus[\"one_hot\"] = data_j_minus[\"one_hot\"][:, atom_mask_j_minus]\n",
    "                #remove atom_mask of atoms in random_indices\n",
    "                data_j_minus[\"atom_mask\"] = data_j_minus[\"atom_mask\"][:, atom_mask_j_minus]\n",
    "                #remove fragment_mask of atoms in random_indices\n",
    "                data_j_minus[\"fragment_mask\"] =  data_j_minus[\"fragment_mask\"][:, atom_mask_j_minus]\n",
    "                #remove linker_mask of atoms in random_indices\n",
    "                data_j_minus[\"linker_mask\"] = data_j_minus[\"linker_mask\"][:, atom_mask_j_minus]\n",
    "                #remove edge_mask of atoms in random_indices\n",
    "                for index in N_j_minus:\n",
    "                    for i in range(num_atoms):\n",
    "                        data_j_minus[\"edge_mask\"][index * num_atoms + i] = 0\n",
    "                        data_j_minus[\"edge_mask\"][i * num_atoms + index] = 0\n",
    "\n",
    "                #remove all values in edge_mask that are 0\n",
    "                data_j_minus[\"edge_mask\"] = data_j_minus[\"edge_mask\"][data_j_minus[\"edge_mask\"] != 0]  #to be checked, but working on atoms has as effect. For the moment we stick to atoms, then we move to edges (need to edit internal function for this, or redefine everything...)\n",
    "\n",
    "                # print(\"After removal j minus:\", data_j_minus[\"positions\"])\n",
    "                # print(data_j_minus[\"positions\"].shape)\n",
    "\n",
    "                #for random sample\n",
    "                data_random[\"positions\"] = data_random[\"positions\"][:, atom_mask_random_molecule]\n",
    "                #remove one_hot of atoms in random_indices\n",
    "                data_random[\"one_hot\"] = data_random[\"one_hot\"][:, atom_mask_random_molecule]\n",
    "                #remove atom_mask of atoms in random_indices\n",
    "                data_random[\"atom_mask\"] = data_random[\"atom_mask\"][:, atom_mask_random_molecule]\n",
    "                #remove fragment_mask of atoms in random_indices\n",
    "                data_random[\"fragment_mask\"] =  data_random[\"fragment_mask\"][:, atom_mask_random_molecule]\n",
    "                #remove linker_mask of atoms in random_indices\n",
    "                data_random[\"linker_mask\"] = data_random[\"linker_mask\"][:, atom_mask_random_molecule]\n",
    "                #remove edge_mask of atoms in random_indices\n",
    "                for index in N_z_mask:\n",
    "                    for i in range(num_atoms):\n",
    "                        data_random[\"edge_mask\"][index * num_atoms + i] = 0\n",
    "                        data_random[\"edge_mask\"][i * num_atoms + index] = 0\n",
    "\n",
    "                #remove all values in edge_mask that are 0\n",
    "                data_random[\"edge_mask\"] = data_random[\"edge_mask\"][data_random[\"edge_mask\"] != 0] \n",
    "\n",
    "\n",
    "\n",
    "                #with node j\n",
    "                chain_j_plus, node_mask_j_plus = model.sample_chain(data_j_plus, keep_frames=args.keep_frames)\n",
    "\n",
    "                V_j_plus_distance = compute_molecular_distance(chain_with_full_fragments.squeeze(), chain_j_plus.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data_j_plus[\"linker_mask\"][0].squeeze())\n",
    "\n",
    "                V_j_plus_cosine_similarity = compute_cosine_similarity(chain_with_full_fragments.squeeze().cpu(), chain_j_plus.squeeze().cpu(), mask1=data[\"linker_mask\"][0].squeeze().cpu(), mask2=data_j_plus[\"linker_mask\"][0].squeeze().cpu())\n",
    "\n",
    "                # print(\"V_j_plus\", V_j_plus)\n",
    "\n",
    "                #without node j\n",
    "                chain_j_minus, node_mask_j_minus = model.sample_chain(data_j_minus, keep_frames=args.keep_frames)\n",
    "\n",
    "                V_j_minus_distance = compute_molecular_distance(chain_with_full_fragments.squeeze(), chain_j_minus.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data_j_minus[\"linker_mask\"][0].squeeze())\n",
    "\n",
    "                V_j_minus_cosine_similarity = compute_cosine_similarity(chain_with_full_fragments.squeeze().cpu(), chain_j_minus.squeeze().cpu(), mask1=data[\"linker_mask\"][0].squeeze().cpu(), mask2=data_j_minus[\"linker_mask\"][0].squeeze().cpu())\n",
    "\n",
    "                #with random sample\n",
    "                chain_random, node_mask_random = model.sample_chain(data_random, keep_frames=args.keep_frames)\n",
    "\n",
    "                V_random_distance = compute_molecular_distance(chain_with_full_fragments.squeeze(), chain_random.squeeze(), mask1=data[\"linker_mask\"][0].squeeze(), mask2=data_random[\"linker_mask\"][0].squeeze())\n",
    "\n",
    "                V_random_cosine_similarity = compute_cosine_similarity(chain_with_full_fragments.squeeze().cpu(), chain_random.squeeze().cpu(), mask1=data[\"linker_mask\"][0].squeeze().cpu(), mask2=data_random[\"linker_mask\"][0].squeeze().cpu())\n",
    "\n",
    "                distances_random_samples.append(V_random_distance)\n",
    "                cosine_similarities_random_samples.append(V_random_cosine_similarity)\n",
    "\n",
    "                # print(V_random_distance, V_random_cosine_similarity)\n",
    "                \n",
    "                marginal_contrib_distance += (V_j_plus_distance - V_j_minus_distance)\n",
    "\n",
    "                marginal_contrib_cosine_similarity += (V_j_plus_cosine_similarity - V_j_minus_cosine_similarity)\n",
    "\n",
    "                # marginal_contrib_hausdorff += (V_j_plus_hausdorff - V_j_minus_hausdorff)\n",
    "\n",
    "            phi_atoms[fragment_indices[j].item()] = [0,0] #,0]    \n",
    "            phi_atoms[fragment_indices[j].item()][0] = marginal_contrib_distance/M #j is the index of the fragment atom in the fragment indices tensor\n",
    "            phi_atoms[fragment_indices[j].item()][1] = marginal_contrib_cosine_similarity/M\n",
    "            # phi_atoms[fragment_indices[j]][2] = marginal_contrib_hausdorff/M\n",
    "\n",
    "            print(data[\"name\"])\n",
    "            # Save phi_atoms to a text file\n",
    "            with open(f'{folder_save_path}/phi_atoms_{sampled}.txt', 'w') as write_file:\n",
    "                write_file.write(\"sample name: \" + str(data[\"name\"]) + \"\\n\")\n",
    "                write_file.write(\"atom_index,distance,cosine_similarity\\n\")\n",
    "                for atom_index, phi_values in phi_atoms.items():\n",
    "                    write_file.write(f\"{atom_index},{phi_values[0]},{phi_values[1]}\\n\")\n",
    "\n",
    "        if ATOM_SAMPLER:\n",
    "            print(\"Before removal:\", data[\"positions\"].shape)\n",
    "            #get all indices in atom_mask that correspond to fragment atoms\n",
    "            fragment_indices = torch.where(data[\"fragment_mask\"] == 1)[1]\n",
    "\n",
    "            print(fragment_indices)\n",
    "            \n",
    "            #randomly pick 50% of fragment atoms\n",
    "            random_indices = torch.randperm(len(fragment_indices))[:int(len(fragment_indices)/2)]\n",
    "            mask_fragments = torch.ones(len(fragment_indices), dtype=torch.bool)\n",
    "            mask_fragments[random_indices] = False\n",
    "            selected_fragment_atoms = fragment_indices[mask_fragments]\n",
    "\n",
    "            #keep only the first index in selected_fragment_atoms\n",
    "            selected_fragment_atoms = selected_fragment_atoms[:1] #@mastro change this removing the explained atom\n",
    "            print(\"Selected fragment atoms\", selected_fragment_atoms)\n",
    "            \n",
    "            num_atoms = data[\"positions\"].shape[1]\n",
    "            # random_indices = torch.randperm(num_atoms)[:int(num_atoms/2)]\n",
    "            mask = torch.ones(num_atoms, dtype=torch.bool)\n",
    "            mask[selected_fragment_atoms] = False\n",
    "\n",
    "\n",
    "            #remove positions of atoms in random_indices\n",
    "            data[\"positions\"] = data[\"positions\"][:, mask]\n",
    "            #remove one_hot of atoms in random_indices\n",
    "            data[\"one_hot\"] = data[\"one_hot\"][:, mask]\n",
    "            #remove atom_mask of atoms in random_indices\n",
    "            data[\"atom_mask\"] = data[\"atom_mask\"][:, mask]\n",
    "            #remove fragment_mask of atoms in random_indices\n",
    "            data[\"fragment_mask\"] =  data[\"fragment_mask\"][:, mask]\n",
    "            #remove linker_mask of atoms in random_indices\n",
    "            data[\"linker_mask\"] = data[\"linker_mask\"][:, mask]\n",
    "            #remove edge_mask of atoms in random_indices\n",
    "            for index in random_indices:\n",
    "                for i in range(num_atoms):\n",
    "                    data[\"edge_mask\"][index * num_atoms + i] = 0\n",
    "                    data[\"edge_mask\"][i * num_atoms + index] = 0\n",
    "\n",
    "            #remove all values in edge_mask that are 0\n",
    "            data[\"edge_mask\"] = data[\"edge_mask\"][data[\"edge_mask\"] != 0]  #to be checked, but working on atoms has as effect. For the moment we stick to atoms, then we move to edges (need to edit internal function for this, or redefine everything...)\n",
    "            \n",
    "\n",
    "            print(\"After removal:\", data[\"positions\"].shape)\n",
    "            # sys.exit()\n",
    "            # print number of zeros in edge mask\n",
    "            print(\"Number of masked out edges (edges not representing bonds)\", torch.sum(data[\"edge_mask\"] == 0))\n",
    "            print(\"Number of edges still present\", torch.sum(data[\"edge_mask\"] != 0))\n",
    "\n",
    "            # print number of zeros in atom mask\n",
    "            print(\"Number of masked out atoms\", torch.sum(data[\"atom_mask\"] == 0))\n",
    "\n",
    "        \n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [-1.3673028945922852, 0.17679688334465027]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# chain_with_full_fragments = chain_with_full_fragments[0,:,:]\n",
    "# # Generate a random boolean mask\n",
    "# mask = np.random.choice([True, False], size=chain_with_full_fragments.shape[0])\n",
    "\n",
    "# # Apply the mask to remove random rows\n",
    "# masked_chain = chain_with_full_fragments[mask, :]\n",
    "\n",
    "# masked_chain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in dataloader:\n",
    "#     positions = data[\"positions\"]\n",
    "#     # print(positions)\n",
    "    \n",
    "#     cos_sim = cosine_similarity((positions[0].squeeze().detach().cpu().numpy().flatten().reshape(1, -1)),positions[0].squeeze().detach().cpu().numpy().flatten().reshape(1, -1))\n",
    "\n",
    "#     cosine = compute_cosine_similarity(positions[0].squeeze().cpu(), positions[0].squeeze().cpu(), mask1=data[\"linker_mask\"][0].squeeze().cpu(), mask2=data[\"linker_mask\"][0].squeeze().cpu())\n",
    "#     print(cosine)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atom_mask_random_molecule"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_explainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
